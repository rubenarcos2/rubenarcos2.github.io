<!DOCTYPE html>
<style>
  .alert {
    padding: 20px;
    background-color: #ff9203;
    text-align: center;
  }

  .alert a{
    color: white;
    text-decoration: none;
  }

  .closebtn {
    margin-left: 15px;
    color: white;
    font-weight: bold;
    float: right;
    font-size: 22px;
    line-height: 20px;
    cursor: pointer;
    transition: 0.3s;
  }

  .closebtn:hover {
    color: black;
  }
</style>







<html lang="en">




<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Opensource Chatbot</title>
  <meta name='description'
    content='Creation of a chatbot with opensource model, applying the RAG technique and using Ollama, LangChain, ChromaDb and a final output as API to a web chatbot.'>

  <!-- Google Fonts -->
  <link
    href="https://fonts.googleapis.com/css?family=Dancing+Script%7CPT+Serif:400,400i,700%7CLato:400,700%7CRoboto:300,400"
    rel="stylesheet">

  <!-- Font Awesome v6.4.2 -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">

  <!-- Normalize v7.0.0 -->
  <link rel="stylesheet" href="/css/normalize.css">

  <!-- Main Stylesheet -->
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://rarcos.com/2024/05/25/Ollama_api_chatbot/">
  <link rel="alternate" type="application/rss+xml" title="Rubén Arcos" href="/feed.xml">

  <!-- Chrome, Firefox OS and Opera -->
  <meta name="theme-color" content="#faf5ee">
  <!-- Windows Phone -->
  <meta name="msapplication-navbutton-color" content="#faf5ee">
  <!-- iOS Safari -->
  <meta name="apple-mobile-web-app-status-bar-style" content="#faf5ee">
  <!-- Start cookieyes banner --> 
  <script id="cookieyes" type="text/javascript" src="https://cdn-cookieyes.com/client_data/6ae1ee7e40cef2c175ff9462/script.js"></script> 
  <!-- End cookieyes banner -->
</head>



  
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VL018H86JE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-VL018H86JE');
</script> <!-- /Google Analytics -->
  

  <div class="full-page-container">
    <div class="overlay"></div>
    <header class="site-header clearfix">
  <div class="wrapper-content">

    <div class="switch-lang">
      
      
      <!--en-->
      
      
      
      
      <a id="switch-lang" href="/es/2024/05/25/Ollama_api_chatbot/" title="Change language to es">
        <img src="https://cdn.wpml.org/wp-content/plugins/sitepress-multilingual-cms/res/flags/es.png">
      </a>
      
      
      
    </div>

    <div class="navigation-wrap">
      <div class="nav-toggle-close"><i class="fa fa-times" aria-hidden="true"></i></div>

      <nav class="site-nav">
        
        
        
        
        
        
        
      
      
      
      
      
      <a href='/about/'>About me</a>
      
      
      
        
        
        
        
        
        
        
      
      
      
      
      
      <a href='/contacto/'>Contact</a>
      
      
      
        
        
        
        
        
        
        
      
      
      
      
      
      <a href='/cookies/'>Cookies</a>
      
      
      
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        <a href="https://linkedin.com/in/rubenarcos2"><i class="fa-brands fa-linkedin fa-2x" aria-hidden="true"></i></a>
        <a href="https://github.com/rubenarcos2"><i class="fa-brands fa-github fa-2x" aria-hidden="true"></i></a>
      </nav>

    </div>

    <span class="search-toggle">
      <i class="fa fa-search" aria-hidden="true"></i>
    </span>

    <div class="nav-toggle"><i class="fa fa-bars" aria-hidden="true"></i></div>

    <div class="site-logo">
      <a href="/">Rubén Arcos</a>
    </div>

  </div>
</header> <!-- /.site-header -->
    <div class="search-box">
  <div class="wrapper-content">
    <form class="search-form">
      
      
      
      
      
      
      <label class="screen-reader-text" for="search-input">Search...</label>
      <input type="text" id="search-input" class="search-field" name="s" placeholder="Search...">
      
      
      

    </form>
    <div class="btn-close">
      <span class="bt-search-close">
        <i class="fa fa-times" aria-hidden="true"></i>
      </span>
    </div>
  </div>
  <ul id="results-container" class="search-results-list"></ul>
</div> <!-- /.search-box -->
    
    
    
    
    
    
    
    <div class="alert">
      <span class="closebtn" onclick="this.parentElement.style.display='none';">&times;</span> 
      <a href="https://www.linkedin.com/in/rubenarcos2/">Job offers, proposals or other initiatives send them to me via LinkedIn</a>
    </div>
    
    
    

    <div class="post-header" style="background: url(/images/pages/ollama_api.jpg)">
  <div class="post-header-info">
    <h1 class="post-title">Opensource Chatbot</h1>
    <div class="post-meta">
      
      
      
      
      
      
      <time datetime="2024-05-25T09:10:28+02:00">
         05-25-2024
      </time>
      
      
      
      
    </div>
  </div>
</div>
<div id="readPostContent" style="text-align:center"><a class="btn btn-middle" onclick="readPostContent(this)">
    
    
    
    
    
    
    Read article aloud
    
    
    
  </a></div>
<div class="content-box">
  <article class="post">

    <div class="post-content">
      <p>The creation of a chatbot for a website is a task that is usually contracted to a service provider, but in this case I will tell you how it can be done from start to finish and also with a set of tools that are free and free.</p>

<h1 id="creation-of-a-chatbot-with-an-opensource-model">Creation of a chatbot with an opensource model</h1>

<p>Chatbots are software applications that emerged in the 1960s that simulate having a conversation with a person by providing automatic responses, which are previously established by a set of experts to inputs made by the user. These bot, also known as expert systems, use case-based reasoning (CBR).</p>

<p>Typically, the conversation is text-based, although there are also models with a multimedia user interface that allow for auditory input. More recently, some are starting to use text-to-speech (CTV) software, making the interaction with the user more realistic and helping to reduce response time.</p>

<p>In order to establish a conversation, easily understandable and coherent sentences have to be used, although most conversational bot do not fully understand. Instead, they take into account the speaker’s words or phrases, which will allow them to use a set of pre-prepared responses. They are able to recognise the way in which a sentence is formulated thanks to a series of pre-established comparative patterns, and thus, based on the different variables of that sentence, they present a corresponding response. In this way, the bot is able to follow a conversation with more or less logic, but without really knowing what it is talking about.</p>

<blockquote>
  <p>For more information I recommend you to visit the following <a href="https://en.wikipedia.org/wiki/Chatbot">article</a> from wikipedia from where this fragment has been obtained.</p>
</blockquote>

<h1 id="what-is-retrieval-augmented-generation-rag">¿What is Retrieval-Augmented Generation (RAG)?</h1>

<p>It is the knowledge augmentation that is applied to a data-driven LLM that has not been trained. This allows the generative AI system to provide contextually appropriate answers to queries, as well as to base those answers on extremely recent data.</p>

<p>In short, RAG helps LLMs to provide more suitable answers.</p>

<p><strong>Key findings</strong></p>

<ul>
  <li>RAG is a relatively new artificial intelligence technique that improves the quality of generative AI by allowing large language models (LLMs) to leverage additional data resources without the need for retraining</li>
  <li>RAG models create repositories of knowledge based on the organisation’s own data. These repositories can be continuously updated to help generative AI provide context-aware and timely responses</li>
  <li>Chatbots and other conversational systems that use natural language processing can benefit greatly from RAG and generative AI</li>
  <li>Implementing RAG requires technologies such as vector databases, which enable rapid encoding of new data and searching on that data to feed the LLM</li>
</ul>

<h2 id="how-does-it-work">How does it work?</h2>

<p>The data from this knowledge library is processed into numerical representations using a special type of algorithm called an embedded language model and stored in a vector database, which can be quickly searched to retrieve the correct contextual information.</p>

<blockquote>
  <p>For more information I recommend you to visit the following <a href="https://www.oracle.com/artificial-intelligence/generative-ai/retrieval-augmented-generation-rag/">article</a> from Oracle where this excerpt is taken from.</p>
</blockquote>

<h1 id="architecture">Architecture</h1>

<p><img src="/images/pages/ollama_api_arquitectura.jpg" alt="Architecture" title="Ollama API Architecture" /></p>

<p>We are going to run our LLM model on a local server. We will also have the possibility to change model from a friendly administration interface, which allows us to download the model we want to use and even to test it in advance. For this reason, I have chosen <a href="https://ollama.com/">Ollama</a>, which has a very interesting opensource <a href="https://ollama.com/library">set of models</a>. We are going to see step by step how to install and configure our software.</p>

<p>But first of all, let’s see a brief description of each of the elements that we are going to install:</p>

<h2 id="ollama">Ollama</h2>

<p>Ollama makes it very easy to run open source LLM locally. You can expect decent performance even on small laptops. Ollama is an alternative to Hugging Face for running models locally. Hugging Face libraries run on top of Tensorflow or Torch. Ollama uses llama.cpp as the underlying runtime. This makes it very easy to get started with Ollama. You don’t even need to have Python installed.</p>

<h2 id="langchain">LangChain</h2>

<p>LangChain is an open source framework for building applications based on large language models (LLMs). LLMs are large deep learning models pre-trained on large amounts of data that can generate answers to user queries, for example, answering questions or creating images from text-based requests. LangChain provides tools and abstractions to improve the personalisation, accuracy and relevance of the information generated by the models. For example, developers can use LangChain components to create new request strings or customise existing templates. LangChain also includes components that allow LLMs to access new datasets without the need for retraining.</p>

<blockquote>
  <p>For more information, I recommend you visit the following AWS <a href="https://aws.amazon.com/what-is/langchain/">article</a> from which this excerpt is taken.</p>
</blockquote>

<h2 id="chromadb">ChromaDb</h2>

<p>ChromaDB is a database specialising in the efficient storage and retrieval of linguistic information, including text data, semantic and syntactic annotations. ChromaDB is particularly useful for storing and managing large amounts of natural language data, allowing developers to take full advantage of advances in machine learning algorithms and text analysis.</p>

<blockquote>
  <p>For more information, I recommend you visit the following <a href="https://brainq.ai/chromadb/">article</a> from which this excerpt was obtained.</p>
</blockquote>

<h2 id="api-with-flask">API with Flask</h2>

<p>Flask is a Python micro web framework that provides the necessary tools to create web applications quickly and easily. Although it is a micro framework, Flask is highly modular and allows you to easily add extensions to add additional functionality.</p>

<blockquote>
  <p>For more information I recommend you to visit the following <a href="https://datascientest.com/es/programacion-de-api-web-en-python-con-flask">article</a> from where this snippet has been obtained and where you can follow the detailed tutorial on how to create an API with Flask.</p>
</blockquote>

<h2 id="the-chatbot-web">The Chatbot web</h2>

<p>I have based myself on this integration of a web chatbot, to use the resources and adapt it to our opensource model hosted by Ollama.</p>

<p>The source code can be found <a href="https://github.com/galaxyofai/chatgpt_flask_webapp">here</a>.</p>

<p>And a detailed explanation of how to integrate it with other APIs can be found <a href="https://galaxyofai.com/building-a-flask-chat-web-app-with-openais-chatgpt-api/">here</a>.</p>

<h1 id="the-demonstration">The demonstration</h1>

<p>The application has been embedded below. It is hosted on a server with very limited characteristics for the execution of artificial intelligence developments. But as a demonstration that it is possible, here it is in operation:</p>

<blockquote>
  <p><img src="/images/pages/aviso_icon.png" alt="Aviso" /> <strong>The chatbot is hosted on a server with few resources</strong><br /><br />This is why it takes a long time to answer. This is precisely what we are looking for, to demonstrate the viability in this type of environment.</p>
</blockquote>

<p>Sample questions you can ask:</p>
<ul>
  <li>What experience does Ruben Arcos have?</li>
  <li>How many years of experience does Ruben Arcos have?</li>
  <li>What programming languages does Ruben Arcos know?</li>
</ul>

<p><em>Click on the purple bubble to open the Chatbot</em>.</p>

<p style="text-align: center">
  <iframe style="border: 0" id="chatbot" title="Chatbot" width="390" height="600" src="https://vps.rarcos.com:10453/">
  </iframe>
</p>

<h1 id="the-tutorial">The tutorial</h1>

<p>As usual in this website, we are going to use a dockerised environment that will be in charge of building Ollama, the Ollama web manager and our ChatBot web application.</p>

<p>For this we have the following <em>docker compose</em> scripts:</p>

<h3 id="more-complete-execution-script-without-gpu">More complete execution script (without GPU)</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>version: '3.8'
services:
  app:
    build: .
    container_name: ollama-app
    ports:
      - 8002:8002
      - 5678:5678
    volumes:
      - ./app:/usr/src/app/
    command: python app.py
    restart: always
    depends_on:
      - ollama
      - ollama-webui
    networks:
      - ollama-docker

  ollama:
    image: ollama/ollama:latest
    ports:
      - 11434:11434
    volumes:
      - .:/code
      - ./ollama/ollama:/root/.ollama
    container_name: ollama
    pull_policy: always
    tty: true
    restart: always
    networks:
      - ollama-docker

  ollama-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: ollama-webui
    volumes:
      - ./ollama/ollama-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
      - 8080:8080
    environment:
      - '/ollama/api=http://ollama:11434/api'
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped
    networks:
      - ollama-docker

networks:
  ollama-docker:
    external: false

</code></pre></div></div>

<h3 id="minimum-script-without-gpu">Minimum script (without GPU)</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>services:

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    tty: true
    restart: unless-stopped
    # Expose Ollama API outside the container stack
    ports:
      - 11434:11434
      - 53:53
    volumes:
      - ollama:/root/.ollama
    command: pip install -r requirements.txt

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    volumes:
      - open-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
      - 8080:8080
    environment:
      - "OLLAMA_API_BASE_URL=http://ollama:11434/api"
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped

volumes:
  ollama: {}
  open-webui: {}
</code></pre></div></div>
<h3 id="the-script-for-gpu-utilisation">The script for GPU utilisation</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>version: '3.8'

services:
  app:
    build: .
    ports:
      - 8000:8000
      - 5678:5678
    volumes:
      - .:/code
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
    restart: always
    depends_on:
      - ollama
      - ollama-webui
    networks:
      - ollama-docker
      
  ollama:
    volumes:
      - ./ollama/ollama:/root/.ollama
    container_name: ollama
    pull_policy: always
    tty: true
    restart: unless-stopped
    image: ollama/ollama:latest
    ports:
      - 11434:11434
    networks:
      - ollama-docker
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  ollama-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: ollama-webui
    volumes:
      - ./ollama/ollama-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
      - 8080:8080
    environment:
      - '/ollama/api=http://ollama:11434/api'
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped
    networks:
      - ollama-docker

networks:
  ollama-docker:
    external: false

</code></pre></div></div>

<p>The access routes that are established are:</p>
<ul>
  <li>Ollama administration web page: <a href="http://localhost:8080">http://localhost:8080</a></li>
  <li>Ollana engine: <a href="http://localhost:11434">http://localhost:11434</a></li>
  <li>Web application: <a href="http://localhost:8002">http://localhost:8002</a></li>
</ul>

<blockquote>
  <p>For more information I recommend you to visit the following <a href="https://github.com/valiantlynx/ollama-docker/">repository</a> from where this script has been obtained and where there are more examples and information.</p>
</blockquote>

<h3 id="the-installation-of-the-model-from-the-ollama-webmaster">The installation of the model from the Ollama webmaster</h3>

<p>Once we have the docker up, we just have to go to the url <a href="http://localhost:8080">http://localhost:8080</a>, download and install the model.</p>

<p>Below is a video of how it is done:</p>

<p><img src="/images/pages/ollama_install.gif" alt="video" /></p>

<p>In our case we will introduce the model: <em>mistral:instruct</em></p>

<h3 id="the-console-application-chatbot">The console application (chatbot)</h3>

<p>Then we have the console application that consumes the LLM model, in our example we have used <em>Mistral</em> for its great performance similar to Llama and for being opensource. We also have the specification of the query promt, with some instructions prior to the queries. And the RAG training method.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langchain_community.vectorstores import Chroma
from langchain_community.chat_models import ChatOllama
from langchain_community.embeddings.fastembed import FastEmbedEmbeddings
from langchain_community.document_loaders import WebBaseLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
import sys
 
class ChatWebDoc:
    vector_store = None
    retriever = None
    chain = None
 
    def __init__(self):
        self.model = ChatOllama(model="mistral:instruct")
        #Loading embedding
        self.embedding = FastEmbedEmbeddings()
 
        self.text_splitter = CharacterTextSplitter(chunk_size=1024, chunk_overlap=100)
        self.prompt = ChatPromptTemplate.from_messages(
        [
            ("system", 
"""You are an assistant for question-answering tasks. Use only the following 
context to answer the question. If you don't know the answer, just say that you don't know.
 
CONTEXT:
 
{context}
"""),
            ("human", "{input}"),
        ]
    )
 
    def ingest(self, url_list):
        #Load web pages
        docs = WebBaseLoader(url_list).load()
        chunks = self.text_splitter.split_documents(docs)
 
        #Create vector store
        vector_store = Chroma.from_documents(documents=chunks, 
            embedding=self.embedding, persist_directory="./chroma_db")
 
    def load(self):
        #Load vector store
        vector_store = Chroma(persist_directory="./chroma_db", 
            embedding_function=self.embedding)
 
        #Create chain
        self.retriever = vector_store.as_retriever(
            search_type="similarity_score_threshold",
            search_kwargs={
                "k": 3,
                "score_threshold": 0.5,
            },
        )
 
        document_chain = create_stuff_documents_chain(self.model, self.prompt)
        self.chain = create_retrieval_chain(self.retriever, document_chain)
 
    def ask(self, query: str):
        if not self.chain:
            self.load()
 
        result = self.chain.invoke({"input": query})
 
        print(result["answer"])
        for doc in result["context"]:
            print("Source: ", doc.metadata["source"])
 
 
def build():
    w = ChatWebDoc()
    w.ingest([
        "https://www.webagesolutions.com/courses/WA3446-comprehensive-angular-programming",
        "https://www.webagesolutions.com/courses/AZ-1005-configuring-azure-virtual-desktop-for-the-enterprise",
        "https://www.webagesolutions.com/courses/AZ-305T00-designing-microsoft-azure-infrastructure-solutions",
        ])
 
def chat():
    w = ChatWebDoc()
 
    w.load()
 
    while True:
        query = input("&gt;&gt;&gt; ")
 
        if len(query) == 0:
            continue
 
        if query == "/exit":
            break
         
        w.ask(query)
 
if len(sys.argv) &lt; 2:
    chat()
elif sys.argv[1] == "--ingest":
    build()
</code></pre></div></div>

<p>The execution of the RAG training of the webs provided in the previous programme is done with the command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python rag-test.py --ingest
</code></pre></div></div>

<p>Interaction with the model once trained:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python rag-test.py
</code></pre></div></div>

<blockquote>
  <p>I recommend taking a closer look at this <a href="https://mobiarch.wordpress.com/2024/02/19/run-rag-locally-using-mistral-ollama-and-langchain/">web page</a> where this same application is discussed.</p>
</blockquote>

<h2 id="the-web-application-the-chatbot">The web application (the Chatbot)</h2>

<p>It remains for a future update of the article to show you how to integrate the LLM engine into the web application, interact with it, train it with the RAG method and upload it to the web server - see you soon! 😉</p>

<hr />

<p><strong>Sources:</strong></p>

<ul>
  <li><a href="https://github.com/valiantlynx/ollama-docker/">https://github.com/valiantlynx/ollama-docker</a></li>
  <li><a href="https://mobiarch.wordpress.com/2024/02/19/run-rag-locally-using-mistral-ollama-and-langchain/">https://mobiarch.wordpress.com/2024/02/19/run-rag-locally-using-mistral-ollama-and-langchain/</a></li>
  <li><a href="https://realpython.com/build-llm-rag-chatbot-with-langchain/">https://realpython.com/build-llm-rag-chatbot-with-langchain/</a></li>
</ul>

    </div>

    <footer class="post-footer">
      
      
      
      
      
      
      <p>
      <h3>Content License</h3>

      <p><img src="/images/pages/88x311.png" /></p>

      <p>This web page, all content with proyects and source code, is licensed under Creative Commons:
        Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) <a
          href="https://creativecommons.org/licenses/by-nc-nd/4.0/">More info</a></p>

      </p>
      
      
      

      <ul class="post-footer-list">
        <li class="post-footer-item">
          <a class="post-facebook"
            href="https://www.facebook.com/sharer/sharer.php?u=https://rarcos.com/2024/05/25/Ollama_api_chatbot/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Facebook" rel="nofollow"><i class="fa-brands fa-facebook"
              aria-hidden="true"></i><span>Facebook</span></a>
        </li>

        <li class="post-footer-item">
          <a class="post-twitter"
            href="https://twitter.com/intent/tweet?text=Opensource%20Chatbot&url=https://rarcos.com/2024/05/25/Ollama_api_chatbot/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Twitter" rel="nofollow"><i class="fa-brands fa-x-twitter"
              aria-hidden="true"></i><span>Twitter</span></a>
        </li>

        <li class="post-footer-item">
          <a href="http://pinterest.com/pin/create/button/?url=https://rarcos.com/2024/05/25/Ollama_api_chatbot/&amp;media=https://rarcos.com/images/pages/ollama_api.jpg&amp;description=Opensource%20Chatbot"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;"
            class="post-pinterest" title="Share on Pinterest" rel="nofollow"><i class="fa-brands fa-pinterest"
              aria-hidden="true"></i><span>Pinterest</span></a>
        </li>

        <li class="post-footer-item">
          <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://rarcos.com/2024/05/25/Ollama_api_chatbot/&title=Opensource%20Chatbot"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;"
            class="post-linkedin" title="Share on Linkedin" rel="nofollow"><i class="fa-brands fa-linkedin"
              aria-hidden="true"></i><span>Linkedin</span></a>
        </li>
      </ul>
      
      <div class="post-tag">
        <span>Tags:</span>
        
        <a href="/tags#ai" class="tag">ai</a>
        
        <a href="/tags#rag" class="tag">rag</a>
        
        <a href="/tags#open source" class="tag">open source</a>
        
        <a href="/tags#models" class="tag">models</a>
        
        <a href="/tags#chatbot" class="tag">chatbot</a>
        
      </div>
      
    </footer>

    
    <div class="post-author">
      
      <div class="post-author-image">
        <a style="background-image: url(/images/ruben.jpg)">
          <span class="screen-reader-text">Rubén Arcos Picture</span>
        </a>
      </div>
      <div class="post-author-info">
        <h4>Rubén Arcos</h4>
        <p class="post-author-bio">
          
          
          
          
          
          
          IT Developer. <br>Higher Education Master in AI and Big Data, <br>Higher Technician in Web Applications Development and <br>Higher Technician in Multiplatform Applications Development.
          
          
          
        </p>
        <div class="post-author-meta">
          
          <a href="https://twitter.com/rarcosdev" target="_blank"><i class="fa-brands fa-x-twitter" aria-hidden="true"></i></a>
          
          
          <a href="https://linkedin.com/in/rubenarcos2" target="_blank"><i class="fa-brands fa-linkedin" aria-hidden="true"></i></a>
          
          
          <a href="https://github.com/rubenarcos2" target="_blank"><i class="fa-brands fa-github" aria-hidden="true"></i></a>
          
          
          
          
          
          
          
          
          
        </div>
      </div>
      
    </div>

    <div class="page-navigation clearfix">
      
      <a class="prev-page" href="/2024/05/25/RAG_modelos_open_source/"><i class="fa fa-angle-left"
          aria-hidden="true"></i><span>RAG with open source AI models</span></a>
      
      
    </div>

    
  </article> <!-- /.post -->

</div> <!-- /.content-box -->

    <div class="top" title="Scroll To Top">
  <i class="fa fa-chevron-up" aria-hidden="true"></i>
</div> <!-- /.top -->
    <footer class="site-footer">

  <div class="footer-wrapper">

    <h2 class="footer-heading">Rubén Arcos</h2>

    <ul class="social-footer">
    
      <li><a href="https://twitter.com/rarcosdev" target="_blank"><i class="fa-brands fa-x-twitter" aria-hidden="true"></i></a></li>
    
    
    
    
    <li><a href="https://linkedin.com/in/rubenarcos2" target="_blank"><i class="fa-brands fa-linkedin" aria-hidden="true"></i></a></li>
    
    
    <li><a href="https://github.com/rubenarcos2" target="_blank"><i class="fa-brands fa-github" aria-hidden="true"></i></a></li>
    
    
    
    
    
    
    
    
    
    </ul>

    <div class="copyright">
      <p><a href="https://jekyllrb.com/">Proudly powered by Jekyll</a> | Theme: Lokmont by <a href="https://artemsheludko.github.io/">Artem Sheludko</a> | Modifications: <a href="https://github.com/rubenarcos2">Rubén Arcos</a></p>
    </div>
  </div>

</footer> <!-- /.site-footer -->

  </div> <!-- /.full-page-container -->

  <script src="/js/jquery-3.7.1.min.js"></script>
<script src="/js/jquery.viewportchecker.min.js"></script>
<script src="/js/jquery.fitvids.js"></script>
<script src="/js/simple-jekyll-search.min.js"></script>
<script src="/js/transition.js"></script>
<script src="/js/zoom.min.js"></script>
<script src="/js/main.js"></script>
</body>

</html>