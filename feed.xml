<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://rarcos.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://rarcos.com/" rel="alternate" type="text/html" /><updated>2025-03-15T20:39:44+01:00</updated><id>https://rarcos.com/feed.xml</id><title type="html">Rubén Arcos</title><subtitle>FullStack, AI &amp; Big Data developer</subtitle><entry xml:lang="en"><title type="html">Spring AI, Kafka, RAG and microservices</title><link href="https://rarcos.com/2025/02/12/GMCCA_microservices/" rel="alternate" type="text/html" title="Spring AI, Kafka, RAG and microservices" /><published>2025-02-12T19:00:00+01:00</published><updated>2025-02-12T19:00:00+01:00</updated><id>https://rarcos.com/2025/02/12/GMCCA_microservices</id><content type="html" xml:base="https://rarcos.com/2025/02/12/GMCCA_microservices/"><![CDATA[<p style="text-align: justify">
I have made an application based on microservices that allows the consultation of documentation of a product (for example the instruction manual in PDF) in order to obtain information through a chatbot. It uses the following technology:
</p>

<ul>
  <li>Data model: <em>mxbai-embed-large</em>, text extraction and <em>ALIA</em> for chat.</li>
  <li>Ollama as a manager of AI models</li>
  <li>Chatbot opensource</li>
  <li>Frontend: React</li>
  <li>Backend: SpringBoot + Spring AI
    <ul>
      <li>Notification module (Kafka)</li>
      <li>AI module (RAG for PDF extraction and post-query information)</li>
      <li>Inventory module</li>
      <li>Ordering module</li>
      <li>Product module</li>
    </ul>
  </li>
</ul>

<p style="text-align: justify">
Next, we are going to see, in a brief but detailed way, the main technologies used in the project, and finally we will see in detail everything I have done in the project. Communication between modules using Kafka, the use of Kafka as an event trigger, the implementation of Spring AI with connection to Ollama, and the microservices architecture... just to mention some relevant points.
</p>

<h1 id="qué-es-spring-ai">¿Qué es Spring AI?</h1>

<p>Es uno de los proyectos que tiene Spring, y que según su página web, lo definen como:</p>

<blockquote>
  <p>Spring AI es un marco de aplicación para la ingeniería de IA. Su objetivo es aplicar al dominio de la IA los principios de diseño del ecosistema Spring, como la portabilidad y el diseño modular, y promover el uso de POJOs como bloques de construcción de una aplicación para el dominio de la IA.</p>
</blockquote>

<p>+info: <a href="https://spring.io/projects/spring-ai">https://spring.io/projects/spring-ai</a></p>

<p style="text-align: justify">
It is part of the Spring Framework and is designed to make it easy to integrate artificial intelligence functionality into applications without unnecessary complication. Spring AI provides abstractions that allow developers to connect business data and APIs with AI models, making it easier to create applications that use AI.
</p>

<h2 id="features">Features:</h2>

<ul>
  <li>Compatibility with all major AI model vendors, such as Anthropic, OpenAI, Microsoft, Amazon, Google and Ollama.
    <ul>
      <li>Supported model types include:
        <ul>
          <li><a href="https://docs.spring.io/spring-ai/reference/api/chatmodel.html">Chat</a></li>
          <li>Embeddings](https://docs.spring.io/spring-ai/reference/api/embeddings.html)</li>
          <li>Text to image](https://docs.spring.io/spring-ai/reference/api/imageclient.html)</li>
          <li><a href="https://docs.spring.io/spring-ai/reference/api/audio/transcriptions.html">Audio transcription</a></li>
          <li>Text to Speech](https://docs.spring.io/spring-ai/reference/api/audio/speech.html)</li>
          <li>Moderation](https://docs.spring.io/spring-ai/reference/api/index.html#api/moderation)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Supports API support between AI providers for synchronous and streaming API options. Access to model-specific functions is also available.</li>
  <li>Structured outputs : mapping of AI model output to POJO.</li>
  <li>Support for major vector database vendors such as Apache Cassandra, Azure Vector Search, Chroma, Milvus, MongoDB Atlas, Neo4j, Oracle, PostgreSQL/PGVector, PineCone, Qdrant, Redis and Weaviate.</li>
  <li>APIs between vector storage providers, including a novel SQL-like metadata filter API.</li>
  <li>Tool/function call: allows the model to request execution of client-side tools and functions, thus accessing the necessary information in real time as needed.</li>
  <li>Observability : provides information about AI-related operations.</li>
  <li>Document injection ETL framework for data engineering.</li>
  <li>AI model evaluation : utilities to help evaluate generated content and protect against hallucinogenic responses.</li>
  <li>ChatClient API - Fluent API for communicating with AI chat models, idiomatically similar to the WebClient and RestClient APIs.</li>
  <li>Advisor API : Encapsulates recurring generative AI patterns, transforms data sent to and from language models (LLMs) and provides portability between various models and use cases.</li>
  <li>Support for chat conversation memory and augmented generation retrieval (AGR).</li>
  <li>Automatic configuration of Spring Boot and starters for all AI models and vector shops.</li>
</ul>

<h2 id="current-status">Current status</h2>

<p style="text-align: justify">
It is still in version 1.0.0-SNAPSHOT, so it is not yet very standardised and stable. So I do not recommend it for production use, since I myself have had some setbacks and changes during the realization of this project. Although it is true that they are constantly changing and evolving. You can see that they are very committed to the Spring AI project.
</p>

<h2 id="documentation">Documentation</h2>

<p>The most recommended documentation is the official one, because of the above:</p>

<ul>
  <li><a href="https://spring.io/projects/spring-ai">https://spring.io/projects/spring-ai</a></li>
  <li><a href="https://docs.spring.io/spring-ai/reference/index.html">https://docs.spring.io/spring-ai/reference/index.html</a></li>
</ul>

<h1 id="what-is-apache-kafka">What is Apache Kafka?</h1>

<p style="text-align: justify">
It is an open source distributed streaming data platform developed by the Apache Software Foundation. It is used to build real-time data pipelines and streaming data applications. Kafka is highly scalable, fault-tolerant and designed to handle large, real-time data streams. It is popular in large technology companies for real-time data management and analytics.
</p>

<blockquote>
  <p>More than 80% of all Fortune 100 companies trust, and use Kafka.</p>
</blockquote>

<blockquote>
  <p>Apache Kafka is an open-source distributed event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.</p>
</blockquote>

<p>+info: <a href="https://kafka.apache.org/">https://kafka.apache.org/</a></p>

<p style="text-align: justify">
Apache Kafka is the alternative to a traditional enterprise messaging system. It started as an internal system that LinkedIn developed to handle 1.4 billion messages per day. Now, it is an open source data transmission solution to meet a variety of business needs.
</p>

<h2 id="why-is-it-developed">Why is it developed?</h2>

<p style="text-align: justify">
Due to the emergence of microservices architecture in the development world, dependencies are reduced and the shared use of a centralized database is moved to smaller, specific and even modular ones. But methods for sharing data are still required. A popular method is the use of synchronous APIs. However, asynchronous integration, which uses a <b>buffer</b>, offers an efficient alternative.
</p>

<p style="text-align: justify">
Apache Kafka plays a crucial role in transmitting data between development teams to populate this data warehouse, facilitating information sharing. Microservices teams require distributed integrations, APIs, and containers to fit their specific needs. Allowing you to use both synchronous and asynchronous methods as needed.
</p>

<p style="text-align: justify">
Apache Kafka is especially useful for integration based on asynchronous events, which complements the use of synchronous APIs, improves microservices and favors agile integration. This streamlines development, drives innovation, saves time, and accelerates time to market for new features, applications, and services.
</p>

<p>I recommend reading this <a href="https://www.redhat.com/es/topics/integration/what-is-apache-kafka">article</a> published by Red Hat in which they explain the features of Kafka and the needs for which it was developed.</p>

<h1 id="what-is-microservices-architecture">What is microservices architecture?</h1>

<p style="text-align: justify">
Microservices architecture is a software design style that organizes an application as a collection of small autonomous services, each of which runs a single process and communicates through lightweight interfaces, often HTTP APIs or messaging such as Apache Kafka.
</p>

<h2 id="benefits-of-microservices-architecture">Benefits of microservices architecture</h2>

<ol>
  <li>Scalability: Each microservice can scale independently based on its demand. This means that resources only need to be increased for the services that really require it, improving efficiency.</li>
  <li>Flexibility in Development: Different teams can work on different microservices using different technologies and programming languages ​​suitable for each case.</li>
  <li>Resilience: If a microservice fails, it does not necessarily affect the entire application. Other services can continue to function, improving overall system availability.</li>
  <li>Independent Lifecycle: Microservices can be deployed, updated, and scale independently, allowing for more agile development and continuous delivery.</li>
  <li>Ease of Maintainability: Due to their small size, microservices are easier to understand, test and maintain. Errors are located and resolved faster.</li>
  <li>Rapid Innovation: Small units of code allow teams to introduce new features and technologies quickly, encouraging continuous innovation.</li>
</ol>

<p style="text-align: justify">
Microservices architecture is especially advantageous for large applications that require rapid and flexible development and deployment. However, it also introduces challenges, such as managing communication between services and the need for adequate infrastructure for support.
</p>

<hr />

<p>And now that we know what technologies we will work with.</p>

<h1 id="lets-start-the-project">Let’s start the project!</h1>

<h2 id="architecture">Architecture</h2>

<p>This is the architecture that has been used in the microservices project:</p>

<p><img src="/images/pages/gmcca_microservices_architecture.jpg" alt="GMCCA Microservices Architecture" title="GMCCA Microservices architecture" /></p>

<p>The principles of microservices architecture have been taken into account at all times. Maintaining independent databases, favoring their scalability. Performing communications between microservices in an efficient and maintainable way in the life cycle. As well as, the resilience of the project, allowing fault tolerance of the microservices independently.</p>

<h3 id="products-module">Products module</h3>

<p>This module is designed to perform CRUD operations of a product warehouse.</p>

<p>Currently only the methods are implemented: <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_products/src/main/java/com/rarcos/gmcca_products/controller/ProductController.java">addProduct, getAllProducts, getProductByCode and changeStatusProduct</a>.</p>

<p>The data is stored in a PostgreSQL database, for this module.</p>

<h3 id="order-module">Order module</h3>

<p>This module is designed to perform CRUD operations of a product order (with product data, a given price and quantity).</p>

<p>Currently only the methods are implemented: <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_orders/src/main/java/com/rarcos/gmcca_orders/controllers/OrderController.java">placeOrder and getOrders</a>.</p>

<p>The service <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_orders/src/main/java/com/rarcos/gmcca_orders/services/OrderService.java">placeOrder</a>, has the peculiarity, that it performs a check using <a href="https://docs.spring.io/spring-framework/reference/web/webflux-webclient.html">WebClient</a> to the inventory module. This check consists of carrying out a query on the product stock to see if there is availability in the warehouse.
Also, send a notification, through Kafka, to warn that the order has been placed (with its number, number of products and its status).</p>

<p>The data is stored in a PostgreSQL database, for this module.</p>

<h3 id="inventory-module">Inventory module</h3>

<p>This module is designed to perform CRUD operations on a product inventory (with product code data and a given quantity).</p>

<p>Currently only the methods are implemented: <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_inventory/src/main/java/com/rarcos/gmcca_inventory/controllers/InventoryController.java">isInStock and areInStock</a>.</p>

<p>The <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_inventory/src/main/java/com/rarcos/gmcca_inventory/services/InventoryService.java">InventoryService</a> service is responsible for returning the stock for a product code or for a complete order.</p>

<p>The data is stored in a PostgreSQL database, for this module.</p>

<h3 id="notifications-module">Notifications module</h3>

<p>Its main purpose is communication with the Kafka messaging queue and the WebSocket web.</p>

<p>It has two event triggers: for the <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_notifications/src/main/java/com/rarcos/gmcca_notifications/events/DocProcessEvent.java">extraction processing</a> status of the PDF document using AI and for the <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_notifications/src/main/java/com/rarcos/gmcca_notifications/events/OrderEvent.java">order status</a>.</p>

<p>The listeners for: <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_notifications/src/main/java/com/rarcos/gmcca_notifications/listeners/DocProcessEventListener.java">document processing</a> have also been implemented. <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_notifications/src/main/java/com/rarcos/gmcca_notifications/listeners/OrderEventListener.java">order</a> and <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_notifications/src/main/java/com/rarcos/gmcca_notifications/listeners/WebSocketEventListener.java">WebSocket</a>.</p>

<ul>
  <li>handleDocProcessNotifications:</li>
  <li>Emits a notification to the WebSocket with the status of the process that is extracting the text from the PDF document using AI.</li>
  <li>Query a product by its code and change the status of that product depending on whether or not it is available for web viewing. That is, whether or not it has a PDF manual related to the product.</li>
  <li>handleOrdersNotifications:</li>
  <li>Emits a notification to the WebSocket with the status of the order.</li>
  <li>handleWebSocketConnectListener and handleWebSocketDisconnectListener.</li>
</ul>

<h3 id="ai-rag-module">AI-RAG module</h3>

<p>The <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_ia_rag/src/main/java/com/rarcos/gmcca_ia_rag/controllers/DocsController.java">functions</a> performed by this module are:</p>

<ul>
  <li>Extracting text from a PDF document using AI (mxbai-embed-large model)</li>
  <li>Storing said information in a vector database (PGVector)</li>
  <li>Storing the PDF document in a document database (MongoDB)</li>
  <li>Downloading the PDF document (viewer)</li>
  <li>The AI-based chatbot (communicated with Ollama)</li>
</ul>

<h2 id="execution-environment---frontend">Execution environment - Frontend</h2>

<p>The website is <strong>still under development</strong>.</p>

<p>At this time it only has the following functionalities:</p>

<ul>
  <li>Upload/Download PDF documents</li>
  <li>Extract information from the PDF using AI</li>
  <li>Notifications using WebSocket</li>
  <li>​​Access to the chatbot, only through web API (not on the web yet)</li>
  <li>CRUD of products (not on the web yet)</li>
  <li>CRUD of orders (not on the web yet)</li>
</ul>

<p style="text-align: center">
<a href="https://gmcca-microservices.rarcos.com/" target="_blank">
<img src="/images/pages/gesmerca.png" width="100" alt="GMCCA Logo" /> Online demo
</a>
</p>

<hr />

<p><em>Repository with the content</em></p>

<p><a href="https://github.com/rubenarcos2/gmcca_microservices"><img src="/images/pages/repository_small.png" alt="Repository" /></a></p>

<hr />

<p><strong>Sources:</strong></p>

<ul>
  <li><a href="https://spring.io/projects/spring-ai">https://spring.io/projects/spring-ai</a></li>
  <li><a href="https://docs.spring.io/spring-ai/reference/index.html">https://docs.spring.io/spring-ai/reference/index.html</a></li>
  <li><a href="https://kafka.apache.org/">https://kafka.apache.org/</a></li>
  <li><a href="https://www.redhat.com/es/topics/integration/what-is-apache-kafka">https://www.redhat.com/es/topics/integration/what-is-apache-kafka</a></li>
  <li><a href="https://www.youtube.com/playlist?list=PLlYjHWCxjWmAt5hE3OEaemlWkZBZa7w4e">https://www.youtube.com/playlist?list=PLlYjHWCxjWmAt5hE3OEaemlWkZBZa7w4e</a></li>
  <li><a href="https://www.youtube.com/watch?v=q2zTo21PEMU">https://www.youtube.com/watch?v=q2zTo21PEMU</a></li>
  <li><a href="https://www.youtube.com/watch?v=UbbyW5Z1lv8">https://www.youtube.com/watch?v=UbbyW5Z1lv8</a></li>
  <li><a href="https://www.baeldung.com/ops/kafka-docker-setup">https://www.baeldung.com/ops/kafka-docker-setup</a></li>
  <li><a href="https://virendraoswal.com/getting-started-with-spring-ai-and-ollama-a-quick-guide-to-using-microsoft-phi3-language-models">https://virendraoswal.com/getting-started-with-spring-ai-and-ollama-a-quick-guide-to-using-microsoft-phi3-language-models</a></li>
  <li><a href="https://erkanyasun.medium.com/simplifying-file-uploads-in-spring-boot-with-multipartfile-eb8bbef68dfe">https://erkanyasun.medium.com/simplifying-file-uploads-in-spring-boot-with-multipartfile-eb8bbef68dfe</a></li>
  <li><a href="https://github.com/spring-projects/spring-ai/issues/356">https://github.com/spring-projects/spring-ai/issues/356</a></li>
  <li><a href="https://www.baeldung.com/spring-boot-mongodb-upload-file">https://www.baeldung.com/spring-boot-mongodb-upload-file</a></li>
</ul>]]></content><author><name></name></author><category term="ai" /><category term="kafka" /><category term="spring ai" /><category term="rag" /><category term="microservices" /><summary type="html"><![CDATA[AI utilisation for text extraction from documents, with a microservices architecture with inter-module and notification communication via Kafka and an AI chat for querying document information.]]></summary></entry><entry xml:lang="en"><title type="html">ALIA in Ollama (and any external model)</title><link href="https://rarcos.com/2025/01/22/ALIA_on_Ollama/" rel="alternate" type="text/html" title="ALIA in Ollama (and any external model)" /><published>2025-01-22T17:00:00+01:00</published><updated>2025-01-22T17:00:00+01:00</updated><id>https://rarcos.com/2025/01/22/ALIA_on_Ollama</id><content type="html" xml:base="https://rarcos.com/2025/01/22/ALIA_on_Ollama/"><![CDATA[<p>Some time ago, I published an article in which we looked at <a href="https://rarcos.com/2024/05/25/Ollama_api_chatbot/">how to install Ollama and how to create a ChatBot</a> using its services.
Now we are going to see how to create a data model obtained from an external source, as opposed to the models that are already prepared in the <a href="https://ollama.com/library">Ollama library</a>.</p>

<p>In our case we are going to use the ALIA model, the first model in Spanish, which has just been released for use.</p>

<p>First of all, let’s comment on the requirements of the model:</p>

<ul>
  <li>System memory: 76.5 GiB</li>
  <li>Model size: 150 Gb</li>
  <li>Model size converted for ollama: 75.3 GB</li>
</ul>

<p>After that, the first thing we are going to do is to locate the model and proceed to download it:</p>

<h1 id="download-the-alia-model">Download the ALIA model</h1>

<p>In Hugging Face we have the models offered by the Barcelona Supercomputing Center. In our case we are interested in 3 models:</p>

<ul>
  <li><a href="https://huggingface.co/BSC-LT/ALIA-40b">ALIA-40b</a></li>
  <li><a href="https://huggingface.co/BSC-LT/salamandra-7b">Salamandra-7b</a></li>
  <li><a href="https://huggingface.co/BSC-LT/salamandra-2b">Salamandra-2b</a></li>
</ul>

<h2 id="cloning-of-the-alia-repository">Cloning of the ALIA repository</h2>

<p>We open a terminal and in the directory we want to download, we enter:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Make sure you have git-lfs installed (https://git-lfs.com)
git lfs install

git clone https://huggingface.co/BSC-LT/ALIA-40b
</code></pre></div></div>
<h1 id="how-to-create-the-alia-model-in-ollama">How to create the ALIA model in ollama?</h1>

<p>This task may seem complex, but it is not really, it is just a matter of executing 3 commands.</p>

<p>First of all we are going to create a file (inside the directory where we have downloaded the model, together with the downloaded files) called <code class="language-plaintext highlighter-rouge">Modelfile</code> and its content will be the following: <code class="language-plaintext highlighter-rouge">FROM .</code>.</p>

<p>Our directory tree will look like this:</p>

<p><img src="/images/pages/arbol_directorio_alia.png" alt="arbol_alia" /></p>

<h2 id="creation-of-the-model-in-ollama">Creation of the model in Ollama</h2>

<p>To do this, we will run the following command, located in the same folder as above:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ollama create alia40b
</code></pre></div></div>

<p><img src="/images/pages/alia_create_model_process.png" alt="arbol_alia" /></p>

<p>Once finished, we check that the model has been created correctly by looking at the list of installed models:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ollama list
</code></pre></div></div>

<p><img src="/images/pages/alia_list_model.png" alt="arbol_alia" /></p>

<h2 id="running-the-model-in-ollama">Running the model in Ollama</h2>

<p>Finally, let’s run the model so we can interact with it:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ollama run alia40b
</code></pre></div></div>

<p><img src="/images/pages/alia_execute_model.png" alt="arbol_alia" /></p>

<h1 id="ready-to-download-salamander-7b-model">Ready-to-download salamander 7b model</h1>

<p>In the Hugging Face <a href="https://huggingface.co/BSC-LT/salamandra-7b-instruct/discussions/7#67923b3de75ed5c939ae48b49">thread</a> you will find a ready-to-download model of salamander-7b-instruct, with which you can test it directly:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ollama run hdnh2006/salamandra-7b-instruct

</code></pre></div></div>

<hr />

<p><strong>Sources:</strong></p>
<ul>
  <li><a href="https://github.com/ollama/ollama/blob/main/docs/import.md">https://github.com/ollama/ollama/blob/main/docs/import.md</a></li>
  <li><a href="https://huggingface.co/BSC-LT/salamandra-7b-instruct/discussions/7">https://huggingface.co/BSC-LT/salamandra-7b-instruct/discussions/7</a></li>
</ul>]]></content><author><name></name></author><category term="ai" /><category term="rag" /><category term="open source" /><category term="models" /><summary type="html"><![CDATA[We are going to see how to create a data model obtained from an external source, unlike the models that are already prepared in the Ollama library, in our case we will create the ALIA model in Ollama.]]></summary></entry><entry xml:lang="en"><title type="html">ALIA the Spanish AI model</title><link href="https://rarcos.com/2025/01/21/ALIA_a_spanish_model/" rel="alternate" type="text/html" title="ALIA the Spanish AI model" /><published>2025-01-21T07:23:28+01:00</published><updated>2025-01-21T07:23:28+01:00</updated><id>https://rarcos.com/2025/01/21/ALIA_a_spanish_model</id><content type="html" xml:base="https://rarcos.com/2025/01/21/ALIA_a_spanish_model/"><![CDATA[<h1 id="what-is-alia">What is ALIA?</h1>

<p><img src="/images/pages/logo_alia.png" alt="Logo" /></p>

<p style="text-align: justify">
ALIA or also known as 'ALIA-40b' is the new Spanish artificial intelligence model and the first in Europe. ALIA is a large artificial intelligence language model, trained in Spanish, Catalan, Galician and Basque. The project is fully publicly funded.

Several models have been created for its use: ALIA-40b, salamandra-7B and salamandra-2B parameters.
</p>

<h2 id="what-is-an-ai-model-according-to-copilot">What is an AI model (according to copilot)?</h2>

<p style="text-align: justify">
An AI (Artificial Intelligence) model is a system that has been trained to perform specific or general tasks, using advanced data and algorithms. These models can be used for a wide range of applications, such as image recognition, natural language processing and decision making.
</p>

<h2 id="what-is-an-llm-according-to-copilot">What is an LLM (according to copilot)?</h2>

<p style="text-align: justify">
An LLM (Large Language Model) is a specific type of AI model designed to process and generate text. These models are trained on huge amounts of text and use advanced techniques to understand and generate human language in a coherent and contextual manner.
</p>

<h2 id="colab-test-of-the-model-7b">Colab test of the model 7B</h2>
<p>I have done a test to see how it works:</p>

<p><a href="https://colab.research.google.com/drive/1iNebMKb4bR8kLqm52qH22DYcNjbo4ebW"><img src="/images/pages/repository_small_colab.png" alt="Program IA" /></a></p>

<h2 id="what-is-its-architecture">What is its architecture?</h2>

<table>
  <thead>
    <tr>
      <th>Total Parameters</th>
      <th style="text-align: left">40,433,885,184</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Embedding Parameters</td>
      <td style="text-align: left">2,097,152,000</td>
    </tr>
    <tr>
      <td>Layers</td>
      <td style="text-align: left">48</td>
    </tr>
    <tr>
      <td>Hidden size</td>
      <td style="text-align: left">8,192</td>
    </tr>
    <tr>
      <td>Attention heads</td>
      <td style="text-align: left">64</td>
    </tr>
    <tr>
      <td>Context length</td>
      <td style="text-align: left">4,096</td>
    </tr>
    <tr>
      <td>Vocabulary size</td>
      <td style="text-align: left">256,000</td>
    </tr>
    <tr>
      <td>Precision</td>
      <td style="text-align: left">bfloat16</td>
    </tr>
    <tr>
      <td>Embedding type</td>
      <td style="text-align: left">RoPE</td>
    </tr>
    <tr>
      <td>Activation Function</td>
      <td style="text-align: left">SwiGLU</td>
    </tr>
    <tr>
      <td>Layer normalization</td>
      <td style="text-align: left">RMS Norm</td>
    </tr>
    <tr>
      <td>Flash attention</td>
      <td style="text-align: left">✅</td>
    </tr>
    <tr>
      <td>Grouped Query Attention</td>
      <td style="text-align: left">✅</td>
    </tr>
    <tr>
      <td>Num. query groups</td>
      <td style="text-align: left">8</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h2 id="what-has-it-been-trained-with">What has it been trained with?</h2>

<p>Pre-training was performed using NVIDIA’s NeMo Framework, which leverages PyTorch Lightning for efficient model training in highly distributed environments.</p>

<p>Instruction-optimised versions were produced with FastChat.</p>

<h3 id="data">Data</h3>
<h4 id="pre-training-data">Pre-training data</h4>

<p style="text-align: justify">
The pre-training corpus comprises data from 35 European languages and 92 programming languages, with detailed data sources provided below. The initial 1.5 training epochs used 2.4 trillion tokens, obtained by manually adjusting data proportion to balance the representation and give more importance to Spain’s co-official (Spanish, Catalan, Galician, and Basque). This way, we downsampled code and English data to half, Spanish co-official languages were oversampled by 2x, and the remaining languages were kept in their original proportions. Following, during the following epochs (still training), the Colossal OSCAR dataset was replaced with the FineWebEdu dataset. This adjustment resulted in a total of 2.68 trillion tokens, distributed as outlined below:
</p>

<p>
<img src="/images/pages/images_corpus_languages_alia.png" />
</p>

<p style="text-align: justify">
The pretraining corpus is predominantly composed of data from Colossal OSCAR, which contributes a significant 53,05% of the total tokens. Following this, Starcoder provides 13,67%, and FineWebEdu (350B tokens subset) adds 10,24%. The next largest sources are HPLT at 4,21% and French-PD at 3,59%. Other notable contributions include MaCoCu, Legal-ES, and EurLex, each contributing around 1.72% to 1.41%. These major sources collectively form the bulk of the corpus, ensuring a rich and diverse dataset for training the language model. The remaining 10% comes from smaller sources in various languages.
</p>

<h3 id="computing-infrastructure">Computing infrastructure</h3>

<p>All models were trained on MareNostrum 5, a pre-exascale EuroHPC supercomputer hosted and operated by the Barcelona Supercomputing Center.</p>

<p>The accelerated partition is composed of 1,120 nodes with the following specifications:</p>

<ul>
  <li>4 Nvidia Hopper GPUs with 64 GB HBM2 memory.</li>
  <li>2 Intel Sapphire Rapids 8460Y+ processors at 2.3 GHz and 32 c each (64 cores)</li>
  <li>4x NDR200 (BW per node 800 Gb/s)</li>
  <li>512 GB main memory (DDR5)</li>
  <li>460 GB NVMe storage</li>
</ul>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Nodes</th>
      <th>GPUs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2B</td>
      <td>64</td>
      <td>256</td>
    </tr>
    <tr>
      <td>7B</td>
      <td>128</td>
      <td>512</td>
    </tr>
    <tr>
      <td>40B</td>
      <td>256 / 512</td>
      <td>1.024 / 2.048</td>
    </tr>
  </tbody>
</table>

<hr />

<p>Links of interest:</p>

<ul>
  <li><a href="https://alia.gob.es/">Official website</a>.</li>
  <li><a href="https://langtech-bsc.gitbook.io/alia-kit/modelos/modelos-de-texto">All the text models</a></li>
  <li><a href="https://langtech-bsc.gitbook.io/alia-kit/modelos/modelos-de-traduccion-automatica">All translation models</a></li>
  <li><a href="https://huggingface.co/spaces/BSC-LT/SalamandraTA-2B-Demo">A translation demonstration</a></li>
</ul>

<p>More information:</p>
<ul>
  <li><a href="https://www.rtve.es/noticias/20250120/alia-familia-modelos-inteligencia-artificial-pedro-sanchez/16414386.shtml">https://www.rtve.es/noticias/20250120/alia-familia-modelos-inteligencia-artificial-pedro-sanchez/16414386.shtml</a></li>
  <li><a href="https://www.xataka.com/robotica-e-ia/pedro-sanchez-anuncia-lanzamiento-primeros-modelos-alia-asi-ia-publica-abierta-que-impulsa-estado">https://www.xataka.com/robotica-e-ia/pedro-sanchez-anuncia-lanzamiento-primeros-modelos-alia-asi-ia-publica-abierta-que-impulsa-estado</a></li>
</ul>]]></content><author><name></name></author><category term="ai" /><category term="rag" /><category term="open source" /><category term="models" /><summary type="html"><![CDATA[Transformer-based decoder-only language model that has been pre-trained from scratch on 6.9 trillion tokens of highly curated data. The pre-training corpus contains text in 35 European languages and code.]]></summary></entry><entry xml:lang="en"><title type="html">Opensource Chatbot</title><link href="https://rarcos.com/2024/05/25/Ollama_api_chatbot/" rel="alternate" type="text/html" title="Opensource Chatbot" /><published>2024-05-25T09:10:28+02:00</published><updated>2024-05-25T09:10:28+02:00</updated><id>https://rarcos.com/2024/05/25/Ollama_api_chatbot</id><content type="html" xml:base="https://rarcos.com/2024/05/25/Ollama_api_chatbot/"><![CDATA[<p>The creation of a chatbot for a website is a task that is usually contracted to a service provider, but in this case I will tell you how it can be done from start to finish and also with a set of tools that are free and free.</p>

<h1 id="creation-of-a-chatbot-with-an-opensource-model">Creation of a chatbot with an opensource model</h1>

<p>Chatbots are software applications that emerged in the 1960s that simulate having a conversation with a person by providing automatic responses, which are previously established by a set of experts to inputs made by the user. These bot, also known as expert systems, use case-based reasoning (CBR).</p>

<p>Typically, the conversation is text-based, although there are also models with a multimedia user interface that allow for auditory input. More recently, some are starting to use text-to-speech (CTV) software, making the interaction with the user more realistic and helping to reduce response time.</p>

<p>In order to establish a conversation, easily understandable and coherent sentences have to be used, although most conversational bot do not fully understand. Instead, they take into account the speaker’s words or phrases, which will allow them to use a set of pre-prepared responses. They are able to recognise the way in which a sentence is formulated thanks to a series of pre-established comparative patterns, and thus, based on the different variables of that sentence, they present a corresponding response. In this way, the bot is able to follow a conversation with more or less logic, but without really knowing what it is talking about.</p>

<blockquote>
  <p>For more information I recommend you to visit the following <a href="https://en.wikipedia.org/wiki/Chatbot">article</a> from wikipedia from where this fragment has been obtained.</p>
</blockquote>

<h1 id="what-is-retrieval-augmented-generation-rag">¿What is Retrieval-Augmented Generation (RAG)?</h1>

<p>It is the knowledge augmentation that is applied to a data-driven LLM that has not been trained. This allows the generative AI system to provide contextually appropriate answers to queries, as well as to base those answers on extremely recent data.</p>

<p>In short, RAG helps LLMs to provide more suitable answers.</p>

<p><strong>Key findings</strong></p>

<ul>
  <li>RAG is a relatively new artificial intelligence technique that improves the quality of generative AI by allowing large language models (LLMs) to leverage additional data resources without the need for retraining</li>
  <li>RAG models create repositories of knowledge based on the organisation’s own data. These repositories can be continuously updated to help generative AI provide context-aware and timely responses</li>
  <li>Chatbots and other conversational systems that use natural language processing can benefit greatly from RAG and generative AI</li>
  <li>Implementing RAG requires technologies such as vector databases, which enable rapid encoding of new data and searching on that data to feed the LLM</li>
</ul>

<h2 id="how-does-it-work">How does it work?</h2>

<p>The data from this knowledge library is processed into numerical representations using a special type of algorithm called an embedded language model and stored in a vector database, which can be quickly searched to retrieve the correct contextual information.</p>

<blockquote>
  <p>For more information I recommend you to visit the following <a href="https://www.oracle.com/artificial-intelligence/generative-ai/retrieval-augmented-generation-rag/">article</a> from Oracle where this excerpt is taken from.</p>
</blockquote>

<h1 id="architecture">Architecture</h1>

<p><img src="/images/pages/ollama_api_arquitectura.jpg" alt="Architecture" title="Ollama API Architecture" /></p>

<p>We are going to run our LLM model on a local server. We will also have the possibility to change model from a friendly administration interface, which allows us to download the model we want to use and even to test it in advance. For this reason, I have chosen <a href="https://ollama.com/">Ollama</a>, which has a very interesting opensource <a href="https://ollama.com/library">set of models</a>. We are going to see step by step how to install and configure our software.</p>

<p>But first of all, let’s see a brief description of each of the elements that we are going to install:</p>

<h2 id="ollama">Ollama</h2>

<p>Ollama makes it very easy to run open source LLM locally. You can expect decent performance even on small laptops. Ollama is an alternative to Hugging Face for running models locally. Hugging Face libraries run on top of Tensorflow or Torch. Ollama uses llama.cpp as the underlying runtime. This makes it very easy to get started with Ollama. You don’t even need to have Python installed.</p>

<h2 id="langchain">LangChain</h2>

<p>LangChain is an open source framework for building applications based on large language models (LLMs). LLMs are large deep learning models pre-trained on large amounts of data that can generate answers to user queries, for example, answering questions or creating images from text-based requests. LangChain provides tools and abstractions to improve the personalisation, accuracy and relevance of the information generated by the models. For example, developers can use LangChain components to create new request strings or customise existing templates. LangChain also includes components that allow LLMs to access new datasets without the need for retraining.</p>

<blockquote>
  <p>For more information, I recommend you visit the following AWS <a href="https://aws.amazon.com/what-is/langchain/">article</a> from which this excerpt is taken.</p>
</blockquote>

<h2 id="chromadb">ChromaDb</h2>

<p>ChromaDB is a database specialising in the efficient storage and retrieval of linguistic information, including text data, semantic and syntactic annotations. ChromaDB is particularly useful for storing and managing large amounts of natural language data, allowing developers to take full advantage of advances in machine learning algorithms and text analysis.</p>

<blockquote>
  <p>For more information, I recommend you visit the following <a href="https://brainq.ai/chromadb/">article</a> from which this excerpt was obtained.</p>
</blockquote>

<h2 id="api-with-flask">API with Flask</h2>

<p>Flask is a Python micro web framework that provides the necessary tools to create web applications quickly and easily. Although it is a micro framework, Flask is highly modular and allows you to easily add extensions to add additional functionality.</p>

<blockquote>
  <p>For more information I recommend you to visit the following <a href="https://datascientest.com/es/programacion-de-api-web-en-python-con-flask">article</a> from where this snippet has been obtained and where you can follow the detailed tutorial on how to create an API with Flask.</p>
</blockquote>

<h2 id="the-chatbot-web">The Chatbot web</h2>

<p>I have based myself on this integration of a web chatbot, to use the resources and adapt it to our opensource model hosted by Ollama.</p>

<p>The source code can be found <a href="https://github.com/galaxyofai/chatgpt_flask_webapp">here</a>.</p>

<p>And a detailed explanation of how to integrate it with other APIs can be found <a href="https://galaxyofai.com/building-a-flask-chat-web-app-with-openais-chatgpt-api/">here</a>.</p>

<h1 id="the-demonstration">The demonstration</h1>

<p>The application has been embedded below. It is hosted on a server with very limited characteristics for the execution of artificial intelligence developments. But as a demonstration that it is possible, here it is in operation:</p>

<blockquote>
  <p><img src="/images/pages/aviso_icon.png" alt="Aviso" /> <strong>The chatbot is hosted on a server with few resources</strong><br /><br />This is why it takes a long time to answer. This is precisely what we are looking for, to demonstrate the viability in this type of environment.</p>
</blockquote>

<p>Sample questions you can ask:</p>
<ul>
  <li>What experience does Ruben Arcos have?</li>
  <li>How many years of experience does Ruben Arcos have?</li>
  <li>What programming languages does Ruben Arcos know?</li>
</ul>

<p><em>Click on the purple bubble to open the Chatbot</em>.</p>

<p style="text-align: center">
  <iframe style="border: 0" id="chatbot" title="Chatbot" width="390" height="600" src="https://chat.rarcos.com/">
  </iframe>
</p>

<h1 id="the-tutorial">The tutorial</h1>

<p>As usual in this website, we are going to use a dockerised environment that will be in charge of building Ollama, the Ollama web manager and our ChatBot web application.</p>

<p>For this we have the following <em>docker compose</em> scripts:</p>

<h3 id="more-complete-execution-script-without-gpu">More complete execution script (without GPU)</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>version: '3.8'
services:
  app:
    build: .
    container_name: ollama-app
    ports:
      - 8002:8002
      - 5678:5678
    volumes:
      - ./app:/usr/src/app/
    command: python app.py
    restart: always
    depends_on:
      - ollama
      - ollama-webui
    networks:
      - ollama-docker

  ollama:
    image: ollama/ollama:latest
    ports:
      - 11434:11434
    volumes:
      - .:/code
      - ./ollama/ollama:/root/.ollama
    container_name: ollama
    pull_policy: always
    tty: true
    restart: always
    networks:
      - ollama-docker

  ollama-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: ollama-webui
    volumes:
      - ./ollama/ollama-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
      - 8080:8080
    environment:
      - '/ollama/api=http://ollama:11434/api'
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped
    networks:
      - ollama-docker

networks:
  ollama-docker:
    external: false

</code></pre></div></div>

<h3 id="minimum-script-without-gpu">Minimum script (without GPU)</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>services:

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    tty: true
    restart: unless-stopped
    # Expose Ollama API outside the container stack
    ports:
      - 11434:11434
      - 53:53
    volumes:
      - ollama:/root/.ollama
    command: pip install -r requirements.txt

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    volumes:
      - open-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
      - 8080:8080
    environment:
      - "OLLAMA_API_BASE_URL=http://ollama:11434/api"
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped

volumes:
  ollama: {}
  open-webui: {}
</code></pre></div></div>
<h3 id="the-script-for-gpu-utilisation">The script for GPU utilisation</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>version: '3.8'

services:
  app:
    build: .
    ports:
      - 8000:8000
      - 5678:5678
    volumes:
      - .:/code
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
    restart: always
    depends_on:
      - ollama
      - ollama-webui
    networks:
      - ollama-docker
      
  ollama:
    volumes:
      - ./ollama/ollama:/root/.ollama
    container_name: ollama
    pull_policy: always
    tty: true
    restart: unless-stopped
    image: ollama/ollama:latest
    ports:
      - 11434:11434
    networks:
      - ollama-docker
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  ollama-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: ollama-webui
    volumes:
      - ./ollama/ollama-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
      - 8080:8080
    environment:
      - '/ollama/api=http://ollama:11434/api'
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped
    networks:
      - ollama-docker

networks:
  ollama-docker:
    external: false

</code></pre></div></div>

<p>The access routes that are established are:</p>
<ul>
  <li>Ollama administration web page: <a href="http://localhost:8080">http://localhost:8080</a></li>
  <li>Ollana engine: <a href="http://localhost:11434">http://localhost:11434</a></li>
  <li>Web application: <a href="http://localhost:8002">http://localhost:8002</a></li>
</ul>

<blockquote>
  <p>For more information I recommend you to visit the following <a href="https://github.com/valiantlynx/ollama-docker/">repository</a> from where this script has been obtained and where there are more examples and information.</p>
</blockquote>

<h3 id="the-installation-of-the-model-from-the-ollama-webmaster">The installation of the model from the Ollama webmaster</h3>

<p>Once we have the docker up, we just have to go to the url <a href="http://localhost:8080">http://localhost:8080</a>, download and install the model.</p>

<p>Below is a video of how it is done:</p>

<p><img src="/images/pages/ollama_install.gif" alt="video" /></p>

<p>In our case we will introduce the model: <em>mistral:instruct</em></p>

<h3 id="the-console-application-chatbot">The console application (chatbot)</h3>

<p>Then we have the console application that consumes the LLM model, in our example we have used <em>Mistral</em> for its great performance similar to Llama and for being opensource. We also have the specification of the query promt, with some instructions prior to the queries. And the RAG training method.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langchain_community.vectorstores import Chroma
from langchain_community.chat_models import ChatOllama
from langchain_community.embeddings.fastembed import FastEmbedEmbeddings
from langchain_community.document_loaders import WebBaseLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
import sys
 
class ChatWebDoc:
    vector_store = None
    retriever = None
    chain = None
 
    def __init__(self):
        self.model = ChatOllama(model="mistral:instruct")
        #Loading embedding
        self.embedding = FastEmbedEmbeddings()
 
        self.text_splitter = CharacterTextSplitter(chunk_size=1024, chunk_overlap=100)
        self.prompt = ChatPromptTemplate.from_messages(
        [
            ("system", 
"""You are an assistant for question-answering tasks. Use only the following 
context to answer the question. If you don't know the answer, just say that you don't know.
 
CONTEXT:
 
{context}
"""),
            ("human", "{input}"),
        ]
    )
 
    def ingest(self, url_list):
        #Load web pages
        docs = WebBaseLoader(url_list).load()
        chunks = self.text_splitter.split_documents(docs)
 
        #Create vector store
        vector_store = Chroma.from_documents(documents=chunks, 
            embedding=self.embedding, persist_directory="./chroma_db")
 
    def load(self):
        #Load vector store
        vector_store = Chroma(persist_directory="./chroma_db", 
            embedding_function=self.embedding)
 
        #Create chain
        self.retriever = vector_store.as_retriever(
            search_type="similarity_score_threshold",
            search_kwargs={
                "k": 3,
                "score_threshold": 0.5,
            },
        )
 
        document_chain = create_stuff_documents_chain(self.model, self.prompt)
        self.chain = create_retrieval_chain(self.retriever, document_chain)
 
    def ask(self, query: str):
        if not self.chain:
            self.load()
 
        result = self.chain.invoke({"input": query})
 
        print(result["answer"])
        for doc in result["context"]:
            print("Source: ", doc.metadata["source"])
 
 
def build():
    w = ChatWebDoc()
    w.ingest([
        "https://www.webagesolutions.com/courses/WA3446-comprehensive-angular-programming",
        "https://www.webagesolutions.com/courses/AZ-1005-configuring-azure-virtual-desktop-for-the-enterprise",
        "https://www.webagesolutions.com/courses/AZ-305T00-designing-microsoft-azure-infrastructure-solutions",
        ])
 
def chat():
    w = ChatWebDoc()
 
    w.load()
 
    while True:
        query = input("&gt;&gt;&gt; ")
 
        if len(query) == 0:
            continue
 
        if query == "/exit":
            break
         
        w.ask(query)
 
if len(sys.argv) &lt; 2:
    chat()
elif sys.argv[1] == "--ingest":
    build()
</code></pre></div></div>

<p>The execution of the RAG training of the webs provided in the previous programme is done with the command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python rag-test.py --ingest
</code></pre></div></div>

<p>Interaction with the model once trained:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python rag-test.py
</code></pre></div></div>

<blockquote>
  <p>I recommend taking a closer look at this <a href="https://mobiarch.wordpress.com/2024/02/19/run-rag-locally-using-mistral-ollama-and-langchain/">web page</a> where this same application is discussed.</p>
</blockquote>

<h2 id="the-web-application-the-chatbot">The web application (the Chatbot)</h2>

<p>It remains for a future update of the article to show you how to integrate the LLM engine into the web application, interact with it, train it with the RAG method and upload it to the web server - see you soon! 😉</p>

<hr />

<p><strong>Sources:</strong></p>

<ul>
  <li><a href="https://github.com/valiantlynx/ollama-docker/">https://github.com/valiantlynx/ollama-docker</a></li>
  <li><a href="https://mobiarch.wordpress.com/2024/02/19/run-rag-locally-using-mistral-ollama-and-langchain/">https://mobiarch.wordpress.com/2024/02/19/run-rag-locally-using-mistral-ollama-and-langchain/</a></li>
  <li><a href="https://realpython.com/build-llm-rag-chatbot-with-langchain/">https://realpython.com/build-llm-rag-chatbot-with-langchain/</a></li>
</ul>]]></content><author><name></name></author><category term="ai" /><category term="rag" /><category term="open source" /><category term="models" /><category term="chatbot" /><summary type="html"><![CDATA[Creation of a chatbot with opensource model, applying the RAG technique and using Ollama, LangChain, ChromaDb and a final output as API to a web chatbot.]]></summary></entry><entry xml:lang="en"><title type="html">RAG with open source AI models</title><link href="https://rarcos.com/2024/05/25/RAG_modelos_open_source/" rel="alternate" type="text/html" title="RAG with open source AI models" /><published>2024-05-25T08:23:28+02:00</published><updated>2024-05-25T08:23:28+02:00</updated><id>https://rarcos.com/2024/05/25/RAG_modelos_open_source</id><content type="html" xml:base="https://rarcos.com/2024/05/25/RAG_modelos_open_source/"><![CDATA[<h1 id="use-of-rag-retrieval-augmented-generation-in-open-source-models">Use of RAG (Retrieval Augmented Generation) in open source models</h1>

<p style="text-align: justify">
Retrieval-enhanced generation (RAG) is the process of optimising the output of a large language model so that it references an authoritative knowledge base outside of the training data sources before generating an answer. Large Language Models (LLMs) are trained on large volumes of data and use billions of parameters to generate original results for tasks such as question answering, language translation and sentence completion. RAG extends the already powerful capabilities of LLMs to specific domains or to an organisation's internal knowledge base, all without the need to retrain the model. It is a cost-effective method for improving LLM results so that they remain relevant, accurate and useful in a variety of contexts.
</p>

<ul>
  <li>For more information I recommend you visit the following <a href="https://aws.amazon.com/es/what-is/retrieval-augmented-generation/">article</a> from AWS.</li>
  <li>Also in this <a href="https://www.thepowerplatformcave.com/rag-ia-generativa-con-tus-datos/">article</a> it is explained in a more technical way.</li>
</ul>

<p>The phases of the RAG technique are shown below:</p>

<p style="text-align: center">
    <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSYb12anR2JNWP4NDPZ6e1qiEEt3DhUMWkiCqk1YSC53w&amp;s" />    
    <img src="https://observatorio-ia.com/wp-content/uploads/2024/02/RAG.png" />    
</p>

<hr />

<p><em>Repository with content</em></p>

<p>RAG Mistral model</p>

<p><a href="https://colab.research.google.com/drive/1JS0bucLeiNdbFsf6y0gr3bo62lcsCwNj?usp=sharing"><img src="/images/pages/repository_small_colab.png" alt="Repository1" /></a></p>

<p>RAG RoBERTa model</p>

<p><a href="https://colab.research.google.com/drive/1wEJDmyXSdmPH1E9pba9mRrkUSVilzNUn?usp=sharing"><img src="/images/pages/repository_small_colab.png" alt="Repository2" /></a></p>

<hr />

<p><strong>Sources:</strong></p>

<ul>
  <li><a href="https://aws.amazon.com/es/what-is/retrieval-augmented-generation/">https://aws.amazon.com/es/what-is/retrieval-augmented-generation/</a></li>
  <li><a href="https://www.thepowerplatformcave.com/rag-ia-generativa-con-tus-datos/">https://www.thepowerplatformcave.com/rag-ia-generativa-con-tus-datos/ </a></li>
  <li><a href="https://observatorio-ia.com/wp-content/uploads/2024/02/RAG.png">https://observatorio-ia.com/wp-content/uploads/2024/02/RAG.png</a></li>
  <li><a href="https://www.e2enetworks.com/blog/implementing-a-rag-pipeline-with-mixtral-8x7b">https://www.e2enetworks.com/blog/implementing-a-rag-pipeline-with-mixtral-8x7b</a></li>
  <li><a href="https://www.hiberus.com/crecemos-contigo/ask-your-web-pages-otro-enfoque-rag-utilizando-modelos-de-codigo-abierto/">https://www.hiberus.com/crecemos-contigo/ask-your-web-pages-otro-enfoque-rag-utilizando-modelos-de-codigo-abierto/</a></li>
  <li><a href="https://www.datacamp.com/tutorial/mistral-7b-tutorial">https://www.datacamp.com/tutorial/mistral-7b-tutorial</a></li>
  <li><a href="https://haystack.deepset.ai/tutorials/22_pipeline_with_promptnode">https://haystack.deepset.ai/tutorials/22_pipeline_with_promptnode</a></li>
</ul>]]></content><author><name></name></author><category term="ai" /><category term="rag" /><category term="open source" /><category term="models" /><summary type="html"><![CDATA[RAG (Retrieval Augmented Generation) brings precision to language modelling]]></summary></entry><entry xml:lang="en"><title type="html">Angular 17 + Spring Boot 3 + Spring Security 6 + JWT</title><link href="https://rarcos.com/2023/11/20/Spring_boot_angular/" rel="alternate" type="text/html" title="Angular 17 + Spring Boot 3 + Spring Security 6 + JWT" /><published>2023-11-20T15:33:28+01:00</published><updated>2023-11-20T15:33:28+01:00</updated><id>https://rarcos.com/2023/11/20/Spring_boot_angular</id><content type="html" xml:base="https://rarcos.com/2023/11/20/Spring_boot_angular/"><![CDATA[<h1 id="angular-17--spring-boot-3--spring-security-6--jwt">Angular 17 + Spring Boot 3 + Spring Security 6 + JWT</h1>

<p style="text-align: justify">
The main purpose of the application has been to demonstrate the implementation of the knowledge acquired throughout the training on the management of user access privileges to different elements (or modules as I will refer to throughout the document) of the application, the management of hierarchical users in different groups (called roles) and the administration by an authorised user. No less relevant has been the application of knowledge in the design and management of relational databases and their implementation platforms. Another factor taken into account was the security of the environment of use (JWT) and of the application (Angular), implementing functionalities such as the encryption of sensitive data, or the prevention of the use of elements sensitive to the injection of automated information (cracking or brute force attacks).
</p>

<h1 id="architecture">Architecture</h1>

<p>This is the architecture that has been used for the production environment on a VPS.</p>

<p><img src="/images/pages/spring_boot_arquitectura.png" alt="VPS Architecture" title="Spring Boot VPS Architecture" /></p>

<p>The logical separation of frontend, backend and database.</p>

<p><img src="/images/pages/spring_boot_arquitectura_Front-Back.png" alt="Architecture GMCCA Frontend-Backend" title="Spring Boot Frontend-Backend architecture" /></p>

<h2 id="execution-environment---frontend">Execution environment - Frontend</h2>

<p style="text-align: center">
<a href="https://gmcca-spring.rarcos.com" target="_blank">
    <img src="/images/pages/gesmerca.png" width="100" alt="GMCCA Logo" />Online web demo
</a>
</p>

<h2 id="api-documentation---backend">API documentation - Backend</h2>

<p style="text-align: center">
<a href="https://swagger.rarcos.com" target="_blank">
    <img src="https://avatars.githubusercontent.com/u/7658037?s=200&amp;v=4" width="100" alt="Swagger Logo" />Api online documentation
</a>
</p>

<hr />

<p><em>Repository with content</em></p>

<p><a href="https://github.com/rubenarcos2/spring_security_angular"><img src="/images/pages/repository_small.png" alt="Repository" /></a></p>

<hr />

<p><strong>Sources:</strong></p>

<p><em>Spring security + JWT</em></p>

<ul>
  <li><a href="https://www.youtube.com/playlist?list=PL4bT56Uw3S4z9rtwwGvuk1Mjhu5sdLSwX">https://www.youtube.com/playlist?list=PL4bT56Uw3S4z9rtwwGvuk1Mjhu5sdLSwX</a></li>
  <li><a href="https://github.com/cavanosa/tutorial_jwt_BACK">https://github.com/cavanosa/tutorial_jwt_BACK</a></li>
</ul>]]></content><author><name></name></author><category term="javascript" /><category term="php" /><category term="angular" /><category term="laravel" /><category term="proyecto integrado" /><category term="GMCCA" /><summary type="html"><![CDATA[Management of user access privileges to different elements, spring boot, spring security, JWT and Angular.]]></summary></entry><entry xml:lang="en"><title type="html">Integrated Project DWA</title><link href="https://rarcos.com/2023/06/30/Proyecto_integrado/" rel="alternate" type="text/html" title="Integrated Project DWA" /><published>2023-06-30T16:33:28+02:00</published><updated>2023-06-30T16:33:28+02:00</updated><id>https://rarcos.com/2023/06/30/Proyecto_integrado</id><content type="html" xml:base="https://rarcos.com/2023/06/30/Proyecto_integrado/"><![CDATA[<h1 id="integrated-project-at-the-end-of-the-higher-technician-in-development-of-web-applications">Integrated project at the end of the Higher Technician in Development of Web Applications</h1>

<p style="text-align: justify">
The main purpose of the application has been to demonstrate the implementation of the knowledge acquired throughout the training cycle of web application development. I have focused the application on the knowledge acquired on the management of user access privileges to different elements (or modules as I will refer to throughout the document) of the application, the management of hierarchical users in different groups (called roles) and the administration by an authorised user. No less relevant has been the application of knowledge in the design and management of relational databases and their implementation platforms. Another factor taken into account was the security of the environment of use (JWT) and of the application (Angular), implementing functionalities such as the encryption of sensitive data, or the prevention of the use of elements sensitive to the injection of automated information (cracking or brute force attacks).
</p>

<h1 id="technologies">Technologies</h1>
<ul>
  <li>Frontend: Angular 16</li>
  <li>Backend: Laravel 10 + JWT</li>
  <li>External API: IA (Flask)</li>
</ul>

<h1 id="presentation-and-presentation-of-the-project">Presentation and presentation of the project</h1>

<iframe src="https://drive.google.com/file/d/18QEggdRyanzHKvrReNoUgMQjEZppg-Sx/preview" frameborder="0" allowfullscreen="" width="100%" height="400"></iframe>

<iframe type="application/pdf" src="/pdf/Gesmerca_DAW_Presentacion.pdf#toolbar=0" frameborder="0" allowfullscreen="" width="100%" height="500"></iframe>

<h1 id="architecture">Architecture</h1>

<p>This is the architecture that has been used for the production environment on a VPS.</p>

<p><img src="/images/pages/GesMerCa_arquitectura.png" alt="VPS Architecture" title="GesMerCa VPS Architecture" /></p>

<p>The logical separation of frontend, backend and database.</p>

<p><img src="/images/pages/GesMerCa_arquitectura_Front-Back.png" alt="Architecture GMCCA Frontend-Backend" title="GesMerCa Frontend-Backend architecture" /></p>

<h2 id="execution-environment---frontend">Execution environment - Frontend</h2>

<p style="text-align: center">
<a href="https://gmcca-laravel.rarcos.com" target="_blank">
    <img src="/images/pages/gesmerca.png" width="100" alt="GMCCA Logo" />Online web demo
</a>
</p>

<h2 id="api-documentation---backend">API documentation - Backend</h2>

<p style="text-align: center">
<a href="https://vps.rarcos.com:10447/" target="_blank">
    <img src="https://avatars.githubusercontent.com/u/7658037?s=200&amp;v=4" width="100" alt="Swagger Logo" />Api online documentation
</a>
</p>

<h2 id="complete-project-documentation-and-diagrams">Complete project documentation and diagrams</h2>

<iframe type="application/pdf" src="/pdf/Documentacion_GESMERCA_anticopia_DAW.pdf#toolbar=0" frameborder="0" allowfullscreen="" width="100%" height="990"></iframe>

<hr />

<p><em>Repository with content</em></p>

<p><a href="https://github.com/rubenarcos2/proyecto_daw/tree/main/frontend/gesmerca"><img src="/images/pages/repository_small.png" alt="Repository" /></a>
Frontend
<a href="https://github.com/rubenarcos2/proyecto_daw/tree/main/backend/gesmerca"><img src="/images/pages/repository_small.png" alt="Repository" /></a>
Backend
<a href="https://github.com/rubenarcos2/proyecto_daw/tree/main/IA"><img src="/images/pages/repository_small.png" alt="Repository" /></a>
IA</p>

<hr />

<p><strong>Sources:</strong></p>

<p><em>Angular</em></p>

<ul>
  <li><a href="https://openwebinars.net/academia/aprende/angular/9221/">https://openwebinars.net/academia/aprende/angular/9221/</a></li>
  <li><a href="https://www.positronx.io/laravel-angular-token-based-authentication-with-jwt/">https://www.positronx.io/laravel-angular-token-based-authentication-with-jwt/</a></li>
  <li><a href="https://www.ultimateakash.com/blog-details/Ii1TNGAKYAo=/How-to-Implement-JWT-Authentication-in-Angular-2023">https://www.ultimateakash.com/blog-details/Ii1TNGAKYAo=/How-to-Implement-JWT-Authentication-in-Angular-2023</a></li>
  <li><a href="https://www.tektutorialshub.com/angular/meta-service-in-angular-add-update-meta-tags-example/">https://www.tektutorialshub.com/angular/meta-service-in-angular-add-update-meta-tags-example/</a>
<a href="https://angular.io/api/platform-browser/MetaDefinition">https://angular.io/api/platform-browser/MetaDefinition</a></li>
  <li><a href="https://www.concretepage.com/angular-2/angular-2-4-minlength-and-maxlength-validation-example#:~:text=It%20means%20the%20value%20entered,can%20write%20code%20as%20below.">https://www.concretepage.com/angular-2/angular-2-4-minlength-and-maxlength-validation-example#:~:text=It%20means%20the%20value%20entered,can%20write%20code%20as%20below.</a></li>
  <li><a href="https://stackoverflow.com/questions/52389376/how-to-reload-current-page">https://stackoverflow.com/questions/52389376/how-to-reload-current-page</a></li>
</ul>

<p><em>LocalStorage y sessionStorage</em></p>

<ul>
  <li><a href="https://ed.team/blog/que-es-y-como-utilizar-localstorage-y-sessionstorage">https://ed.team/blog/que-es-y-como-utilizar-localstorage-y-sessionstorage</a></li>
</ul>

<p><em>Component Lifecycle</em></p>

<ul>
  <li><a href="https://angular.io/guide/lifecycle-hooks">https://angular.io/guide/lifecycle-hooks</a></li>
</ul>

<p><em>Unit testing</em></p>

<ul>
  <li><a href="https://www.infragistics.com/community/blogs/b/infragistics/posts/unit-testing-in-angular">https://www.infragistics.com/community/blogs/b/infragistics/posts/unit-testing-in-angular</a> -&gt; ng test –code-coverage</li>
</ul>

<p><em>Auth guard with roles/permission based</em></p>

<ul>
  <li><a href="https://jasonwatmore.com/post/2022/12/22/angular-14-role-based-authorization-tutorial-with-example">https://jasonwatmore.com/post/2022/12/22/angular-14-role-based-authorization-tutorial-with-example</a></li>
</ul>

<p><em>Unsuscribing AJAX request</em></p>

<ul>
  <li><a href="https://nocodenobug.substack.com/p/rxjs-en-angular-el-drama-de-las-suscripciones">https://nocodenobug.substack.com/p/rxjs-en-angular-el-drama-de-las-suscripciones</a></li>
</ul>

<p><em>Laravel</em>
<em>Creating the rest API in laravel with JWT authentication</em></p>

<ul>
  <li><a href="https://www.positronx.io/laravel-jwt-authentication-tutorial-user-login-signup-api/">https://www.positronx.io/laravel-jwt-authentication-tutorial-user-login-signup-api/</a></li>
  <li><a href="https://www.nigmacode.com/laravel/roles-de-usuario-en-laravel/">https://www.nigmacode.com/laravel/roles-de-usuario-en-laravel/</a> -&gt; php artisan vendor:publish –provider=”Spatie\Permission\PermissionServiceProvider”</li>
  <li><a href="https://laraveldaily.com/post/laravel-api-errors-and-exceptions-how-to-return-responses">https://laraveldaily.com/post/laravel-api-errors-and-exceptions-how-to-return-responses</a></li>
  <li><a href="https://stackoverflow.com/questions/64897053/laravel-8-return-all-exceptions-as-json">https://stackoverflow.com/questions/64897053/laravel-8-return-all-exceptions-as-json</a></li>
  <li><a href="https://www.itsolutionstuff.com/post/laravel-9-user-roles-and-permissions-tutorialexample.html">https://www.itsolutionstuff.com/post/laravel-9-user-roles-and-permissions-tutorialexample.html</a>
<a href="https://larainfo.com/blogs/laravel-9-image-file-upload-example">https://larainfo.com/blogs/laravel-9-image-file-upload-example</a></li>
  <li><a href="https://stackoverflow.com/questions/68128685/laravel-get-public-url-for-file-stored-in-storage-public-folder">https://stackoverflow.com/questions/68128685/laravel-get-public-url-for-file-stored-in-storage-public-folder</a> -&gt; php artisan storage:link
<a href="https://tinkerwell.app/blog/laravel-caches-and-all-ways-to-clear-them">https://tinkerwell.app/blog/laravel-caches-and-all-ways-to-clear-them</a></li>
  <li><a href="https://www.positronx.io/laravel-image-resize-upload-with-intervention-image-package/">https://www.positronx.io/laravel-image-resize-upload-with-intervention-image-package/</a></li>
</ul>

<p><em>Spatie permissions</em></p>

<ul>
  <li><a href="https://spatie.be/docs/laravel-permission/v5/basic-usage/direct-permissions">https://spatie.be/docs/laravel-permission/v5/basic-usage/direct-permissions</a></li>
  <li><a href="https://laravelcode.com/post/laravel-8-user-roles-and-permissions-using-spatie">https://laravelcode.com/post/laravel-8-user-roles-and-permissions-using-spatie</a>
<a href="https://spatie.be/docs/laravel-permission/v5/basic-usage/role-permissions">https://spatie.be/docs/laravel-permission/v5/basic-usage/role-permissions</a></li>
  <li><a href="https://scrutinizer-ci.com/g/spatie/laravel-permission/code-structure/master/operation/Spatie%5CPermission%5CTraits%5CHasPermissions::syncPermissions">https://scrutinizer-ci.com/g/spatie/laravel-permission/code-structure/master/operation/Spatie%5CPermission%5CTraits%5CHasPermissions::syncPermissions</a></li>
</ul>

<p><em>Faker y seed imagenes</em></p>

<ul>
  <li><a href="https://styde.net/generando-datos-de-prueba-con-faker-en-laravel/">https://styde.net/generando-datos-de-prueba-con-faker-en-laravel/</a></li>
  <li><a href="https://github.com/fzaninotto/Faker#formatters">https://github.com/fzaninotto/Faker#formatters</a></li>
  <li><a href="https://kodementor.com/how-to-seeds-images-with-faker-in-laravel/">https://kodementor.com/how-to-seeds-images-with-faker-in-laravel/</a></li>
  <li><a href="https://styde.net/insercion-de-datos-con-los-seeders-de-laravel/">https://styde.net/insercion-de-datos-con-los-seeders-de-laravel/</a> -&gt; php artisan migrate:fresh –seed</li>
</ul>

<p><em>storage -&gt; public link</em></p>

<ul>
  <li><a href="https://laravel.com/docs/10.x/filesystem#the-public-disk">https://laravel.com/docs/10.x/filesystem#the-public-disk</a> -&gt; php artisan storage:link</li>
</ul>

<p><em>Unit testing</em></p>

<ul>
  <li><a href="https://platzi.com/discusiones/1842-intro-laravel/85644-que-diferencia-hay-entre-unit-test-y-feature-test/">https://platzi.com/discusiones/1842-intro-laravel/85644-que-diferencia-hay-entre-unit-test-y-feature-test/</a></li>
  <li><a href="https://laravel.com/docs/10.x/testing">https://laravel.com/docs/10.x/testing</a> -&gt; php artisan test</li>
</ul>

<p><em>Docker postgreSQL database backup</em></p>

<ul>
  <li><a href="https://stackoverflow.com/questions/30171063/how-to-generate-a-postgresql-dump-from-a-docker-container">https://stackoverflow.com/questions/30171063/how-to-generate-a-postgresql-dump-from-a-docker-container</a></li>
</ul>]]></content><author><name></name></author><category term="javascript" /><category term="php" /><category term="angular" /><category term="laravel" /><category term="proyecto integrado" /><category term="GMCCA" /><summary type="html"><![CDATA[Integrated project at the end of the Higher Technician in Development of Web Applications (DWA).Angular 16 + Laravel 10 + JWT + IA]]></summary></entry><entry xml:lang="en"><title type="html">Securing VPS</title><link href="https://rarcos.com/2023/03/14/Securizando-VPS/" rel="alternate" type="text/html" title="Securing VPS" /><published>2023-03-14T06:41:00+01:00</published><updated>2023-03-14T06:41:00+01:00</updated><id>https://rarcos.com/2023/03/14/Securizando%20VPS</id><content type="html" xml:base="https://rarcos.com/2023/03/14/Securizando-VPS/"><![CDATA[<p>By way of notes, a standard VPS securisation:</p>
<ul>
  <li><a href="#seg-basica">Basic security</a></li>
  <li><a href="#ssh">SSH key-based authentication</a></li>
  <li><a href="#maldet">Malware detection - maldet</a></li>
  <li><a href="#postfix">Postfix - Sending email</a></li>
  <li><a href="#cpu">Notification if CPU max</a></li>
</ul>

<p><a name="seg-basica"></a></p>

<h1 id="linux-security-and-common-weaknesses">Linux security and common weaknesses</h1>

<p>15 VPS security tips for protecting your server security</p>

<p><a href="https://www.hostinger.es/tutoriales/seguridad-vps">https://www.hostinger.es/tutoriales/seguridad-vps</a></p>

<p><a name="ssh"></a></p>

<h1 id="ssh-key-based-authentication---access">SSH Key Based Authentication - Access</h1>

<p>Generation of the key pair: public-private</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">ssh-keygen <span class="nt">-t</span> rsa</code></pre></figure>

<p>Public key authorisation</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">cat</span> ~/.ssh/id_rsa.pub <span class="o">&gt;&gt;</span> ~/.ssh/authorized_keys</code></pre></figure>

<p>Disable password authentication on your server</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>nano /etc/ssh/sshd_config</code></pre></figure>

<p>Change the value of PasswordAuthentication inside the sshd_config to:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">PasswordAuthentication no</code></pre></figure>

<p>Restart the SSH server for the changes to take effect:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">service ssh restart</code></pre></figure>

<p>We pass by sftp the private key <em>id_rsa</em> to the client we are going to use. Putty in my case.
On the client side, we install putty and generate the private key as follows:</p>

<p><a href="https://www.simplified.guide/putty/convert-ssh-key-to-ppk">https://www.simplified.guide/putty/convert-ssh-key-to-ppk</a></p>

<p><a name="maldet"></a></p>

<h1 id="malware-detection---maldet">Malware detection - maldet</h1>

<p>Installation and commissioning:</p>

<p><a href="https://codigonaranja.com/como-detectar-malware-en-tu-sitio-web-servidores-linux-ubuntu-debian">https://codigonaranja.com/como-detectar-malware-en-tu-sitio-web-servidores-linux-ubuntu-debian</a></p>

<p>View reports and briefings:</p>

<p><a href="https://wpbeaches.com/set-lmd-maldet-clamav-runcloud/">https://wpbeaches.com/set-lmd-maldet-clamav-runcloud/</a></p>

<p>Manual scanning:</p>

<p><a href="https://www.nosolocodigo.com/linux-malware-detect-escaner-para-aplicaciones-web-open-source/">https://www.nosolocodigo.com/linux-malware-detect-escaner-para-aplicaciones-web-open-source/</a></p>

<p><a name="postfix"></a></p>

<h1 id="installing-and-configuring-postfix-to-use-gmail-smtp">Installing and configuring Postfix to use Gmail SMTP</h1>

<p><a href="http://somebooks.es/configurar-postfix-para-usar-el-smtp-de-gmail-en-ubuntu-20-04-lts/">http://somebooks.es/configurar-postfix-para-usar-el-smtp-de-gmail-en-ubuntu-20-04-lts/</a></p>

<p><a href="https://www.fosstechnix.com/how-to-configure-postfix-with-gmail-on-ubuntu/">https://www.fosstechnix.com/how-to-configure-postfix-with-gmail-on-ubuntu/</a></p>

<p>Email aliases for users:</p>

<p><a href="https://www.cyberciti.biz/tips/how-to-redirect-one-users-mail-to-another-user-with-postfix.html">https://www.cyberciti.biz/tips/how-to-redirect-one-users-mail-to-another-user-with-postfix.html</a></p>

<p>Resolution of the error in the certificate:</p>

<p><a href="https://github.com/rancher/rancher/issues/4293">https://github.com/rancher/rancher/issues/4293</a></p>

<p><a name="cpu"></a></p>

<h1 id="email-notification-if-cpu-exceeds-80">Email notification if CPU exceeds 80%</h1>

<p><a href="https://www.2daygeek.com/linux-shell-script-to-monitor-cpu-utilization-usage-and-send-email/">https://www.2daygeek.com/linux-shell-script-to-monitor-cpu-utilization-usage-and-send-email/</a></p>]]></content><author><name></name></author><category term="vps" /><category term="seguridad" /><category term="ssh" /><category term="postfix" /><category term="malware" /><summary type="html"><![CDATA[VPS securisation notes: basic security, ssh keys, malware detection, posfix...]]></summary></entry><entry><title type="html">Dockerizando VPS</title><link href="https://rarcos.com/2023/03/11/Dockerizando-VPS/" rel="alternate" type="text/html" title="Dockerizando VPS" /><published>2023-03-11T06:41:00+01:00</published><updated>2023-03-11T06:41:00+01:00</updated><id>https://rarcos.com/2023/03/11/Dockerizando%20VPS</id><content type="html" xml:base="https://rarcos.com/2023/03/11/Dockerizando-VPS/"><![CDATA[<p>He traspasado todas mis aplicaciones que tenía en heroku a un vps propio y además he aprovechado para dockerizarlas todas, incluyendo bases de datos y otros servicios web. Concretamente he dockerizado:</p>
<ul>
  <li><a href="#cont-spring-boot">Spring Boot</a></li>
  <li><a href="#cont-laravel">Laravel</a></li>
  <li><a href="#cont-flask">Flask</a></li>
  <li><a href="#cont-nginx">Nginx</a></li>
  <li><a href="#cont-postgres">PostgreSQL</a></li>
  <li><a href="#cont-mysql">MySQL</a></li>
  <li><a href="#cont-mongo">MongoDB</a></li>
</ul>

<h1 id="instalación-de-docker-en-el-vps">Instalación de docker en el VPS</h1>

<p><strong>Docker</strong></p>

<p>En primer lugar he tenido que instalar docker y docker compose. Para la instalación de docker en ubuntu 22.04 server :</p>

<p>Actualizamos la lista de paquetes del S.O. y actualizamos el S.O.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">apt update <span class="o">&amp;&amp;</span> apt upgrade</code></pre></figure>

<p>Añadimos una serie de paquetes de requisitos previos.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">apt <span class="nb">install </span>apt-transport-https ca-certificates curl software-properties-common</code></pre></figure>

<p>Se agrega la clave GPG para el repositorio oficial de Docker a nuestro S.O.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">curl <span class="nt">-fsSL</span> https://download.docker.com/linux/ubuntu/gpg | apt-key add -</code></pre></figure>

<p>Y por último ya podremos añadir el repositorio a nuestro S.O. Podemos comprobar que se ha añadido una línea en /etc/apt/source.list.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">add-apt-repository <span class="s2">"deb [arch=amd64] https://download.docker.com/linux/ubuntu jammy stable"</span></code></pre></figure>

<p>Actualizamos la base de datos ya que hay una línea nueva (compruebe en el listado que sale) y comprobaremos antes de instalar que vamos a instalar desde el repositorio (y no desde Ubuntu Server).</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">apt update &amp; apt-cache policy docker-ce</code></pre></figure>

<p>Por último, podremos instalar el paquete (paquete pesado de aproximadamente 400 MBytes). Como no puede ser de otra manera hay que asegurar que Docker engine está arrancado y si reinicia el servicio en el arranque del S.O. anfitrión.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">apt-get <span class="nb">install </span>docker-ce</code></pre></figure>

<p><em>Manualillo de systemctl</em></p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">systemctl disable Docker <span class="c"># deshabilitamos en el arranque el demonio docker </span>
systemctl list-unit-files | <span class="nb">grep </span>docker 
systemctl <span class="nb">enable </span>docker 
systemctl list-unit-files | <span class="nb">grep </span>docker 
systemctl stop docker <span class="o">&amp;&amp;</span> systemctl status Docker 
systemctl start docker <span class="o">&amp;&amp;</span> systemctl status Docker 
docker versión</code></pre></figure>

<p><em>Resolución del problema de permisos de docker para un usuario no root</em></p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>groupadd docker
<span class="nb">sudo </span>usermod <span class="nt">-aG</span> docker mi_usuario
newgrp docker
docker ps</code></pre></figure>

<p><strong>Docker-Compose</strong></p>

<p>Actualización de la lista de repositorios</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>apt update</code></pre></figure>

<p>Instalación de docker-compose</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>apt <span class="nb">install </span>docker-compose</code></pre></figure>

<p>Comprobamos el estado del servidor docker y las versiones respectivamente</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">systemctl status docker
docker <span class="nt">-v</span>
docker-compose <span class="nt">-version</span></code></pre></figure>

<h1 id="creación-de-los-contenedores-y-docker-compose">Creación de los contenedores y docker-compose</h1>

<p>En primer lugar me he creado una carpeta <em>docker</em> en el home, que irá alojando los scripts y ficheros necesarios. Tiene la siguiente estructura:</p>

<p><img src="/images/pages/docker-jerarquia.jpg" alt="docker-jerarquia.jpg" /></p>

<p>Vamos a utilizar para el certificado de autenticación del servidor https <a href="https://letsencrypt.org/">Let’s encrypt</a>.</p>

<p><strong>Instalación y generación del certificado Let’s encrypt</strong></p>

<p>Para la instalación de la aplicación <em>certbot</em> de Let’s encrypt para generar los certificados, recomiendo seguir las instrucciones de la siguiente página <a href="https://certbot.eff.org/instructions?ws=other&amp;os=ubuntufocal">https://certbot.eff.org/instructions?ws=other&amp;os=ubuntufocal</a> está preseleccionado para Ubuntu server.</p>

<p>La página indicada anteriormente, es la única que funciona actualmente con Ubuntu Server 22.04, el resto de tutoriales que he visitado se encuentran obsoletos al haber cambiado a snap la aplicación de certbot de Let’s encrypt y el repositorio de github ya no funciona tampoco como se esperaba en instrucciones antiguas.</p>

<p>Una vez terminado nos generará la siguiente salida:
<img src="/images/pages/certificado_letsencrypt.jpg" alt="salida_certificado_letsencrypt" /></p>

<p>Generamos el certificado que es válido para tomcat .p12.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">openssl pkcs12 <span class="nt">-export</span> <span class="nt">-in</span> /etc/letsencrypt/live/mi_dominio_web/fullchain.pem <span class="nt">-inkey</span> /etc/letsencrypt/live/mi_dominio_web/privkey.pem <span class="nt">-out</span> springboot_letsencrypt.p12 <span class="nt">-name</span> bootalias <span class="nt">-CAfile</span> chain.pem <span class="nt">-caname</span> root</code></pre></figure>

<p><em>Recuerda cambiar las rutas por las tuyas</em></p>

<p><a name="cont-spring-boot"></a></p>

<p><strong>Contenedor para Spring Boot</strong></p>

<p>Copiamos los ficheros necesarios en nuestra carpeta de nuestro nuestra carpeta en el home de <em>/docker/docker-java/</em>: estando en la raíz de esta el fichero .jar y .p12.</p>

<p><em>Generación de los scripts de docker</em></p>

<p>En primer lugar, vamos a crear un <em>Dockerfile</em> para que contenga la imagen (para Ubuntu server) y realice la copia de los ficheros necesarios (el .jar y el certificado) hacia nuestro contenedor.</p>

<p>Dockerfile</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">FROM eclipse-temurin:17-jdk-alpine

ARG <span class="nv">JAR_FILE</span><span class="o">=</span><span class="k">*</span>.jar

COPY <span class="k">${</span><span class="nv">JAR_FILE</span><span class="k">}</span> my_proyect_compiled.jar
COPY my_cert_letsencrypt.p12 <span class="nb">.</span>

ENTRYPOINT <span class="o">[</span><span class="s2">"java"</span>,<span class="s2">"-jar"</span>,<span class="s2">"/my_proyect_compiled.jar"</span><span class="o">]</span></code></pre></figure>

<p><em>Tendremos que cambiar el nombre del certificado y del fichero del proyecto compilado .jar</em></p>

<p>En segundo lugar, vamos a crear el script de <em>docker-compose.yml</em> que creará nuestro servicio web y expondrá el puerto 8443 por defecto.</p>

<p>docker-compose.yml</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">version: <span class="s1">'3.8'</span>
services:
  proyect_name:
    build: <span class="nb">.</span>
    container_name: <span class="s1">'proyect_name-spring-app'</span>
    restart: always
    ports:
      - <span class="s1">'8080:8080'</span>
      - <span class="s1">'8443:8443'</span></code></pre></figure>

<p><em>Tendremos que cambiar el nombre del servicio y del contenedor</em></p>

<p><em>Proyecto Spring Boot</em></p>

<p>Vamos a añadir al fichero <em>aplication.properties</em> la configuración para que el servidor tomcat que crea Spring, escuche por el puerto https, que por defecto es el 8443 en lugar del 443. Y el certificado que hemos creado previamente para que nuestro servidor funcione con Let’s encrypt.</p>

<p>aplication.properties</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">server</span><span class="o">.</span><span class="na">port</span><span class="o">=</span><span class="mi">9443</span>
<span class="n">server</span><span class="o">.</span><span class="na">ssl</span><span class="o">.</span><span class="na">enabled</span><span class="o">=</span><span class="kc">true</span>
<span class="n">server</span><span class="o">.</span><span class="na">ssl</span><span class="o">.</span><span class="na">key</span><span class="o">-</span><span class="n">store</span><span class="o">=</span><span class="n">my_cert_letsencrypt</span><span class="o">.</span><span class="na">p12</span>
<span class="n">server</span><span class="o">.</span><span class="na">ssl</span><span class="o">.</span><span class="na">key</span><span class="o">-</span><span class="n">store</span><span class="o">-</span><span class="n">password</span><span class="o">=</span><span class="n">your_password</span>
<span class="n">server</span><span class="o">.</span><span class="na">ssl</span><span class="o">.</span><span class="na">keyStoreType</span><span class="o">=</span><span class="no">PKCS12</span>
<span class="n">server</span><span class="o">.</span><span class="na">ssl</span><span class="o">.</span><span class="na">keyAlias</span><span class="o">=</span><span class="n">your_alias</span></code></pre></figure>

<p><em>Tendremos que cambiar: el certificado, la contraseña y el alias con el que creamos anteriormente.</em></p>

<p>Generamos el fichero <em>.jar</em> mediante el comando de mvn para compilar</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">mvn package</code></pre></figure>

<p><em>Para ver la diferencia entre mvn package y mvn install, consulta este <a href="https://www.appsdeveloperblog.com/difference-between-mvn-package-and-mvn-install/">enlace</a></em></p>

<p>Ahora en la carpeta <em>/target</em> del proyecto tendremos el fichero <em>.jar</em> que pasaremos por ftp a nuestra carpeta en el home de <em>/docker/docker-java/nombre_aplicacion</em> que contendrá a su vez los ficheros de <em>Dockerfile</em> y <em>docker-compose.yml</em>, junto a nuestro certificado <em>.p12</em>. Para que todo se pueda copiar en el contenedor de docker, según las instrucciones de nuesto <em>Dockerfile</em>.</p>

<p>Finalmente, debemos tener la siguiente estructura de ficheros en la carpeta de docker:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">/docker-my_app
|-Dockerfile
|-docker-compose.yml
|-my_app.jar
|-my_cert.p12</code></pre></figure>

<p>En la página oficial del Spring Boot hay también un tutorial que indica con mayor detalle lo realizado anteriormente <a href="https://spring.io/guides/topicals/spring-boot-docker/">https://spring.io/guides/topicals/spring-boot-docker/</a> incluyendo aspectos de seguridad como la creación de un usuario diferente a root dentro del contenedor de docker.</p>

<p><a name="cont-laravel"></a></p>

<p><strong>Contenedor para Laravel</strong></p>

<p>Para Laravel vamos a utilizar un servidor ngnix con la última versión por seguridad.
para ello crearemos varios ficheros que describiré a continuación:</p>

<p><em>Generación de los scripts de docker</em></p>

<p>Dockerfile</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># imagen de dockerhub que descargara</span>
FROM php:8.2-fpm-alpine

<span class="c"># algunas configuraciones para que funcione el contenedor para mysql</span>
<span class="c">#RUN docker-php-ext-install pdo pdo_mysql</span>

<span class="c"># Install Postgre PDO</span>
RUN <span class="nb">set</span> <span class="nt">-ex</span> <span class="se">\</span>
  <span class="o">&amp;&amp;</span> apk <span class="nt">--no-cache</span> add <span class="se">\</span>
    postgresql-dev

RUN docker-php-ext-install pdo pdo_pgsql

<span class="c"># instala composer en el contenedor</span>
RUN curl <span class="nt">-sS</span> https://getcomposer.org/installer | php <span class="nt">--</span> <span class="nt">--install-dir</span><span class="o">=</span>/usr/local/bin <span class="nt">--filename</span><span class="o">=</span>composer

<span class="c"># da permisos para editar los archivos en esta ruta del container</span>
RUN <span class="nb">chown</span> <span class="nt">-R</span> www-data:www-data /var/www
RUN <span class="nb">chmod </span>755 /var/www</code></pre></figure>

<p>docker-compose.yml</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">version: <span class="s2">"3.3"</span>

<span class="c"># Servidor nginx</span>
services:
  nginx-laravel:
    image: nginx:latest
    restart: always
    ports:
      - <span class="s2">"10440:443"</span>
    volumes:
      - ./src:/var/www/html
      - ./src/storage:/var/www/html/storage
      - ./nginx.conf:/etc/nginx/conf.d/default.conf
      - /etc/letsencrypt/live/mi_dominio_web/fullchain.pem:/etc/nginx/ssl/fullchain.pem:ro
      - /etc/letsencrypt/live/mi_dominio_web/privkey.pem:/etc/nginx/ssl/privkey.pem:ro

    links:
      - php-laravel

  <span class="c"># Configuración de php-fpm</span>
  php-laravel:
<span class="c">#    image: php:8-fpm</span>
    build: <span class="nb">.</span>
    restart: always
    volumes:
      - ./src:/var/www/html
<span class="c">#    command: sh -c "cd /var/www/html &amp;&amp; composer update nesbot/carbon"</span></code></pre></figure>

<p>nginx.conf</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">server <span class="o">{</span>
    listen 80<span class="p">;</span>
    listen <span class="o">[</span>::]:80<span class="p">;</span>
    listen 443 ssl<span class="p">;</span>
    server_name mi_ip www.mi_dominio mi_dominio localhost<span class="p">;</span>
    ssl_certificate /etc/nginx/ssl/fullchain.pem<span class="p">;</span>
    ssl_certificate_key /etc/nginx/ssl/privkey.pem<span class="p">;</span>

    <span class="c"># Redirect non-https traffic to https</span>
    <span class="k">if</span> <span class="o">(</span><span class="nv">$scheme</span> <span class="o">!=</span> <span class="s2">"https"</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return </span>301 https://<span class="nv">$host$request_uri</span><span class="p">;</span>
    <span class="o">}</span>

    <span class="c"># Log files for Debug</span>
    error_log  /var/log/nginx/error.log<span class="p">;</span>
    access_log /var/log/nginx/access.log<span class="p">;</span>

    <span class="c"># Laravel web root directory</span>
    root /var/www/html/public<span class="p">;</span>
    index index.php index.html<span class="p">;</span>

    location / <span class="o">{</span>
        try_files <span class="nv">$uri</span> <span class="nv">$uri</span>/ /index.php?<span class="nv">$query_string</span><span class="p">;</span>
        gzip_static on<span class="p">;</span>
    <span class="o">}</span>

    <span class="c"># Nginx Pass requests to PHP-FPM</span>
    location ~ <span class="se">\.</span>php<span class="nv">$ </span><span class="o">{</span>
        try_files <span class="nv">$uri</span> <span class="o">=</span>404<span class="p">;</span>
        fastcgi_split_path_info ^<span class="o">(</span>.+<span class="se">\.</span>php<span class="o">)(</span>/.+<span class="o">)</span><span class="nv">$;</span>
        fastcgi_pass php-laravel:9000<span class="p">;</span>
        fastcgi_index index.php<span class="p">;</span>
        include fastcgi_params<span class="p">;</span>
        fastcgi_param SCRIPT_FILENAME <span class="nv">$document_root$fastcgi_script_name</span><span class="p">;</span>
        fastcgi_param PATH_INFO <span class="nv">$fastcgi_path_info</span><span class="p">;</span>
    <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

<p><em>Sustituye mi dominio mi_dominio por el tuyo</em></p>

<p>Finalmente, debemos tener la siguiente estructura de ficheros en la carpeta de docker:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">/docker-my_app
|-Dockerfile
|-docker-compose.yml
|-default.conf
|-nginx.conf
|-src</code></pre></figure>

<p>Y en la carpeta <em>src</em> vamos a copiar todo el contenido de Laravel.</p>

<p>Levantamos el contenedor de docker como demonio y con la compilación activada</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">docker-compose up <span class="nt">--build</span> <span class="nt">-d</span></code></pre></figure>

<p>Con esto ya tenemos una versión de Laravel Dockerizada y funcionando.</p>

<p><a name="cont-flask"></a></p>

<p><strong>Contenedor para Flask</strong></p>

<p>Tenemos nuestra aplicación python con flask en la carpeta <em>app</em> y los certificados en la carpeta <em>certs</em> y el fichero de <em>requirements</em> al mismo nivel que los de docker.</p>

<p><em>Generación de los scripts de docker</em></p>

<p>Dockerfile</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">version: <span class="s1">'3.8'</span>

services:
  flask:
    restart: always
    build: <span class="nb">.</span>
    <span class="nb">command</span>: python app.py run <span class="nt">-h</span> 0.0.0.0
    volumes:
      - ./app:/usr/src/app/
    ports:
      - 10443:5000
    environment:
      - <span class="nv">FLASK_APP</span><span class="o">=</span>app.py
      - <span class="nv">FLASK_DEBUG</span><span class="o">=</span>1</code></pre></figure>

<p>nginx.conf</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">server <span class="o">{</span>
    listen 80<span class="p">;</span>
    listen <span class="o">[</span>::]:80<span class="p">;</span>
    listen 443 ssl<span class="p">;</span>
    server_name  www.mi_dominio_web mi_dominio_web<span class="p">;</span>
    ssl_certificate /etc/nginx/certs/fullchain.pem<span class="p">;</span>
    ssl_certificate_key /etc/nginx/certs/privkey.pem<span class="p">;</span>

    <span class="c"># Redirect non-https traffic to https</span>
    <span class="k">if</span> <span class="o">(</span><span class="nv">$scheme</span> <span class="o">!=</span> <span class="s2">"https"</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return </span>301 https://<span class="nv">$host$request_uri</span><span class="p">;</span>
    <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

<p>app.py</p>

<p><em>Sustituye mi dominio mi_dominio_web por el tuyo</em></p>

<p><a name="cont-nginx"></a></p>

<p><strong>Contenedor para Nginx</strong></p>

<p>Copiamos los ficheros necesarios en nuestra carpeta de nuestro nuestra carpeta en el home de <em>/docker/docker-ngnix/</em>: estando en la raíz de esta el fichero <em>docker-compose.yml y nginx.conf</em>, las carpetas: <em>cers, site-content y templates</em>.</p>

<p><em>Generación de los scripts de docker</em></p>

<p>docker-compose.yml</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">version: <span class="s2">"3.7"</span>
services:
  web:
    image: nginx
    volumes:
     - ./templates:/etc/nginx/templates
     - ./site-content:/etc/nginx/html
     - ./certs:/etc/nginx/certs:ro
     - ./nginx.conf:/etc/nginx/conf.d/nginx.conf

    ports:
     - <span class="s2">"80:80"</span>
     - <span class="s2">"443:443"</span></code></pre></figure>

<p><em>Generación del script de configuración de ngnix</em></p>

<p>nginx.conf</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">server <span class="o">{</span>
    listen 80<span class="p">;</span>
    listen <span class="o">[</span>::]:80<span class="p">;</span>
    listen 443 ssl<span class="p">;</span>
    server_name  www.mi_dominio_web mi_dominio_web<span class="p">;</span>
    ssl_certificate /etc/nginx/certs/fullchain.pem<span class="p">;</span>
    ssl_certificate_key /etc/nginx/certs/privkey.pem<span class="p">;</span>

    <span class="c"># Redirect non-https traffic to https</span>
    <span class="k">if</span> <span class="o">(</span><span class="nv">$scheme</span> <span class="o">!=</span> <span class="s2">"https"</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return </span>301 https://<span class="nv">$host$request_uri</span><span class="p">;</span>
    <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

<p><em>Sustituye mi dominio mi_dominio_web por el tuyo</em></p>

<p><em>Generación del resto de ficheros y carpetas</em></p>

<p>En la carpeta <em>certs</em> tienes que tener una copia de los ficheros generados por <em>certbot</em>, son los ficheros: <em>fullchain.pem y privkey.pem</em>.</p>

<p>En la carpeta <em>site-content</em> el <em>index.html</em> de tu web con todo su contenido. Este es un ejemplo de redirección de mi página, por si te sirve de ejemplo.</p>

<p>site-content/index.html</p>

<figure class="highlight"><pre><code class="language-html" data-lang="html"><span class="cp">&lt;!DOCTYPE html&gt;</span>
<span class="nt">&lt;html</span> <span class="na">lang=</span><span class="s">"es"</span><span class="nt">&gt;</span>

<span class="nt">&lt;head&gt;</span>
    <span class="nt">&lt;meta</span> <span class="na">charset=</span><span class="s">"UTF-8"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;meta</span> <span class="na">name=</span><span class="s">"viewport"</span> <span class="na">content=</span><span class="s">"width=device-width, initial-scale=1.0"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;meta</span> <span class="na">http-equiv=</span><span class="s">"X-UA-Compatible"</span> <span class="na">content=</span><span class="s">"ie=edge"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;meta</span> <span class="na">http-equiv=</span><span class="s">"refresh"</span> <span class="na">content=</span><span class="s">"5;url=https://mi_dominio_web"</span><span class="nt">&gt;</span>
<span class="nt">&lt;/head&gt;</span>

<span class="nt">&lt;body&gt;</span>
<span class="nt">&lt;h1&gt;</span>Acceso no permitido<span class="nt">&lt;/h1&gt;</span>
<span class="nt">&lt;p&gt;</span>Va a ser redireccionado a la página <span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">"https://mi_dominio_web"</span><span class="nt">&gt;</span>https://mi_dominio_web<span class="nt">&lt;/a&gt;&lt;/p&gt;</span>
<span class="nt">&lt;/body&gt;</span>
<span class="nt">&lt;/html&gt;</span></code></pre></figure>

<p><a name="cont-postgres"></a></p>

<p><strong>Contenedor para PostgreSQL</strong></p>

<p>La dockerización de PostgreSQL es una de las más sencillas que hay, solamente tenemos que crear un docker-compose y levantar el contenedor.</p>

<p><em>Generación del scripts de docker</em></p>

<p>docker-compose.yml</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">version: <span class="s1">'3.3'</span>
services:
  db:
    image: postgres
    restart: always
    container_name: postgresql
    environment:
      - <span class="nv">POSTGRES_USER</span><span class="o">=</span>mi_usuario
      - <span class="nv">POSTGRES_PASSWORD</span><span class="o">=</span>mi_contraseña
    ports:
      - <span class="s1">'mi_puerto_ext:5432'</span>
    volumes:
      - db:/var/lib/postgresql/data
volumes:
  db:
    driver: <span class="nb">local</span></code></pre></figure>

<p>En la carpeta <em>./db</em> que se creará automáticamente tendremos todos los ficheros de la base de datos para poder consultar y/o modificar lo que necesitemos desde fuera del contenedor.</p>

<p><a name="cont-mysql"></a></p>

<p><strong>Contenedor para mySQL</strong></p>

<p>La dockerización de MySQL es una de las más sencillas que hay, solamente tenemos que crear un docker-compose y levantar el contenedor.</p>

<p><em>Generación del scripts de docker</em></p>

<p>docker-compose.yml</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">version: <span class="s1">'2.4'</span>
services:
  mariadb:
    image: mariadb
    container_name: mysql
    restart: always
    volumes:
      - ./db:/var/lib/mysql
    environment:
      TZ: Europe/Madrid
      <span class="c">#MYSQL_RANDOM_ROOT_PASSWORD: "yes"</span>
      MYSQL_ROOT_PASSWORD: mi_contraseña_root
      MYSQL_DATABASE: mi_nombre_bbdd
      MYSQL_USER: mi_usuario
      MYSQL_PASSWORD: mi_contraseña
    ports:
      - 23452:3306
    <span class="c">#healthcheck:</span>
      <span class="c">#test:  mysqladmin ping -h 127.0.0.1 -u root --password=$$MYSQL_ROOT_PASSWORD || exit 1</span>
      <span class="c">#test:  mysqladmin ping -h 127.0.0.1 -u $$MYSQL_USER --password=$$MYSQL_PASSWORD || exit 1</span>
      <span class="c">#interval: 60s</span>
      <span class="c">#timeout: 5s</span>
      <span class="c">#retries: 5</span>
      <span class="c">#start_period: 30s</span></code></pre></figure>

<p>En la carpeta <em>./db</em> que se creará automáticamente tendremos todos los ficheros de la base de datos para poder consultar y/o modificar lo que necesitemos desde fuera del contenedor.</p>

<p><a name="cont-mongo"></a></p>

<p><strong>Contenedor para MongoDB</strong></p>

<p>La dockerización de MongoDB es una de las más sencillas que hay, solamente tenemos que crear un docker-compose y levantar el contenedor.</p>

<p><em>Generación del scripts de docker</em></p>

<p>docker-compose.yml</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">version: <span class="s1">'3.7'</span>
services:
  mongodb_container:
    image: mongo:latest
    ports:
      - mi_puerto_ext:27017
    volumes:
      - db:/data/db
volumes:
  db:</code></pre></figure>

<p>En la carpeta <em>./db</em> que se creará automáticamente tendremos todos los ficheros de la base de datos para poder consultar y/o modificar lo que necesitemos desde fuera del contenedor.</p>

<hr />

<p><strong>Fuentes:</strong></p>

<p><a href="https://certbot.eff.org/instructions">https://certbot.eff.org/instructions</a></p>

<p><a href="https://wstutorial.com/rest/spring-boot-with-lets-encrypt.html">https://wstutorial.com/rest/spring-boot-with-lets-encrypt.html</a></p>

<p><a href="https://spring.io/guides/topicals/spring-boot-docker/">https://spring.io/guides/topicals/spring-boot-docker/</a></p>

<p><a href="https://awstip.com/run-nginx-in-a-docker-container-using-pre-generated-ssl-certificates-from-letsencrypt-b005ebce74ca">https://awstip.com/run-nginx-in-a-docker-container-using-pre-generated-ssl-certificates-from-letsencrypt-b005ebce74ca</a></p>]]></content><author><name></name></author><category term="docker" /><category term="docker-compose" /><category term="vps" /><category term="spring" /><category term="java" /><category term="php" /><category term="laravel" /><category term="flask" /><category term="python" /><summary type="html"><![CDATA[Cómo he dockerizado mi vps para alojar aplicaciones: spring, laravel, flask...y más]]></summary></entry><entry><title type="html">Python - IA juego Hotel</title><link href="https://rarcos.com/2022/08/11/IA-Juego-Hotel/" rel="alternate" type="text/html" title="Python - IA juego Hotel" /><published>2022-08-11T16:33:28+02:00</published><updated>2022-08-11T16:33:28+02:00</updated><id>https://rarcos.com/2022/08/11/IA%20-%20Juego%20Hotel</id><content type="html" xml:base="https://rarcos.com/2022/08/11/IA-Juego-Hotel/"><![CDATA[<p>He realizado la creación de un sistema de IA para aprendizaje de la decisión de compra para el juego del Hotel. Se trata de decidir si se compra o no en la casilla de <em>compra</em>, y predecir cual de las propiedades es mejor comprar.</p>

<h1 id="programa-generador-de-partidas">Programa generador de partidas</h1>

<p><strong>Generador de partidas</strong></p>

<p>En primer lugar he tenido que realizar una generador de partidas del juego del Hotel, para alimentar a la IA. Posteriormente he creado también un jugador IA para comparar los resultados obtenidos tras el aprendizaje de la IA.</p>

<p><em>Generador de partidas aleatorio (juego Hotel, 4 jugadores):</em></p>

<p><a href="https://colab.research.google.com/drive/1KEqghfPGeuk9u5u8_s531CCb7869Hn3u"><img src="/images/pages/repository_small_colab.png" alt="Generador de partidas" /></a></p>

<p><strong>Dataset</strong></p>

<p>El conjunto de datos utilizado es el dataset de 500 partidas, pero se ha probado progresivamente de 10, 100, 500, 1000. No teniendo apenas diferencia en el aprendizaje entre el de 500 a 1000 partidas.</p>

<p><em>10 partidas - 100 partidas - 500 partidas - 1000 partidas</em></p>

<p><a href="https://github.com/rubenarcos2/ia-juego_hotel/raw/main/datasets/Diez_Partidas_Hotel.csv"><img src="/images/pages/repository_small_file.png" alt="Dataset 10 partidas" /></a>
<a href="https://github.com/rubenarcos2/ia-juego_hotel/raw/main/datasets/Cien_Partidas_Hotel.csv"><img src="/images/pages/repository_small_file.png" alt="Dataset 100 partidas" /></a>
<a href="https://github.com/rubenarcos2/ia-juego_hotel/raw/main/datasets/Quinientas_Partidas_Hotel_A.csv"><img src="/images/pages/repository_small_file.png" alt="Dataset 500 partidas" /></a>
<a href="https://github.com/rubenarcos2/ia-juego_hotel/raw/main/datasets/Mil_Partidas_Hotel.csv"><img src="/images/pages/repository_small_file.png" alt="Dataset 1000 partidas" /></a></p>

<h1 id="programa-de-ia">Programa de IA</h1>

<p>Tras alimentar con el dataset y realizar el EDA correspondiente, he procedido a probar los modelos predictivos de IA que podrían ser más recomendables debido a la casuística en la que nos encontramos. Tras descartar, los que dabamos valores totalmente fuera de lugar, han sido: Adaboost, Naives Bayes, Decision Tree, Random Forest, XGBoost y 3 modelos diferente de deep learning (LSTM, Neuronal básica, Neuronal profunda).</p>

<p><strong>Evaluación y resultados</strong></p>

<table>
  <tbody>
    <tr>
      <td><strong>Modelo predictivo</strong></td>
      <td><strong>Tasa acierto</strong></td>
      <td><strong>Tase error</strong> *</td>
      <td><strong>Accuracy</strong></td>
    </tr>
    <tr>
      <td>Naives Bayes (Smooth 1e-10)</td>
      <td>66%</td>
      <td>40%</td>
      <td>0.66662</td>
    </tr>
    <tr>
      <td>Naives Bayes (Smooth 1e-7)</td>
      <td>91%</td>
      <td>75%</td>
      <td>0.90729</td>
    </tr>
    <tr>
      <td>Naives Bayes (Smooth 1e-11)</td>
      <td>65%</td>
      <td>40%</td>
      <td>0.65114</td>
    </tr>
    <tr>
      <td>Adaboost</td>
      <td>2%</td>
      <td>100%</td>
      <td>0.96112</td>
    </tr>
    <tr>
      <td>Decision Tree</td>
      <td>2%</td>
      <td>63%</td>
      <td>0.96113</td>
    </tr>
    <tr>
      <td>Adaboost</td>
      <td>2%</td>
      <td>100%</td>
      <td>0.96011</td>
    </tr>
    <tr>
      <td>Adaboost</td>
      <td>2%</td>
      <td>78%</td>
      <td>0.95977</td>
    </tr>
  </tbody>
</table>

<p><em>*en los diferenetes a ‘no compra’, es decir en la elección de la propiedad</em></p>

<p>Para ver los detalles de la evaluación y el programa de IA que contiene los resultados en :</p>

<p><a href="https://colab.research.google.com/drive/10rXkRiRnq59435RtOSICPrA1T2dXyxG6"><img src="/images/pages/repository_small_colab.png" alt="Programa IA" /></a></p>

<p><strong>Jugadores vs IA</strong></p>

<p>El resultado es que gana la IA entre un 40%-47% de las veces.</p>

<p>Para ver el programa que evalua la partida de jugadores aleatorios vs IA:</p>

<p><a href="https://colab.research.google.com/drive/1c-ozdgzMSYzZD2el46knjWx0SRIi-hMC"><img src="/images/pages/repository_small_colab.png" alt="Programa Jugadores vs IA" /></a></p>

<p>Los resultado de las partidas se encuentran aquí:</p>

<p><em>10 partidas - 100 partidas</em></p>

<p><a href="https://raw.githubusercontent.com/rubenarcos2/ia-juego_hotel/main/jugador_partidas_vs_ia/Diez_Partidas_Hotel-Jugadores_vs_IA.csv"><img src="/images/pages/repository_small_file.png" alt="Dataset 10 partidas" /></a>
<a href="https://github.com/rubenarcos2/ia-juego_hotel/raw/main/jugador_partidas_vs_ia/Cien_Partidas_Hotel-Jugadores_vs_IA.csv"><img src="/images/pages/repository_small_file.png" alt="Dataset 100 partidas" /></a></p>

<h1 id="programa-de-predicción">Programa de predicción</h1>

<p>He realizado en flask el programa de predicción, importando el modelo ya entrenado con <em>pickle</em> y creado un formulario web para la introducción de los datos necesarios para la predicción.</p>

<p><a href="https://hotel.rarcos.com">Aplicación web - https://hotel.rarcos.com</a></p>

<hr />

<p>Si quieres ver el resultado de todo, te recomiendo visites:</p>

<p><em>Repositorio con el contenido</em></p>

<p><em>Repositorio - Generador - Prog. IA - Jugadores vs IA</em></p>

<p><a href="https://github.com/rubenarcos2/ia-juego_hotel"><img src="/images/pages/repository_small.png" alt="Repositorio" /></a>
<a href="https://colab.research.google.com/drive/1KEqghfPGeuk9u5u8_s531CCb7869Hn3u"><img src="/images/pages/repository_small_colab.png" alt="Generador de partidas" /></a>
<a href="https://colab.research.google.com/drive/10rXkRiRnq59435RtOSICPrA1T2dXyxG6"><img src="/images/pages/repository_small_colab.png" alt="Programa IA" /></a>
<a href="https://colab.research.google.com/drive/1c-ozdgzMSYzZD2el46knjWx0SRIi-hMC"><img src="/images/pages/repository_small_colab.png" alt="Programa Jugadores vs IA" /></a></p>]]></content><author><name></name></author><category term="python" /><category term="naives bayes" /><category term="ia" /><category term="colab" /><summary type="html"><![CDATA[Creación de un sistema de IA para aprendizaje de la decisión de compra para el juego del Hotel]]></summary></entry></feed>