<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://rarcos.com/es/feed.xml" rel="self" type="application/atom+xml" /><link href="https://rarcos.com/es/" rel="alternate" type="text/html" /><updated>2025-09-27T15:30:20+02:00</updated><id>https://rarcos.com/feed.xml</id><title type="html">Rubén Arcos</title><subtitle>FullStack, AI &amp; Big Data developer</subtitle><entry xml:lang="es"><title type="html">Spring AI, Kafka, RAG y microservicios</title><link href="https://rarcos.com/es/2025/02/12/GMCCA_microservices/" rel="alternate" type="text/html" title="Spring AI, Kafka, RAG y microservicios" /><published>2025-02-12T19:00:00+01:00</published><updated>2025-02-12T19:00:00+01:00</updated><id>https://rarcos.com/2025/02/12/GMCCA_microservices</id><content type="html" xml:base="https://rarcos.com/2025/02/12/GMCCA_microservices/"><![CDATA[<p style="text-align: justify">
He realizado una aplicación basada en microservicios que permite la consulta de documentación de un producto (por ejemplo el manual de instrucciones en PDF) para poder obtener información mediante un chatbot. Utiliza la siguiente tecnología:
</p>

<ul>
  <li>Modelo de datos: <em>mxbai-embed-large</em>, extracción de texto y <em>ALIA</em> para el chat</li>
  <li>Ollama como gestor de los modelos de IA</li>
  <li>Chatbot opensource</li>
  <li>Frontend: React</li>
  <li>Backend: SpringBoot + Spring AI
    <ul>
      <li>Módulo de notificaciones (Kafka)</li>
      <li>Módulo de IA (RAG para le extracción de PDF y post-consulta de información)</li>
      <li>Módulo de inventario</li>
      <li>Módulo de pedidos</li>
      <li>Módulo de productos</li>
    </ul>
  </li>
</ul>

<p style="text-align: justify">
A continuación, vamos a ir viendo, de forma breve pero detallada, las principales tecnologías utilizadas en el proyecto, y finalmente veremos en detalle todo lo que he hecho en el proyecto. Comunicación entre módulos mediante Kafka, utilización de Kafka como trigger de eventos, la implementación de Spring AI con conexión a Ollama, y la arquitectura de microservicios... por mencionar algunos puntos relevantes.
</p>

<h1 id="qué-es-spring-ai">¿Qué es Spring AI?</h1>

<p>Es uno de los proyectos que tiene Spring, y que según su página web, lo definen como:</p>

<blockquote>
  <p>Spring AI is an application framework for AI engineering. Its goal is to apply to the AI domain Spring ecosystem design principles such as portability and modular design and promote using POJOs as the building blocks of an application to the AI domain.</p>
</blockquote>

<p>+info: <a href="https://spring.io/projects/spring-ai">https://spring.io/projects/spring-ai</a></p>

<p style="text-align: justify">
Forma parte del Spring Framework y está diseñado para facilitar la integración de funcionalidades de inteligencia artificial en aplicaciones sin complicaciones innecesarias. Spring AI proporciona abstracciones que permiten a los desarrolladores conectar datos empresariales y APIs con modelos de IA, facilitando la creación de aplicaciones que utilizan IA.
</p>

<h2 id="características">Características:</h2>

<ul>
  <li>Compatibilidad con todos los principales proveedores de modelos de IA, como Anthropic, OpenAI, Microsoft, Amazon, Google y Ollama.
    <ul>
      <li>Los tipos de modelos compatibles incluyen:
        <ul>
          <li><a href="https://docs.spring.io/spring-ai/reference/api/chatmodel.html">Chat</a></li>
          <li><a href="https://docs.spring.io/spring-ai/reference/api/embeddings.html">Embeddings</a></li>
          <li><a href="https://docs.spring.io/spring-ai/reference/api/imageclient.html">Texto a image</a></li>
          <li><a href="https://docs.spring.io/spring-ai/reference/api/audio/transcriptions.html">Transcripción de audio</a></li>
          <li><a href="https://docs.spring.io/spring-ai/reference/api/audio/speech.html">Texto a voz</a></li>
          <li><a href="https://docs.spring.io/spring-ai/reference/api/index.html#api/moderation">Moderación</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Admite la compatibilidad con APIs entre proveedores de IA para opciones de API sincrónicas y de transmisión. También está disponible el acceso a funciones específicas del modelo.</li>
  <li>Salidas estructuradas : mapeo de la salida del modelo de IA a POJO.</li>
  <li>Compatibilidad con los principales proveedores de bases de datos vectoriales, como Apache Cassandra, Azure Vector Search, Chroma, Milvus, MongoDB Atlas, Neo4j, Oracle, PostgreSQL/PGVector, PineCone, Qdrant, Redis y Weaviate.</li>
  <li>API entre proveedores de almacenamiento vectorial, incluida una novedosa API de filtro de metadatos similar a SQL .</li>
  <li>Llamada de herramientas/funciones : permite que el modelo solicite la ejecución de herramientas y funciones del lado del cliente, accediendo así a la información necesaria en tiempo real según sea necesario.</li>
  <li>Observabilidad : proporciona información sobre las operaciones relacionadas con la IA.</li>
  <li>Marco ETL de inyección de documentos para ingeniería de datos.</li>
  <li>Evaluación de modelos de IA : utilidades para ayudar a evaluar el contenido generado y proteger contra respuestas alucinógenas.</li>
  <li>API ChatClient : API fluida para comunicarse con modelos de chat de IA, idiomáticamente similar a las API WebClient y RestClient.</li>
  <li>API de asesores : encapsula patrones de IA generativa recurrentes, transforma los datos enviados hacia y desde los modelos de lenguaje (LLM) y proporciona portabilidad entre varios modelos y casos de uso.</li>
  <li>Soporte para memoria de conversación de chat y recuperación de generación aumentada (RAG) .</li>
  <li>Configuración automática de Spring Boot y arrancadores para todos los modelos de IA y tiendas vectoriales.</li>
</ul>

<h2 id="estado-actual">Estado actual</h2>

<p style="text-align: justify">
Se encuentra aún en la versión 1.0.0-SNAPSHOT, por lo que aún no está muy estandarizada y estable su utilización. Por lo que no lo recomiendo para uso en producción, puesto que yo mismo, he tenido algunos contratiempos y cambios durante la realización de este proyecto. Aunque es cierto que están en constante cambio y evolución. Se nota que están muy volcados en el proyecto de Spring AI.
</p>

<h2 id="documentación">Documentación</h2>

<p>La documentación más recomendada es la oficial, por lo expuesto anteriormente:</p>

<ul>
  <li><a href="https://spring.io/projects/spring-ai">https://spring.io/projects/spring-ai</a></li>
  <li><a href="https://docs.spring.io/spring-ai/reference/index.html">https://docs.spring.io/spring-ai/reference/index.html</a></li>
</ul>

<h1 id="qué-es-apache-kafka">¿Qué es Apache Kafka?</h1>

<p style="text-align: justify">
Es una plataforma de transmisión de datos distribuida de código abierto desarrollada por Apache Software Foundation. Se utiliza para construir pipelines de datos en tiempo real y aplicaciones de transmisión de datos. Kafka es altamente escalable, tolerante a fallos y está diseñado para manejar flujos de datos grandes y en tiempo real. Es popular en grandes empresas tecnológicas para la gestión de datos y análisis en tiempo real.
</p>

<blockquote>
  <p>More than 80% of all Fortune 100 companies trust, and use Kafka.</p>
</blockquote>

<blockquote>
  <p>Apache Kafka is an open-source distributed event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.</p>
</blockquote>

<p>+info: <a href="https://kafka.apache.org/">https://kafka.apache.org/</a></p>

<p style="text-align: justify">
Apache Kafka es la alternativa a un sistema de mensajería tradicional para empresas. Comenzó como un sistema interno que LinkedIn desarrolló para gestionar 1,4 billones de mensajes por día. Ahora, es una solución open source de transmisión de datos que permite satisfacer diversas necesidades empresariales.
</p>

<h2 id="por-qué-se-desarrolla">¿Por qué se desarrolla?</h2>

<p style="text-align: justify">
Debido a la irrupción de la arquitectura de microservicios en el mundo del desarrollo, se reducen las dependencias y se pasa del uso compartido de una base de datos centralizada por unas más pequeñas, específicas e incluso modulares. Pero aún se requieren métodos para compartir datos. Un método popular es el uso de APIs sincrónicas. Sin embargo, la integración asíncrona, que utiliza un <b>almacén intermedio</b>, ofrece una alternativa eficiente.
</p>

<p style="text-align: justify">
Apache Kafka juega un papel crucial al transmitir datos entre equipos de desarrollo para llenar este almacén de datos, lo que facilita el intercambio de información. Los equipos de microservicios requieren integraciones distribuidas, API y contenedores para adaptarse a sus necesidades específicas. Lo que permite utilizar tanto métodos sincrónicos como asíncronos según sea necesario.
</p>

<p style="text-align: justify">
Apache Kafka es especialmente útil para la <b>integración basada en eventos asíncronos, que complementa el uso de APIs sincrónicas</b>, mejora los microservicios y favorece la integración ágil. Esto optimiza el desarrollo, impulsa la innovación, ahorra tiempo y acelera la comercialización de nuevas funciones, aplicaciones y servicios.
</p>

<p>Recomiendo leer este <a href="https://www.redhat.com/es/topics/integration/what-is-apache-kafka">artículo</a> publicado por Red Hat en el que explican las características de Kafka y las necesidades por las que se desarrolló.</p>

<h1 id="qué-es-la-arquitectura-de-microservicios">¿Qué es la arquitectura de microservicios?</h1>

<p style="text-align: justify">
La arquitectura de microservicios es un estilo de diseño de software que organiza una aplicación como una colección de pequeños servicios autónomos, cada uno de los cuales ejecuta un proceso único y se comunica a través de interfaces ligeras, a menudo APIs HTTP o mensajería como Apache Kafka.
</p>

<h2 id="beneficios-de-la-arquitectura-de-microservicios">Beneficios de la arquitectura de microservicios</h2>

<ol>
  <li>Escalabilidad: Cada microservicio puede escalarse de manera independiente en función de su demanda. Esto significa que solo se necesita aumentar los recursos de los servicios que realmente lo requieren, mejorando la eficiencia.</li>
  <li>Flexibilidad en el Desarrollo: Diferentes equipos pueden trabajar en distintos microservicios utilizando diferentes tecnologías y lenguajes de programación adecuados para cada caso.</li>
  <li>Resiliencia: Si un microservicio falla, no necesariamente afecta a toda la aplicación. Otros servicios pueden seguir funcionando, lo que mejora la disponibilidad general del sistema.</li>
  <li>Ciclo de Vida Independiente: Los microservicios pueden implementarse, actualizarse y escalarse de manera independiente, lo que permite un desarrollo más ágil y una entrega continua.</li>
  <li>Facilidad de Mantenimiento: Debido a su tamaño reducido, los microservicios son más fáciles de entender, probar y mantener. Los errores se localizan y solucionan más rápido.</li>
  <li>Innovación Rápida: Las pequeñas unidades de código permiten a los equipos introducir nuevas funciones y tecnologías rápidamente, fomentando la innovación continua.</li>
</ol>

<p style="text-align: justify">
La arquitectura de microservicios es especialmente ventajosa para grandes aplicaciones que requieren un desarrollo y despliegue rápidos y flexibles. Sin embargo, también introduce desafíos, como la gestión de la comunicación entre servicios y la necesidad de una infraestructura adecuada para soporte.
</p>

<hr />

<p>Y ahora que sabemos con qué tecnologías trabajaremos.</p>

<h1 id="vamos-a-comenzar-con-el-proyecto">¡Vamos a comenzar con el proyecto!</h1>

<h2 id="arquitectura">Arquitectura</h2>

<p>Esta es la arquitectura que se ha utilizado en el proyecto de microservicios:</p>

<p><img src="/images/pages/gmcca_microservices_architecture.jpg" alt="GMCCA Microservices Architecture" title="GMCCA Microservices arquitectura" /></p>

<p>Se ha tendido en cuenta en todo momento los principios de la arquitectura de microservicios. Manteniendo bases de datos independientes, favoreciendo su escalabilidad. Realizando las comunicaciones entre microservicios de forma eficiente y mantenible en el ciclo de vida. Así como, la resiliencia del proyecto, permitiendo la tolerancia ante fallos de los microservicios de forma independiente.</p>

<h3 id="módulo-de-productos">Módulo de productos</h3>

<p>Este módulo está pensado para realizar las operaciones CRUD de un almacén de productos.</p>

<p>Actualmente solo están implementados los métodos: <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_products/src/main/java/com/rarcos/gmcca_products/controller/ProductController.java">addProduct, getAllProducts, getProductByCode y changeStatusProduct</a>.</p>

<p>Los datos son almacenados en una base de datos PostgreSQL, para este módulo.</p>

<h3 id="módulo-de-pedidos">Módulo de pedidos</h3>

<p>Este módulo está pensado para realizar las operaciones CRUD de un pedido de productos (con los datos de producto, un precio y una cantidad dadas).</p>

<p>Actualmente solo están implementados los métodos: <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_orders/src/main/java/com/rarcos/gmcca_orders/controllers/OrderController.java">placeOrder y getOrders</a>.</p>

<p>El servicio <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_orders/src/main/java/com/rarcos/gmcca_orders/services/OrderService.java">placeOrder</a>, tiene la peculiaridad, que realiza una comprobación mediante <a href="https://docs.spring.io/spring-framework/reference/web/webflux-webclient.html">WebClient</a> al módulo de inventario. Esta comprobación consiste, en la realización de una consulta al stock del producto, para ver si hay disponibilidad en el almacén.
También, realiza el envío de una notificación, mediante Kafka, para advertir de que se ha realizado el pedido (con su número, cantidad de productos y el estado del mismo).</p>

<p>Los datos son almacenados en una base de datos PostgreSQL, para este módulo.</p>

<h3 id="módulo-de-inventario">Módulo de inventario</h3>

<p>Este módulo está pensado para realizar las operaciones CRUD de un inventario de productos (con los datos del código de producto y una cantidad dadas).</p>

<p>Actualmente solo están implementados los métodos: <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_inventory/src/main/java/com/rarcos/gmcca_inventory/controllers/InventoryController.java">isInStock y areInStock</a>.</p>

<p>El servicio <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_inventory/src/main/java/com/rarcos/gmcca_inventory/services/InventoryService.java">InventoryService</a>, se encarga de devolver el stock para un código de producto o bien para un pedido completo.</p>

<p>Los datos son almacenados en una base de datos PostgreSQL, para este módulo.</p>

<h3 id="módulo-de-notificaciones">Módulo de notificaciones</h3>

<p>Su finalidad principal, es la comunicación con la cola de mensajería Kafka y con el WebSocket web.</p>

<p>Dispone de dos disparadores de eventos: para el estado de <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_notifications/src/main/java/com/rarcos/gmcca_notifications/events/DocProcessEvent.java">procesamiento de la extracción</a> del documento PDF mediante IA y en el <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_notifications/src/main/java/com/rarcos/gmcca_notifications/events/OrderEvent.java">estado del pedido</a>.</p>

<p>También se han implementado los listeners de: <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_notifications/src/main/java/com/rarcos/gmcca_notifications/listeners/DocProcessEventListener.java">procesado de documento</a>, <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_notifications/src/main/java/com/rarcos/gmcca_notifications/listeners/OrderEventListener.java">pedido</a> y <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_notifications/src/main/java/com/rarcos/gmcca_notifications/listeners/WebSocketEventListener.java">WebSocket</a>.</p>

<ul>
  <li>handleDocProcessNotifications:
    <ul>
      <li>Emite una notificación al WebSocket con el estado del proceso que está realizando la extracción del texto del documento PDF mediante IA.</li>
      <li>Consulta un producto por su código y cambia el estado de ese producto según esté o no disponible para su visualización web. Es decir, si tiene o no un manual PDF relacionado con el producto.</li>
    </ul>
  </li>
  <li>handleOrdersNotifications:
    <ul>
      <li>Emite una notificación al WebSocket con el estado del pedido.</li>
    </ul>
  </li>
  <li>handleWebSocketConnectListener y handleWebSocketDisconnectListener.</li>
</ul>

<h3 id="módulo-de-ia-rag">Módulo de IA-RAG</h3>

<p>Las <a href="https://github.com/rubenarcos2/gmcca_microservices/blob/main/backend/gmcca_microservices/gmcca_ia_rag/src/main/java/com/rarcos/gmcca_ia_rag/controllers/DocsController.java">funciones</a> que realiza este módulo son:</p>

<ul>
  <li>La extracción de texto de un documento PDF mediante IA (modelo mxbai-embed-large)</li>
  <li>El almacenamiento de dicha información en una base de datos vectorial (PGVector)</li>
  <li>El almacenamiento del documento PDF en una base de datos documental (MongoDB)</li>
  <li>La descarga del documento PDF (visor)</li>
  <li>El chatbot basado en IA (comunicado con Ollama)</li>
</ul>

<h2 id="entorno-de-ejecución---frontend">Entorno de ejecución - Frontend</h2>

<p>La página web se encuentra <strong>aún en desarrollo</strong>.</p>

<p>En este momento solamente tiene las funcionalidades:</p>

<ul>
  <li>Subir/Descargar documentos PDF</li>
  <li>Extracción de la información del PDF mediante IA</li>
  <li>Notificaciones mediante WebSocket</li>
  <li>Acceso al chatbot, solamente mediante API web (no está en la web aún)</li>
  <li>CRUD de productos (no está en la web aún)</li>
  <li>CRUD de pedidos (no está en la web aún)</li>
</ul>

<p style="text-align: center">
<a href="https://gmcca-microservices.rarcos.com/" target="_blank">
    <img src="/images/pages/gesmerca.png" width="100" alt="GMCCA Logo" /> Demo online
</a>
</p>

<hr />

<p><em>Repositorio con el contenido</em></p>

<p><a href="https://github.com/rubenarcos2/gmcca_microservices"><img src="/images/pages/repository_small.png" alt="Repository" /></a></p>

<hr />

<p><strong>Fuentes:</strong></p>

<ul>
  <li><a href="https://spring.io/projects/spring-ai">https://spring.io/projects/spring-ai</a></li>
  <li><a href="https://docs.spring.io/spring-ai/reference/index.html">https://docs.spring.io/spring-ai/reference/index.html</a></li>
  <li><a href="https://kafka.apache.org/">https://kafka.apache.org/</a></li>
  <li><a href="https://www.redhat.com/es/topics/integration/what-is-apache-kafka">https://www.redhat.com/es/topics/integration/what-is-apache-kafka</a></li>
  <li><a href="https://www.youtube.com/playlist?list=PLlYjHWCxjWmAt5hE3OEaemlWkZBZa7w4e">https://www.youtube.com/playlist?list=PLlYjHWCxjWmAt5hE3OEaemlWkZBZa7w4e</a></li>
  <li><a href="https://www.youtube.com/watch?v=q2zTo21PEMU">https://www.youtube.com/watch?v=q2zTo21PEMU</a></li>
  <li><a href="https://www.youtube.com/watch?v=UbbyW5Z1lv8">https://www.youtube.com/watch?v=UbbyW5Z1lv8</a></li>
  <li><a href="https://www.baeldung.com/ops/kafka-docker-setup">https://www.baeldung.com/ops/kafka-docker-setup</a></li>
  <li><a href="https://virendraoswal.com/getting-started-with-spring-ai-and-ollama-a-quick-guide-to-using-microsoft-phi3-language-models">https://virendraoswal.com/getting-started-with-spring-ai-and-ollama-a-quick-guide-to-using-microsoft-phi3-language-models</a></li>
  <li><a href="https://erkanyasun.medium.com/simplifying-file-uploads-in-spring-boot-with-multipartfile-eb8bbef68dfe">https://erkanyasun.medium.com/simplifying-file-uploads-in-spring-boot-with-multipartfile-eb8bbef68dfe</a></li>
  <li><a href="https://github.com/spring-projects/spring-ai/issues/356">https://github.com/spring-projects/spring-ai/issues/356</a></li>
  <li><a href="https://www.baeldung.com/spring-boot-mongodb-upload-file">https://www.baeldung.com/spring-boot-mongodb-upload-file</a></li>
</ul>]]></content><author><name></name></author><category term="ai" /><category term="kafka" /><category term="spring ai" /><category term="rag" /><category term="microservices" /><summary type="html"><![CDATA[Útilización de IA para la extracción de texto de documentos, con una arquitectura en microservicios con comunicación, entre módulos y de notificaciones, mediante Kafka y un chat de IA para la consulta de la información del documento.]]></summary></entry><entry xml:lang="es"><title type="html">ALIA en Ollama (y cualquier modelo externo)</title><link href="https://rarcos.com/es/2025/01/22/ALIA_on_Ollama/" rel="alternate" type="text/html" title="ALIA en Ollama (y cualquier modelo externo)" /><published>2025-01-22T17:00:00+01:00</published><updated>2025-01-22T17:00:00+01:00</updated><id>https://rarcos.com/2025/01/22/ALIA_on_Ollama</id><content type="html" xml:base="https://rarcos.com/2025/01/22/ALIA_on_Ollama/"><![CDATA[<p>Hace un tiempo, publiqué un artículo en el que veíamos <a href="https://rarcos.com/es/2024/05/25/Ollama_api_chatbot/">cómo instalar Ollama y cómo crear un ChatBot</a> que utilizase sus servicios. 
Pues ahora vamos a ver cómo crear un modelo de datos obtenido de una fuente externa, a diferencia de los modelos que ya se encuentran preparados en la <a href="https://ollama.com/library">librería de Ollama</a>.</p>

<p>En nuestro caso vamos a utilizar el modelo ALIA, el primer modelo en español, que acaba de lanzarse para su uso.</p>

<p>Antes de nada, comentar los requisitos del modelo:</p>

<ul>
  <li>Memoria del sistema: 76.5 GiB</li>
  <li>Tamaño del modelo: 150 Gb</li>
  <li>Tamaño del modelo convertido para ollama: 75,3 GB</li>
</ul>

<p>Tras ello, lo primero que vamos a hacer es localizar el modelo y proceder a su descarga:</p>

<h1 id="descarga-del-modelo-alia">Descarga del modelo ALIA</h1>

<p>En Hugging Face tenemos los modelos ofrecidos por el Barcelona Supercomputing Center. En nuestro caso nos interesan 3 modelos:</p>

<ul>
  <li><a href="https://huggingface.co/BSC-LT/ALIA-40b">ALIA-40b</a></li>
  <li><a href="https://huggingface.co/BSC-LT/salamandra-7b">Salamandra-7b</a></li>
  <li><a href="https://huggingface.co/BSC-LT/salamandra-2b">Salamandra-2b</a></li>
</ul>

<h2 id="clonado-del-repositorio-de-alia">Clonado del repositorio de ALIA</h2>

<p>Abrimos una terminal y en el directorio que deseamos realizar la descarga, introducimos:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Make sure you have git-lfs installed (https://git-lfs.com)
git lfs install

git clone https://huggingface.co/BSC-LT/ALIA-40b
</code></pre></div></div>

<h1 id="cómo-crear-el-modelo-de-alia-en-ollama">¿Cómo crear el modelo de ALIA en ollama?</h1>

<p>Esta tarea que puede parecernos compleja, no lo es realmente, se trata solamente de ejecutar 3 comandos.</p>

<p>En primer lugar vamos a crear un fichero (dentro del directorio donde hemos descargado el modelo, junto con los ficheros descargados) denominado <code class="language-plaintext highlighter-rouge">Modelfile</code> y su contenido será el siguiente: <code class="language-plaintext highlighter-rouge">FROM .</code></p>

<p>Nuestro árbol de directorio quedará así:</p>

<p><img src="/images/pages/arbol_directorio_alia.png" alt="arbol_alia" /></p>

<h2 id="creación-del-modelo-en-ollama">Creación del modelo en Ollama</h2>

<p>Para ello, vamos a ejecutar el siguiente comando, ubicados en la misma carpeta anterior:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ollama create alia40b
</code></pre></div></div>

<p><img src="/images/pages/alia_create_model_process.png" alt="arbol_alia" /></p>

<p>Una vez finalizado, comprobamos que se ha creado el modelo correctamente, viendo la lista de modelos instalados:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ollama list
</code></pre></div></div>

<p><img src="/images/pages/alia_list_model.png" alt="arbol_alia" /></p>

<h2 id="ejecución-del-modelo-en-ollama">Ejecución del modelo en Ollama</h2>

<p>Por último, vamos a ejecutar el modelo y así poder interactuar con él:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ollama run alia40b
</code></pre></div></div>

<p><img src="/images/pages/alia_execute_model.png" alt="arbol_alia" /></p>

<h1 id="modelo-listo-para-descargar-de-salamandra-7b">Modelo listo para descargar de salamandra 7b</h1>
<p>En el <a href="https://huggingface.co/BSC-LT/salamandra-7b-instruct/discussions/7#67923b3de75ed5c939ae48b49">hilo</a> de Hugging Face se encuentra un modelo listo para su descarga de salamandra-7b-instruct, con el que podrás probar su funcionamiento directamente:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ollama run hdnh2006/salamandra-7b-instruct

</code></pre></div></div>

<hr />

<p><strong>Fuentes:</strong></p>
<ul>
  <li><a href="https://github.com/ollama/ollama/blob/main/docs/import.md">https://github.com/ollama/ollama/blob/main/docs/import.md</a></li>
  <li><a href="https://huggingface.co/BSC-LT/salamandra-7b-instruct/discussions/7">https://huggingface.co/BSC-LT/salamandra-7b-instruct/discussions/7</a></li>
</ul>]]></content><author><name></name></author><category term="ai" /><category term="rag" /><category term="open source" /><category term="models" /><summary type="html"><![CDATA[Vamos a ver cómo crear un modelo de datos obtenido de una fuente externa, a diferencia de los modelos que ya se encuentran preparados en la librería de Ollama, en nuestro caso crearemos el modelo ALIA en Ollama.]]></summary></entry><entry xml:lang="es"><title type="html">ALIA el modelo español de IA</title><link href="https://rarcos.com/es/2025/01/21/ALIA_a_spanish_model/" rel="alternate" type="text/html" title="ALIA el modelo español de IA" /><published>2025-01-21T07:23:28+01:00</published><updated>2025-01-21T07:23:28+01:00</updated><id>https://rarcos.com/2025/01/21/ALIA_a_spanish_model</id><content type="html" xml:base="https://rarcos.com/2025/01/21/ALIA_a_spanish_model/"><![CDATA[<h1 id="qué-es-alia">¿Qué es ALIA?</h1>

<p><img src="/images/pages/logo_alia.png" alt="Logo" /></p>

<p style="text-align: justify">
ALIA o también conocida como 'ALIA-40b' es el nuevo modelo de inteligencia artificial español y el primero de Europa. ALIA es un gran modelo de lenguaje de inteligencia artificial, entrenado en español, catalán, gallego, euskera. El proyecto está completamente financiado con fondos públicos. 

Se han creado varios modelos para su uso: ALIA-40b, salamandra-7B y salamandra-2B de parámetros.
</p>

<h2 id="qué-es-un-modelo-de-ia-según-copilot">¿Qué es un modelo de IA (según copilot)?</h2>

<p style="text-align: justify">
Un modelo de IA (Inteligencia Artificial) es un sistema que ha sido entrenado para realizar tareas específicas o generales, utilizando datos y algoritmos avanzados. Estos modelos pueden ser utilizados para una amplia gama de aplicaciones, como el reconocimiento de imágenes, el procesamiento del lenguaje natural y la toma de decisiones.
</p>

<h2 id="qué-es-un-llm-según-copilot">¿Qué es un LLM (según copilot)?</h2>

<p style="text-align: justify">
Un LLM (Large Language Model), o modelo de lenguaje grande, es un tipo específico de modelo de IA diseñado para procesar y generar texto. Estos modelos son entrenados con enormes cantidades de texto y utilizan técnicas avanzadas para comprender y generar lenguaje humano de manera coherente y contextual.
</p>

<h2 id="prueba-en-colab-del-modelo-7b">Prueba en Colab del modelo 7B</h2>
<p>He realizado una prueba para ver que tal funciona:</p>

<p><a href="https://colab.research.google.com/drive/1iNebMKb4bR8kLqm52qH22DYcNjbo4ebW"><img src="/images/pages/repository_small_colab.png" alt="Programa IA" /></a></p>

<h2 id="qué-arquitectura-tiene">¿Qué arquitectura tiene?</h2>

<table>
  <thead>
    <tr>
      <th>Total Parameters</th>
      <th style="text-align: left">40,433,885,184</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Embedding Parameters</td>
      <td style="text-align: left">2,097,152,000</td>
    </tr>
    <tr>
      <td>Layers</td>
      <td style="text-align: left">48</td>
    </tr>
    <tr>
      <td>Hidden size</td>
      <td style="text-align: left">8,192</td>
    </tr>
    <tr>
      <td>Attention heads</td>
      <td style="text-align: left">64</td>
    </tr>
    <tr>
      <td>Context length</td>
      <td style="text-align: left">4,096</td>
    </tr>
    <tr>
      <td>Vocabulary size</td>
      <td style="text-align: left">256,000</td>
    </tr>
    <tr>
      <td>Precision</td>
      <td style="text-align: left">bfloat16</td>
    </tr>
    <tr>
      <td>Embedding type</td>
      <td style="text-align: left">RoPE</td>
    </tr>
    <tr>
      <td>Activation Function</td>
      <td style="text-align: left">SwiGLU</td>
    </tr>
    <tr>
      <td>Layer normalization</td>
      <td style="text-align: left">RMS Norm</td>
    </tr>
    <tr>
      <td>Flash attention</td>
      <td style="text-align: left">✅</td>
    </tr>
    <tr>
      <td>Grouped Query Attention</td>
      <td style="text-align: left">✅</td>
    </tr>
    <tr>
      <td>Num. query groups</td>
      <td style="text-align: left">8</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h2 id="con-qué-ha-sido-entrenada">¿Con qué ha sido entrenada?</h2>

<p style="text-align: justify">
El entrenamiento previo se realizó utilizando NeMo Framework de NVIDIA, que aprovecha PyTorch Lightning para un entrenamiento de modelos eficiente en entornos altamente distribuidos.

Las versiones optimizadas con instrucciones se produjeron con FastChat.
</p>

<h3 id="datos">Datos</h3>
<h4 id="datos-de-preentrenamiento">Datos de preentrenamiento</h4>

<p style="text-align: justify">
El corpus de preentrenamiento comprende datos de 35 idiomas europeos y 92 lenguajes de programación, con fuentes de datos detalladas que se proporcionan a continuación. Las 1,5 épocas de entrenamiento iniciales utilizaron 2,4 billones de tokens, obtenidos mediante el ajuste manual de la proporción de datos para equilibrar la representación y dar más importancia a los idiomas cooficiales de España (español, catalán, gallego y vasco). De esta manera, redujimos el código y los datos en inglés a la mitad, los idiomas cooficiales españoles se sobremuestrearon en un doble y los idiomas restantes se mantuvieron en sus proporciones originales. A continuación, durante las siguientes épocas (aún en entrenamiento), el conjunto de datos Colossal OSCAR se reemplazó con el conjunto de datos FineWebEdu. Este ajuste dio como resultado un total de 2,68 billones de tokens, distribuidos como se describe a continuación:
</p>

<p>
<img src="/images/pages/images_corpus_languages_alia.png" />
</p>

<p style="text-align: justify">
El corpus de preentrenamiento está compuesto predominantemente por datos de Colossal OSCAR, que contribuye con un significativo 53,05% del total de tokens. A continuación, Starcoder proporciona el 13,67% y FineWebEdu (subconjunto de 350 mil millones de tokens) agrega el 10,24%. Las siguientes fuentes más importantes son HPLT con un 4,21% y French-PD con un 3,59%. Otras contribuciones notables incluyen MaCoCu, Legal-ES y EurLex, cada una de las cuales contribuye con alrededor del 1,72% al 1,41%. Estas fuentes principales forman colectivamente la mayor parte del corpus, lo que garantiza un conjunto de datos rico y diverso para entrenar el modelo de lenguaje. El 10% restante proviene de fuentes más pequeñas en varios idiomas.
</p>

<h3 id="infraestructura-informática">Infraestructura informática</h3>

<p>Todos los modelos fueron entrenados en MareNostrum 5, un superordenador EuroHPC pre-exascale alojado y operado por el Barcelona Supercomputing Center.</p>

<p>La partición acelerada está compuesta por 1.120 nodos con las siguientes especificaciones:</p>

<ul>
  <li>4 GPU Nvidia Hopper con memoria HBM2 de 64 GB</li>
  <li>2 procesadores Intel Sapphire Rapids 8460Y+ a 2,3 GHz y 32 c cada uno (64 núcleos)</li>
  <li>4x NDR200 (BW por nodo 800 Gb/s)</li>
  <li>512 GB de memoria principal (DDR5)</li>
  <li>460 GB en almacenamiento NVMe</li>
</ul>

<table>
  <thead>
    <tr>
      <th>Modelo</th>
      <th>Nodos</th>
      <th>GPU</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2B</td>
      <td>64</td>
      <td>256</td>
    </tr>
    <tr>
      <td>7B</td>
      <td>128</td>
      <td>512</td>
    </tr>
    <tr>
      <td>40B</td>
      <td>256 / 512</td>
      <td>1.024 / 2.048</td>
    </tr>
  </tbody>
</table>

<hr />

<p>Enlaces de interés:</p>

<ul>
  <li><a href="https://alia.gob.es/">Web oficial</a>.</li>
  <li><a href="https://langtech-bsc.gitbook.io/alia-kit/modelos/modelos-de-texto">Todos los modelos de texto</a></li>
  <li><a href="https://langtech-bsc.gitbook.io/alia-kit/modelos/modelos-de-traduccion-automatica">Todos los modelos de traducción</a></li>
  <li><a href="https://huggingface.co/spaces/BSC-LT/SalamandraTA-2B-Demo">Una demostración de traducción</a></li>
</ul>

<p>Ampliar información:</p>
<ul>
  <li><a href="https://www.rtve.es/noticias/20250120/alia-familia-modelos-inteligencia-artificial-pedro-sanchez/16414386.shtml">https://www.rtve.es/noticias/20250120/alia-familia-modelos-inteligencia-artificial-pedro-sanchez/16414386.shtml</a></li>
  <li><a href="https://www.xataka.com/robotica-e-ia/pedro-sanchez-anuncia-lanzamiento-primeros-modelos-alia-asi-ia-publica-abierta-que-impulsa-estado">https://www.xataka.com/robotica-e-ia/pedro-sanchez-anuncia-lanzamiento-primeros-modelos-alia-asi-ia-publica-abierta-que-impulsa-estado</a></li>
</ul>

<hr />

<p><strong>Fuentes:</strong></p>
<ul>
  <li><a href="https://huggingface.co/BSC-LT/ALIA-40b">https://huggingface.co/BSC-LT/ALIA-40b</a></li>
</ul>]]></content><author><name></name></author><category term="ai" /><category term="rag" /><category term="open source" /><category term="models" /><summary type="html"><![CDATA[Modelo de lenguaje basado en transformer que solo utiliza decoder y que ha sido entrenado previamente desde cero con 6,9 billones de tokens de datos cuidadosamente seleccionados. El corpus de preentrenamiento contiene texto en 35 idiomas europeos y código.]]></summary></entry><entry xml:lang="es"><title type="html">Chatbot opensource</title><link href="https://rarcos.com/es/2024/05/25/Ollama_api_chatbot/" rel="alternate" type="text/html" title="Chatbot opensource" /><published>2024-05-25T09:10:28+02:00</published><updated>2024-05-25T09:10:28+02:00</updated><id>https://rarcos.com/2024/05/25/Ollama_api_chatbot</id><content type="html" xml:base="https://rarcos.com/2024/05/25/Ollama_api_chatbot/"><![CDATA[<p>La creación de un chatbot para una página web, es una tarea que se suele contratar a un proveedor de servicios, pero en este caso voy a contar como se puede realizar de principio a fin y además con un conjunto de herramientas que son libres y gratuitas.</p>

<h1 id="creación-de-un-chatbot-con-modelo-opensource">Creación de un chatbot con modelo opensource</h1>

<p>Los bot de charla o bot conversacional (en inglés: chatbot), son aplicaciones software que surgen en los años 60, y que simulan mantener una conversación con una persona al proveer respuestas automáticas, las cuales son previamente establecidas por un conjunto de expertos a entradas realizadas por el usuario. Estos bot, también conocidos como sistemas expertos, utilizan el razonamiento basado en casos (CBR: case base reasoning).</p>

<p>Habitualmente, la conversación se establece mediante texto, aunque también hay modelos que disponen de una interfaz de usuario multimedia que permiten la entrada auditiva. Más recientemente, algunos comienzan a utilizar programas conversores de texto a sonido (CTV), dotando de mayor realismo a la interacción con el usuario y ayudando a reducir el tiempo de respuesta.</p>

<p>Para establecer una conversación, han de utilizarse frases fácilmente comprensibles y que sean coherentes, aunque la mayoría de los bot conversacionales no consiguen comprender del todo. En su lugar, tienen en cuenta las palabras o frases del interlocutor, que les permitirán usar una serie de respuestas preparadas de antemano. Estos son capaces de reconocer la manera en la que una frase está formulada gracias a una serie de patrones comparativos preestablecidos, y de este modo, basándose en las diferentes variables de dicha frase, presentan una respuesta correspondiente. De esta manera, el bot es capaz de seguir una conversación con más o menos lógica, pero sin saber realmente de qué está hablando.</p>

<blockquote>
  <p>Para tener más información te recomiendo visites el siguiente <a href="https://es.wikipedia.org/wiki/Bot_conversacional">artículo</a> de wikipedia de donde se ha obtenido este fragmento.</p>
</blockquote>

<h1 id="qué-es-retrieval-augmented-generation-rag">¿Qué es Retrieval-Augmented Generation (RAG)?</h1>

<p>Es el aumento de conocimiento que se aplica a un LLM con datos que no ha sido entrenado. Esto permite al sistema de IA generativa proporcionar respuestas contextualmente adecuadas a las consultas, así como basar dichas respuestas en datos extremadamente recientes.</p>

<p>En pocas palabras, la RAG ayuda a los LLM a proporcionar respuestas más idóneas.</p>

<p><strong>Conclusiones clave</strong></p>

<ul>
  <li>La RAG es una técnica de inteligencia artificial relativamente nueva que mejora la calidad de la IA generativa al permitir a grandes modelos de lenguaje (LLM) aprovechar recursos de datos adicionales sin necesidad de volver a entrenarlos.</li>
  <li>Los modelos RAG crean repositorios de conocimientos basados en los datos de la propia organización. Estos repositorios se pueden actualizar continuamente para ayudar a la IA generativa a brindar respuestas adaptadas al contexto y oportunas.</li>
  <li>Los chatbots y otros sistemas conversacionales que utilizan el procesamiento del lenguaje natural pueden beneficiarse enormemente de la RAG y la IA generativa.</li>
  <li>La implementación de RAG requiere tecnologías como bases de datos vectoriales, que permiten la codificación rápida de nuevos datos y la búsqueda en esos datos para alimentar el LLM.</li>
</ul>

<h2 id="cómo-funciona">¿Cómo funciona?</h2>

<p>Los datos de esa biblioteca de conocimientos se procesan en representaciones numéricas utilizando un tipo especial de algoritmo llamado modelo de lenguaje embebido y se almacenan en una base de datos vectorial, en la que se puede buscar rápidamente para recuperar la información contextual correcta.</p>

<blockquote>
  <p>Para tener más información te recomiendo visites el siguiente <a href="https://www.oracle.com/es/artificial-intelligence/generative-ai/retrieval-augmented-generation-rag/">artículo</a> de Oracle de donde se ha obtenido este fragmento.</p>
</blockquote>

<h1 id="arquitectura">Arquitectura</h1>

<p><img src="/images/pages/ollama_api_arquitectura.jpg" alt="Architecture" title="Ollama API Architecture" /></p>

<p>Nosotros vamos a ejecutar nuestro modelo LLM en un servidor local. Además vamos a tener la posibilidad de cambiar de modelo desde una interfaz amigable de administración, que nos permite descargarnos el modelo que deseemos utilizar e incluso poder probarlo con antelación. Por ello, he elegido <a href="https://ollama.com/">Ollama</a> que tiene un <a href="https://ollama.com/library">conjunto de modelos</a> opensource bastante interesante. Vamos a ir viendo paso a paso cómo ir instalando y configurando nuestro software.</p>

<p>Pero antes de nada, vamos a ver una breve descripción de cada uno de los elementos que vamos a instalar:</p>

<h2 id="ollama">Ollama</h2>

<p>Ollama hace que sea muy fácil ejecutar LLM de código abierto localmente. Puede esperar un rendimiento decente incluso en portátiles pequeños. Ollama es una alternativa a Hugging Face para ejecutar modelos localmente. Las bibliotecas de Hugging Face se ejecutan sobre Tensorflow o Torch. Ollama usa llama.cpp como tiempo de ejecución subyacente. Esto hace que sea muy fácil comenzar con Ollama. Ni siquiera necesitas tener Python instalado.</p>

<h2 id="langchain">LangChain</h2>

<p>LangChain es un marco de trabajo de código abierto para crear aplicaciones basadas en modelos de lenguaje de gran tamaño (LLM). Los LLM son grandes modelos de aprendizaje profundo entrenados previamente con grandes cantidades de datos que pueden generar respuestas a las consultas de los usuarios, por ejemplo, responder preguntas o crear imágenes a partir de peticiones basadas en texto. LangChain proporciona herramientas y abstracciones para mejorar la personalización, precisión y relevancia de la información que generan los modelos. Por ejemplo, los desarrolladores pueden usar los componentes de LangChain para crear nuevas cadenas de peticiones o personalizar las plantillas existentes. LangChain también incluye componentes que permiten a los LLM acceder a nuevos conjuntos de datos sin necesidad de repetir el entrenamiento.</p>

<blockquote>
  <p>Para tener más información te recomiendo visites el siguiente <a href="https://aws.amazon.com/es/what-is/langchain/">artículo</a> de AWS de donde se ha obtenido este fragmento.</p>
</blockquote>

<h2 id="chromadb">ChromaDb</h2>

<p>ChromaDB es una base de datos especializada en el almacenamiento y recuperación eficiente de información lingüística, incluyendo datos de texto, anotaciones semánticas y sintácticas. ChromaDB es particularmente útil para el almacenamiento y la gestión de grandes cantidades de datos de lenguaje natural, lo que permite a los desarrolladores aprovechar al máximo los avances en algoritmos de aprendizaje automático y análisis de texto.</p>

<blockquote>
  <p>Para tener más información te recomiendo visites el siguiente <a href="https://brainq.ai/chromadb/">artículo</a> de donde se ha obtenido este fragmento.</p>
</blockquote>

<h2 id="api-con-flask">API con Flask</h2>

<p>Flask es un micro marco de trabajo web de Python que proporciona las herramientas necesarias para crear aplicaciones web de manera rápida y sencilla. Aunque es un micro marco, Flask es altamente modular y permite agregar fácilmente extensiones para agregar funcionalidades adicionales.</p>

<blockquote>
  <p>Para tener más información te recomiendo visites el siguiente <a href="https://datascientest.com/es/programacion-de-api-web-en-python-con-flask">artículo</a> de donde se ha obtenido este fragmento y donde puedes seguir el tutorial detallado de como crear una API con Flask.</p>
</blockquote>

<h2 id="el-chatbot-web">El Chatbot web</h2>

<p>Me he basado en esta integración de un chatbot web, para utilizar los recursos y adaptarlo a nuestro modelo opensource alojado en Ollama.</p>

<p>El código fuente se encuentra <a href="https://github.com/galaxyofai/chatgpt_flask_webapp">aquí</a>.</p>

<p>Y un explicación detallada de como integrarlo con otras API, se encuentra <a href="https://galaxyofai.com/building-a-flask-chat-web-app-with-openais-chatgpt-api/">aquí</a>.</p>

<h1 id="la-demostración">La demostración</h1>

<p>A continuación se ha embebido la aplicación realizada. Esta está alojada en un servidor de unas características muy limitadas para la ejecución de desarrollos de inteligencia artificial. Pero como demostración de que es posible, aquí se encuentra en funcionamiento:</p>

<blockquote>
  <p><img src="/images/pages/aviso_icon.png" alt="Aviso" /> <strong>El chatbot está alojado en un servidor con pocos recursos.</strong><br /><br />Por ello tarda bastante en contestar. Es precisamente lo que se busca, demostrar la viabilidad en este tipo de entornos.</p>
</blockquote>

<p>Preguntas de ejemplo que puede realizar:</p>
<ul>
  <li>¿Qué experiencia tiene Rubén Arcos?</li>
  <li>¿Cuántos años de experiencia tiene Rubén Arcos?</li>
  <li>¿Qué lenguajes de programación sabe Rubén Arcos?</li>
</ul>

<p><em>Haga clic sobre la burbuja morada, para abrir el Chatbot</em></p>

<p style="text-align: center">
  <iframe style="border: 0" id="chatbot" title="Chatbot" width="390" height="600" src="https://chat.rarcos.com/">
  </iframe>
</p>

<h1 id="el-tutorial">El tutorial</h1>

<p>Como viene siendo habitual en esta página web, vamos a utilizar un entorno dockerizado que será el encargado de levantar Ollama, el administrador web de Ollama y nuestra aplicación de ChatBot web.</p>

<p>Para ello tenemos los siguiente scripts de <em>docker compose</em>:</p>

<h3 id="script-de-ejecución-más-completo-sin-gpu">Script de ejecución más completo (sin GPU)</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>version: '3.8'
services:
  app:
    build: .
    container_name: ollama-app
    ports:
      - 8002:8002
      - 5678:5678
    volumes:
      - ./app:/usr/src/app/
    command: python app.py
    restart: always
    depends_on:
      - ollama
      - ollama-webui
    networks:
      - ollama-docker

  ollama:
    image: ollama/ollama:latest
    ports:
      - 11434:11434
    volumes:
      - .:/code
      - ./ollama/ollama:/root/.ollama
    container_name: ollama
    pull_policy: always
    tty: true
    restart: always
    networks:
      - ollama-docker

  ollama-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: ollama-webui
    volumes:
      - ./ollama/ollama-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
      - 8080:8080
    environment:
      - '/ollama/api=http://ollama:11434/api'
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped
    networks:
      - ollama-docker

networks:
  ollama-docker:
    external: false

</code></pre></div></div>

<h3 id="el-script-mínimo-sin-gpu">El script mínimo (sin GPU)</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>services:

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    tty: true
    restart: unless-stopped
    # Expose Ollama API outside the container stack
    ports:
      - 11434:11434
      - 53:53
    volumes:
      - ollama:/root/.ollama
    command: pip install -r requirements.txt

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    volumes:
      - open-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
      - 8080:8080
    environment:
      - "OLLAMA_API_BASE_URL=http://ollama:11434/api"
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped

volumes:
  ollama: {}
  open-webui: {}
</code></pre></div></div>
<h3 id="el-script-para-utilización-de-gpu">El script para utilización de GPU</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>version: '3.8'

services:
  app:
    build: .
    ports:
      - 8000:8000
      - 5678:5678
    volumes:
      - .:/code
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
    restart: always
    depends_on:
      - ollama
      - ollama-webui
    networks:
      - ollama-docker
      
  ollama:
    volumes:
      - ./ollama/ollama:/root/.ollama
    container_name: ollama
    pull_policy: always
    tty: true
    restart: unless-stopped
    image: ollama/ollama:latest
    ports:
      - 11434:11434
    networks:
      - ollama-docker
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  ollama-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: ollama-webui
    volumes:
      - ./ollama/ollama-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
      - 8080:8080
    environment:
      - '/ollama/api=http://ollama:11434/api'
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped
    networks:
      - ollama-docker

networks:
  ollama-docker:
    external: false

</code></pre></div></div>

<p>Las rutas de acceso que se establecen son:</p>
<ul>
  <li>Página web de administración de Ollama: <a href="http://localhost:8080">http://localhost:8080</a></li>
  <li>Motor de Ollana: <a href="http://localhost:11434">http://localhost:11434</a></li>
  <li>Aplicación web: <a href="http://localhost:8002">http://localhost:8002</a></li>
</ul>

<blockquote>
  <p>Para tener más información te recomiendo visites el siguiente <a href="https://github.com/valiantlynx/ollama-docker/">repositorio</a> de donde se ha obtenido este script y donde hay más ejemplos e información.</p>
</blockquote>

<h3 id="la-instalación-del-modelo-desde-el-administrador-web-de-ollama">La instalación del modelo desde el administrador web de Ollama</h3>

<p>Una vez tenemos el docker levantado, tan solo tenemos que entrar a la url <a href="http://localhost:8080">http://localhost:8080</a>, descargar e instalar el modelo.</p>

<p>A continuación se muestra un video de cómo se realiza:</p>

<p><img src="/images/pages/ollama_install.gif" alt="video" /></p>

<p>En nuestro caso introduciremos el modelo: <em>mistral:instruct</em></p>

<h3 id="la-aplicación-en-consola-el-chatbot">La aplicación en consola (el chatbot)</h3>

<p>Luego tenemos la aplicación en consola que consume el modelo LLM, en nuestro ejemplo se ha utilizado <em>Mistral</em> por sus gran rendimiento similar a Llama y por ser opensource. También tenemos la especificación del promt de consulta, con unas instrucciones previas a las consultas. Y el método de entrenamiento RAG.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langchain_community.vectorstores import Chroma
from langchain_community.chat_models import ChatOllama
from langchain_community.embeddings.fastembed import FastEmbedEmbeddings
from langchain_community.document_loaders import WebBaseLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
import sys
 
class ChatWebDoc:
    vector_store = None
    retriever = None
    chain = None
 
    def __init__(self):
        self.model = ChatOllama(model="mistral:instruct")
        #Loading embedding
        self.embedding = FastEmbedEmbeddings()
 
        self.text_splitter = CharacterTextSplitter(chunk_size=1024, chunk_overlap=100)
        self.prompt = ChatPromptTemplate.from_messages(
        [
            ("system", 
"""You are an assistant for question-answering tasks. Use only the following 
context to answer the question. If you don't know the answer, just say that you don't know.
 
CONTEXT:
 
{context}
"""),
            ("human", "{input}"),
        ]
    )
 
    def ingest(self, url_list):
        #Load web pages
        docs = WebBaseLoader(url_list).load()
        chunks = self.text_splitter.split_documents(docs)
 
        #Create vector store
        vector_store = Chroma.from_documents(documents=chunks, 
            embedding=self.embedding, persist_directory="./chroma_db")
 
    def load(self):
        #Load vector store
        vector_store = Chroma(persist_directory="./chroma_db", 
            embedding_function=self.embedding)
 
        #Create chain
        self.retriever = vector_store.as_retriever(
            search_type="similarity_score_threshold",
            search_kwargs={
                "k": 3,
                "score_threshold": 0.5,
            },
        )
 
        document_chain = create_stuff_documents_chain(self.model, self.prompt)
        self.chain = create_retrieval_chain(self.retriever, document_chain)
 
    def ask(self, query: str):
        if not self.chain:
            self.load()
 
        result = self.chain.invoke({"input": query})
 
        print(result["answer"])
        for doc in result["context"]:
            print("Source: ", doc.metadata["source"])
 
 
def build():
    w = ChatWebDoc()
    w.ingest([
        "https://www.webagesolutions.com/courses/WA3446-comprehensive-angular-programming",
        "https://www.webagesolutions.com/courses/AZ-1005-configuring-azure-virtual-desktop-for-the-enterprise",
        "https://www.webagesolutions.com/courses/AZ-305T00-designing-microsoft-azure-infrastructure-solutions",
        ])
 
def chat():
    w = ChatWebDoc()
 
    w.load()
 
    while True:
        query = input("&gt;&gt;&gt; ")
 
        if len(query) == 0:
            continue
 
        if query == "/exit":
            break
         
        w.ask(query)
 
if len(sys.argv) &lt; 2:
    chat()
elif sys.argv[1] == "--ingest":
    build()
</code></pre></div></div>

<p>La ejecución del entrenamiento RAG de las web provistas anteriorement en el programa anterior se realiza con el comando:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python rag-test.py --ingest
</code></pre></div></div>

<p>La interactuación con el model una vez entrenado:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python rag-test.py
</code></pre></div></div>

<blockquote>
  <p>Recomiendo ver con mayor detalle esta <a href="https://mobiarch.wordpress.com/2024/02/19/run-rag-locally-using-mistral-ollama-and-langchain/">página web</a> donde se trata esta misma aplicación.</p>
</blockquote>

<h2 id="la-aplicación-web-el-chatbot">La aplicación web (el Chatbot)</h2>

<p>Queda pendiente para una futura actualización del artículo que os muestre como integrar en la aplicación web el motor LLM, interactuar con el, entrenarlo con el método RAG y levantarlo en el servidor web. ¡Hasta pronto! 😉</p>

<hr />

<p><strong>Fuentes:</strong></p>

<ul>
  <li><a href="https://github.com/valiantlynx/ollama-docker/">https://github.com/valiantlynx/ollama-docker</a></li>
  <li><a href="https://mobiarch.wordpress.com/2024/02/19/run-rag-locally-using-mistral-ollama-and-langchain/">https://mobiarch.wordpress.com/2024/02/19/run-rag-locally-using-mistral-ollama-and-langchain/</a></li>
  <li><a href="https://realpython.com/build-llm-rag-chatbot-with-langchain/">https://realpython.com/build-llm-rag-chatbot-with-langchain/</a></li>
</ul>]]></content><author><name></name></author><category term="ia" /><category term="rag" /><category term="open source" /><category term="modelos" /><summary type="html"><![CDATA[Creación de un chatbot con modelo opensource. Aplicando la técnica RAG y utilizando Ollama, LangChain, ChromaDb y una salida final como API a un chatbot web]]></summary></entry><entry xml:lang="es"><title type="html">RAG con modelos de IA open source</title><link href="https://rarcos.com/es/2024/05/25/RAG_modelos_open_source/" rel="alternate" type="text/html" title="RAG con modelos de IA open source" /><published>2024-05-25T08:23:28+02:00</published><updated>2024-05-25T08:23:28+02:00</updated><id>https://rarcos.com/2024/05/25/RAG_modelos_open_source</id><content type="html" xml:base="https://rarcos.com/2024/05/25/RAG_modelos_open_source/"><![CDATA[<h1 id="uso-de-rag-generación-aumentada-por-recuperación-en-modelos-open-source">Uso de RAG (Generación Aumentada por Recuperación) en modelos open source</h1>

<p style="text-align: justify">
La generación mejorada por recuperación (RAG) es el proceso de optimización de la salida de un modelo lingüístico de gran tamaño, de modo que haga referencia a una base de conocimientos autorizada fuera de los orígenes de datos de entrenamiento antes de generar una respuesta. Los modelos de lenguaje de gran tamaño (LLM) se entrenan con grandes volúmenes de datos y usan miles de millones de parámetros para generar resultados originales en tareas como responder preguntas, traducir idiomas y completar frases. RAG extiende las ya poderosas capacidades de los LLM a dominios específicos o a la base de conocimientos interna de una organización, todo ello sin la necesidad de volver a entrenar el modelo. Se trata de un método rentable para mejorar los resultados de los LLM de modo que sigan siendo relevantes, precisos y útiles en diversos contextos.
</p>

<ul>
  <li>Para tener más información te recomiendo visites el siguiente <a href="https://aws.amazon.com/es/what-is/retrieval-augmented-generation/">artículo</a> de AWS.</li>
  <li>También en este <a href="https://www.thepowerplatformcave.com/rag-ia-generativa-con-tus-datos/">artículo</a> se explica de una forma más técnica.</li>
</ul>

<p>A continuación se muestran las fases de la técnica RAG:</p>

<p style="text-align: center">
    <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSYb12anR2JNWP4NDPZ6e1qiEEt3DhUMWkiCqk1YSC53w&amp;s" />    
    <img src="https://observatorio-ia.com/wp-content/uploads/2024/02/RAG.png" />    
</p>

<hr />

<p><em>Repositorio con el contenido</em></p>

<p>RAG Mistral model</p>

<p><a href="https://colab.research.google.com/drive/1JS0bucLeiNdbFsf6y0gr3bo62lcsCwNj?usp=sharing"><img src="/images/pages/repository_small_colab.png" alt="Repository1" /></a></p>

<p>RAG RoBERTa model</p>

<p><a href="https://colab.research.google.com/drive/1wEJDmyXSdmPH1E9pba9mRrkUSVilzNUn?usp=sharing"><img src="/images/pages/repository_small_colab.png" alt="Repository2" /></a></p>

<hr />

<p><strong>Fuentes:</strong></p>

<ul>
  <li><a href="https://aws.amazon.com/es/what-is/retrieval-augmented-generation/">https://aws.amazon.com/es/what-is/retrieval-augmented-generation/</a></li>
  <li><a href="https://www.thepowerplatformcave.com/rag-ia-generativa-con-tus-datos/">https://www.thepowerplatformcave.com/rag-ia-generativa-con-tus-datos/ </a></li>
  <li><a href="https://observatorio-ia.com/wp-content/uploads/2024/02/RAG.png">https://observatorio-ia.com/wp-content/uploads/2024/02/RAG.png</a></li>
  <li><a href="https://www.e2enetworks.com/blog/implementing-a-rag-pipeline-with-mixtral-8x7b">https://www.e2enetworks.com/blog/implementing-a-rag-pipeline-with-mixtral-8x7b</a></li>
  <li><a href="https://www.hiberus.com/crecemos-contigo/ask-your-web-pages-otro-enfoque-rag-utilizando-modelos-de-codigo-abierto/">https://www.hiberus.com/crecemos-contigo/ask-your-web-pages-otro-enfoque-rag-utilizando-modelos-de-codigo-abierto/</a></li>
  <li><a href="https://www.datacamp.com/tutorial/mistral-7b-tutorial">https://www.datacamp.com/tutorial/mistral-7b-tutorial</a></li>
  <li><a href="https://haystack.deepset.ai/tutorials/22_pipeline_with_promptnode">https://haystack.deepset.ai/tutorials/22_pipeline_with_promptnode</a></li>
</ul>]]></content><author><name></name></author><category term="ia" /><category term="rag" /><category term="open source" /><category term="modelos" /><summary type="html"><![CDATA[RAG (Generación Aumentada por Recuperación) lleva la precisión a los modelos del lenguaje]]></summary></entry><entry xml:lang="es"><title type="html">Angular 17 + Spring Boot 3 + Spring Security 6 + JWT</title><link href="https://rarcos.com/es/2023/11/20/Spring_boot_angular/" rel="alternate" type="text/html" title="Angular 17 + Spring Boot 3 + Spring Security 6 + JWT" /><published>2023-11-20T15:33:28+01:00</published><updated>2023-11-20T15:33:28+01:00</updated><id>https://rarcos.com/2023/11/20/Spring_boot_angular</id><content type="html" xml:base="https://rarcos.com/2023/11/20/Spring_boot_angular/"><![CDATA[<h1 id="angular-17--spring-boot-3--spring-security-6--jwt">Angular 17 + Spring Boot 3 + Spring Security 6 + JWT</h1>

<p style="text-align: justify">
La finalidad principal de la aplicación, ha sido la demostración de la puesta en práctica de los conocimientos adquiridos sobre la gestión de privilegios de acceso de usuarios a distintos elementos (o módulos como me referiré a lo largo del documento) de la aplicación, la gestión de usuarios jerarquizados en distintos grupos (denominados roles) y la administración por parte de un usuario autorizado. No menos relevante ha sido la aplicación de los conocimientos en el diseño y gestión de bases de datos relacionales y las plataformas de implementación de estas. Otro factor que se ha tenido en cuenta ha sido la seguridad del entorno de uso (JWT) y de la aplicación (Angular), implementando funcionalidades como, la encriptación de datos sensibles, o la prevención en la utilización de elementos sensibles a la inyección de información automatizada (cracking o ataques de fuerza bruta).
</p>

<h1 id="arquitectura">Arquitectura</h1>

<p>Esta es la arquitectura que se ha utilizado para el entorno de producción en un VPS.</p>

<p><img src="/images/pages/spring_boot_arquitectura.png" alt="VPS Architecture" title="Spring Boot VPS Architecture" /></p>

<p>Separación lógica del frontend, backend y la base de datos.</p>

<p><img src="/images/pages/spring_boot_arquitectura_Front-Back.png" alt="Architecture GMCCA Frontend-Backend" title="Spring Boot Frontend-Backend architecture" /></p>

<h2 id="entorno-de-ejecución---frontend">Entorno de ejecución - Frontend</h2>

<p style="text-align: center">
<a href="https://gmcca-spring.rarcos.com" target="_blank">
    <img src="/images/pages/gesmerca.png" width="100" alt="GMCCA Logo" />Demo online
</a>
</p>

<h2 id="documentación-api---backend">Documentación API - Backend</h2>

<p style="text-align: center">
<a href="https://swagger.rarcos.com" target="_blank">
    <img src="https://avatars.githubusercontent.com/u/7658037?s=200&amp;v=4" width="100" alt="Swagger Logo" />Documentación API online
</a>
</p>

<hr />

<p><em>Repositorio con el contenido</em></p>

<p><a href="https://github.com/rubenarcos2/spring_security_angular"><img src="/images/pages/repository_small.png" alt="Repository" /></a></p>

<hr />

<p><strong>Fuentes:</strong></p>

<p><em>Spring security + JWT</em></p>

<ul>
  <li><a href="https://www.youtube.com/playlist?list=PL4bT56Uw3S4z9rtwwGvuk1Mjhu5sdLSwX">https://www.youtube.com/playlist?list=PL4bT56Uw3S4z9rtwwGvuk1Mjhu5sdLSwX</a></li>
  <li><a href="https://github.com/cavanosa/tutorial_jwt_BACK">https://github.com/cavanosa/tutorial_jwt_BACK</a></li>
</ul>]]></content><author><name></name></author><category term="javascript" /><category term="php" /><category term="angular" /><category term="laravel" /><category term="proyecto integrado" /><category term="GMCCA" /><summary type="html"><![CDATA[Gestión de privilegios de acceso de usuarios a distintos elementos con spring boot, spring security, JWT y Angular.]]></summary></entry><entry xml:lang="es"><title type="html">Proyecto Integrado DAW</title><link href="https://rarcos.com/es/2023/06/30/Proyecto_integrado/" rel="alternate" type="text/html" title="Proyecto Integrado DAW" /><published>2023-06-30T16:33:28+02:00</published><updated>2023-06-30T16:33:28+02:00</updated><id>https://rarcos.com/2023/06/30/Proyecto_integrado</id><content type="html" xml:base="https://rarcos.com/2023/06/30/Proyecto_integrado/"><![CDATA[<h1 id="proyecto-integrado-fin-del-ciclo-formativo-de-grado-superior-en-desarrollo-de-aplicaciones-web">Proyecto integrado fin del Ciclo Formativo de Grado Superior en desarrollo de Aplicaciones Web</h1>

<p style="text-align: justify">
La finalidad principal de la aplicación, ha sido la demostración de la puesta en práctica de los conocimientos adquiridos a lo largo del ciclo formativo de desarrollo de aplicaciones web. He focalizado la aplicación en los conocimientos adquiridos sobre la gestión de privilegios de acceso de usuarios a distintos elementos (o módulos como me referiré a lo largo del documento) de la aplicación, la gestión de usuarios jerarquizados en distintos grupos (denominados roles) y la administración por parte de un usuario autorizado. No menos relevante ha sido la aplicación de los conocimientos en el diseño y gestión de bases de datos relacionales y las plataformas de implementación de estas. Otro factor que se ha tenido en cuenta ha sido la seguridad del entorno de uso (JWT) y de la aplicación (Angular), implementando funcionalidades como, la encriptación de datos sensibles, o la prevención en la utilización de elementos sensibles a la inyección de información automatizada (cracking o ataques de fuerza bruta).
</p>

<h1 id="tecnologías">Tecnologías</h1>
<ul>
  <li>Frontend: Angular 16</li>
  <li>Backend: Laravel 10 + JWT</li>
  <li>API externa: IA (Flask)</li>
</ul>

<h1 id="presentación-y-exposición-del-proyecto">Presentación y exposición del proyecto</h1>

<iframe src="https://drive.google.com/file/d/18QEggdRyanzHKvrReNoUgMQjEZppg-Sx/preview" frameborder="0" allowfullscreen="" width="100%" height="400"></iframe>

<iframe type="application/pdf" src="/pdf/Gesmerca_DAW_Presentacion.pdf#toolbar=0" frameborder="0" allowfullscreen="" width="100%" height="500"></iframe>

<h1 id="arquitectura">Arquitectura</h1>

<p>Esta es la arquitectura que se ha utilizado para el entorno de producción, en un VPS.</p>

<p><img src="/images/pages/GesMerCa_arquitectura.png" alt="Arquitectura en VPS" title="Arquitectura en VPS de GesMerCa" /></p>

<p>La separación lógica del frontend, el backend y la base de datos.</p>

<p><img src="/images/pages/GesMerCa_arquitectura_Front-Back.png" alt="Arquitectura GMCCA Frontend-Backend" title="Arquitectura GesMerCa Frontend-Backend" /></p>

<h2 id="entorno-de-ejecución---frontend">Entorno de ejecución - Frontend</h2>

<p style="text-align: center">
<a href="https://gmcca-laravel.rarcos.com" target="_blank">
    <img src="/images/pages/gesmerca.png" width="100" alt="GMCCA Logo" /> Demostración web online
</a>
</p>
<h2 id="documentación-de-la-api---backend">Documentación de la API - Backend</h2>
<p style="text-align: center">
<a href="https://vps.rarcos.com:10447/" target="_blank">
    <img src="https://avatars.githubusercontent.com/u/7658037?s=200&amp;v=4" width="100" alt="Swagger Logo" /> Documentación api online
</a>
</p>

<h2 id="documentación-completa-y-diagramas-del-proyecto">Documentación completa y diagramas del proyecto</h2>

<iframe type="application/pdf" src="/pdf/Documentacion_GESMERCA_anticopia_DAW.pdf#toolbar=0" frameborder="0" allowfullscreen="" width="100%" height="990"></iframe>

<hr />

<p><em>Repositorio con el contenido</em></p>

<p><a href="https://github.com/rubenarcos2/proyecto_daw/tree/main/frontend/gesmerca"><img src="/images/pages/repository_small.png" alt="Repositorio" /></a>
Frontend
<a href="https://github.com/rubenarcos2/proyecto_daw/tree/main/backend/gesmerca"><img src="/images/pages/repository_small.png" alt="Repositorio" /></a>
Backend
<a href="https://github.com/rubenarcos2/proyecto_daw/tree/main/IA"><img src="/images/pages/repository_small.png" alt="Repositorio" /></a>
IA</p>

<hr />

<p><strong>Fuentes:</strong></p>

<p><em>Angular</em></p>

<ul>
  <li><a href="https://openwebinars.net/academia/aprende/angular/9221/">https://openwebinars.net/academia/aprende/angular/9221/</a></li>
  <li><a href="https://www.positronx.io/laravel-angular-token-based-authentication-with-jwt/">https://www.positronx.io/laravel-angular-token-based-authentication-with-jwt/</a></li>
  <li><a href="https://www.ultimateakash.com/blog-details/Ii1TNGAKYAo=/How-to-Implement-JWT-Authentication-in-Angular-2023">https://www.ultimateakash.com/blog-details/Ii1TNGAKYAo=/How-to-Implement-JWT-Authentication-in-Angular-2023</a></li>
  <li><a href="https://www.tektutorialshub.com/angular/meta-service-in-angular-add-update-meta-tags-example/">https://www.tektutorialshub.com/angular/meta-service-in-angular-add-update-meta-tags-example/</a>
<a href="https://angular.io/api/platform-browser/MetaDefinition">https://angular.io/api/platform-browser/MetaDefinition</a></li>
  <li><a href="https://www.concretepage.com/angular-2/angular-2-4-minlength-and-maxlength-validation-example#:~:text=It%20means%20the%20value%20entered,can%20write%20code%20as%20below.">https://www.concretepage.com/angular-2/angular-2-4-minlength-and-maxlength-validation-example#:~:text=It%20means%20the%20value%20entered,can%20write%20code%20as%20below.</a></li>
  <li><a href="https://stackoverflow.com/questions/52389376/how-to-reload-current-page">https://stackoverflow.com/questions/52389376/how-to-reload-current-page</a></li>
</ul>

<p><em>LocalStorage y sessionStorage</em></p>

<ul>
  <li><a href="https://ed.team/blog/que-es-y-como-utilizar-localstorage-y-sessionstorage">https://ed.team/blog/que-es-y-como-utilizar-localstorage-y-sessionstorage</a></li>
</ul>

<p><em>Component Lifecycle</em></p>

<ul>
  <li><a href="https://angular.io/guide/lifecycle-hooks">https://angular.io/guide/lifecycle-hooks</a></li>
</ul>

<p><em>Unit testing</em></p>

<ul>
  <li><a href="https://www.infragistics.com/community/blogs/b/infragistics/posts/unit-testing-in-angular">https://www.infragistics.com/community/blogs/b/infragistics/posts/unit-testing-in-angular</a> -&gt; ng test –code-coverage</li>
</ul>

<p><em>Auth guard with roles/permission based</em></p>

<ul>
  <li><a href="https://jasonwatmore.com/post/2022/12/22/angular-14-role-based-authorization-tutorial-with-example">https://jasonwatmore.com/post/2022/12/22/angular-14-role-based-authorization-tutorial-with-example</a></li>
</ul>

<p><em>Unsuscribing AJAX request</em></p>

<ul>
  <li><a href="https://nocodenobug.substack.com/p/rxjs-en-angular-el-drama-de-las-suscripciones">https://nocodenobug.substack.com/p/rxjs-en-angular-el-drama-de-las-suscripciones</a></li>
</ul>

<p><em>Laravel</em>
<em>Creación del API rest en laravel con autenticación JWT</em></p>

<ul>
  <li><a href="https://www.positronx.io/laravel-jwt-authentication-tutorial-user-login-signup-api/">https://www.positronx.io/laravel-jwt-authentication-tutorial-user-login-signup-api/</a></li>
  <li><a href="https://www.nigmacode.com/laravel/roles-de-usuario-en-laravel/">https://www.nigmacode.com/laravel/roles-de-usuario-en-laravel/</a> -&gt; php artisan vendor:publish –provider=”Spatie\Permission\PermissionServiceProvider”</li>
  <li><a href="https://laraveldaily.com/post/laravel-api-errors-and-exceptions-how-to-return-responses">https://laraveldaily.com/post/laravel-api-errors-and-exceptions-how-to-return-responses</a></li>
  <li><a href="https://stackoverflow.com/questions/64897053/laravel-8-return-all-exceptions-as-json">https://stackoverflow.com/questions/64897053/laravel-8-return-all-exceptions-as-json</a></li>
  <li><a href="https://www.itsolutionstuff.com/post/laravel-9-user-roles-and-permissions-tutorialexample.html">https://www.itsolutionstuff.com/post/laravel-9-user-roles-and-permissions-tutorialexample.html</a>
<a href="https://larainfo.com/blogs/laravel-9-image-file-upload-example">https://larainfo.com/blogs/laravel-9-image-file-upload-example</a></li>
  <li><a href="https://stackoverflow.com/questions/68128685/laravel-get-public-url-for-file-stored-in-storage-public-folder">https://stackoverflow.com/questions/68128685/laravel-get-public-url-for-file-stored-in-storage-public-folder</a> -&gt; php artisan storage:link
<a href="https://tinkerwell.app/blog/laravel-caches-and-all-ways-to-clear-them">https://tinkerwell.app/blog/laravel-caches-and-all-ways-to-clear-them</a></li>
  <li><a href="https://www.positronx.io/laravel-image-resize-upload-with-intervention-image-package/">https://www.positronx.io/laravel-image-resize-upload-with-intervention-image-package/</a></li>
</ul>

<p><em>Spatie permissions</em></p>

<ul>
  <li><a href="https://spatie.be/docs/laravel-permission/v5/basic-usage/direct-permissions">https://spatie.be/docs/laravel-permission/v5/basic-usage/direct-permissions</a></li>
  <li><a href="https://laravelcode.com/post/laravel-8-user-roles-and-permissions-using-spatie">https://laravelcode.com/post/laravel-8-user-roles-and-permissions-using-spatie</a>
<a href="https://spatie.be/docs/laravel-permission/v5/basic-usage/role-permissions">https://spatie.be/docs/laravel-permission/v5/basic-usage/role-permissions</a></li>
  <li><a href="https://scrutinizer-ci.com/g/spatie/laravel-permission/code-structure/master/operation/Spatie%5CPermission%5CTraits%5CHasPermissions::syncPermissions">https://scrutinizer-ci.com/g/spatie/laravel-permission/code-structure/master/operation/Spatie%5CPermission%5CTraits%5CHasPermissions::syncPermissions</a></li>
</ul>

<p><em>Faker y seed imagenes</em></p>

<ul>
  <li><a href="https://styde.net/generando-datos-de-prueba-con-faker-en-laravel/">https://styde.net/generando-datos-de-prueba-con-faker-en-laravel/</a></li>
  <li><a href="https://github.com/fzaninotto/Faker#formatters">https://github.com/fzaninotto/Faker#formatters</a></li>
  <li><a href="https://kodementor.com/how-to-seeds-images-with-faker-in-laravel/">https://kodementor.com/how-to-seeds-images-with-faker-in-laravel/</a></li>
  <li><a href="https://styde.net/insercion-de-datos-con-los-seeders-de-laravel/">https://styde.net/insercion-de-datos-con-los-seeders-de-laravel/</a> -&gt; php artisan migrate:fresh –seed</li>
</ul>

<p><em>Vínculo de storage -&gt; public</em></p>

<ul>
  <li><a href="https://laravel.com/docs/10.x/filesystem#the-public-disk">https://laravel.com/docs/10.x/filesystem#the-public-disk</a> -&gt; php artisan storage:link</li>
</ul>

<p><em>Unit testing</em></p>

<ul>
  <li><a href="https://platzi.com/discusiones/1842-intro-laravel/85644-que-diferencia-hay-entre-unit-test-y-feature-test/">https://platzi.com/discusiones/1842-intro-laravel/85644-que-diferencia-hay-entre-unit-test-y-feature-test/</a></li>
  <li><a href="https://laravel.com/docs/10.x/testing">https://laravel.com/docs/10.x/testing</a> -&gt; php artisan test</li>
</ul>

<p><em>Docker postgreSQL database backup</em></p>

<ul>
  <li><a href="https://stackoverflow.com/questions/30171063/how-to-generate-a-postgresql-dump-from-a-docker-container">https://stackoverflow.com/questions/30171063/how-to-generate-a-postgresql-dump-from-a-docker-container</a></li>
</ul>]]></content><author><name></name></author><category term="javascript" /><category term="php" /><category term="angular" /><category term="laravel" /><category term="proyecto integrado" /><category term="GMCCA" /><summary type="html"><![CDATA[Proyecto integrado fin del Ciclo Formativo de Grado Superior en desarrollo de Aplicaciones Web.Angular 16 + Laravel 10 + JWT + IA]]></summary></entry><entry xml:lang="es"><title type="html">Securizando VPS</title><link href="https://rarcos.com/es/2023/03/14/Securizando-VPS/" rel="alternate" type="text/html" title="Securizando VPS" /><published>2023-03-14T06:41:00+01:00</published><updated>2023-03-14T06:41:00+01:00</updated><id>https://rarcos.com/2023/03/14/Securizando%20VPS</id><content type="html" xml:base="https://rarcos.com/2023/03/14/Securizando-VPS/"><![CDATA[<p>A modo de apuntes, una securización estándar de un VPS:</p>
<ul>
  <li><a href="#seg-basica">Seguridad básica</a></li>
  <li><a href="#ssh">Autenticación basada en clave SSH </a></li>
  <li><a href="#maldet">Detección de malware - maldet</a></li>
  <li><a href="#postfix">Postfix - Envío de emai</a></li>
  <li><a href="#cpu">Notificación si CPU máx</a></li>
</ul>

<p><a name="seg-basica"></a></p>

<h1 id="seguridad-de-linux-y-debilidades-comunes">Seguridad de Linux y debilidades comunes</h1>

<p>15 consejos de seguridad de VPS para proteger la seguridad de tu servidor</p>

<p><a href="https://www.hostinger.es/tutoriales/seguridad-vps">https://www.hostinger.es/tutoriales/seguridad-vps</a></p>

<p><a name="ssh"></a></p>

<h1 id="autenticación-basada-en-clave-ssh---acceso">Autenticación basada en clave SSH - Acceso</h1>

<p>Generación del para de claves: pública-privada</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">ssh-keygen <span class="nt">-t</span> rsa</code></pre></figure>

<p>Autorización de la clave pública</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">cat</span> ~/.ssh/id_rsa.pub <span class="o">&gt;&gt;</span> ~/.ssh/authorized_keys</code></pre></figure>

<p>Deshabilitar la autenticación de contraseña en su servidor</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>nano /etc/ssh/sshd_config</code></pre></figure>

<p>Cambiar el valor de PasswordAuthentication dentro del sshd_config a:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">PasswordAuthentication no</code></pre></figure>

<p>Reiniciamos el servidor SSH para que se hagan efectivo los cambios:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">service ssh restart</code></pre></figure>

<p>Pasamos por sftp la clave privada <em>id_rsa</em> al cliente que vayamos a utilizar. Putty en mi caso.
En la parte del cliente, instalamos putty y generamos la clave privada de la siguiente forma:</p>

<p><a href="https://www.simplified.guide/putty/convert-ssh-key-to-ppk">https://www.simplified.guide/putty/convert-ssh-key-to-ppk</a></p>

<p><a name="maldet"></a></p>

<h1 id="detección-de-malware---maldet">Detección de malware - maldet</h1>

<p>Instalación y puesta en funcionamiento:</p>

<p><a href="https://codigonaranja.com/como-detectar-malware-en-tu-sitio-web-servidores-linux-ubuntu-debian">https://codigonaranja.com/como-detectar-malware-en-tu-sitio-web-servidores-linux-ubuntu-debian</a></p>

<p>Ve informes y reportes:</p>

<p><a href="https://wpbeaches.com/set-lmd-maldet-clamav-runcloud/">https://wpbeaches.com/set-lmd-maldet-clamav-runcloud/</a></p>

<p>Escaneo manual:</p>

<p><a href="https://www.nosolocodigo.com/linux-malware-detect-escaner-para-aplicaciones-web-open-source/">https://www.nosolocodigo.com/linux-malware-detect-escaner-para-aplicaciones-web-open-source/</a></p>

<p><a name="postfix"></a></p>

<h1 id="instalación-y-configuración-de-postfix-para-usar-el-smtp-de-gmail">Instalación y configuración de Postfix para usar el SMTP de Gmail</h1>

<p><a href="http://somebooks.es/configurar-postfix-para-usar-el-smtp-de-gmail-en-ubuntu-20-04-lts/">http://somebooks.es/configurar-postfix-para-usar-el-smtp-de-gmail-en-ubuntu-20-04-lts/</a></p>

<p><a href="https://www.fosstechnix.com/how-to-configure-postfix-with-gmail-on-ubuntu/">https://www.fosstechnix.com/how-to-configure-postfix-with-gmail-on-ubuntu/</a></p>

<p>Email alias para usuarios:</p>

<p><a href="https://www.cyberciti.biz/tips/how-to-redirect-one-users-mail-to-another-user-with-postfix.html">https://www.cyberciti.biz/tips/how-to-redirect-one-users-mail-to-another-user-with-postfix.html</a></p>

<p>Resolución al error en el certificado:</p>

<p><a href="https://github.com/rancher/rancher/issues/4293">https://github.com/rancher/rancher/issues/4293</a></p>

<p><a name="cpu"></a></p>

<h1 id="notificación-por-email-si-cpu-supera-el-80">Notificación por email si CPU supera el 80%</h1>

<p><a href="https://www.2daygeek.com/linux-shell-script-to-monitor-cpu-utilization-usage-and-send-email/">https://www.2daygeek.com/linux-shell-script-to-monitor-cpu-utilization-usage-and-send-email/</a></p>]]></content><author><name></name></author><category term="vps" /><category term="seguridad" /><category term="ssh" /><category term="postfix" /><category term="malware" /><summary type="html"><![CDATA[Apuntes de securización VPS: seguridad básica, claves ssh, detección malware, posfix...]]></summary></entry><entry><title type="html">Dockerizando VPS</title><link href="https://rarcos.com/es/2023/03/11/Dockerizando-VPS/" rel="alternate" type="text/html" title="Dockerizando VPS" /><published>2023-03-11T06:41:00+01:00</published><updated>2023-03-11T06:41:00+01:00</updated><id>https://rarcos.com/2023/03/11/Dockerizando%20VPS</id><content type="html" xml:base="https://rarcos.com/2023/03/11/Dockerizando-VPS/"><![CDATA[<p>He traspasado todas mis aplicaciones que tenía en heroku a un vps propio y además he aprovechado para dockerizarlas todas, incluyendo bases de datos y otros servicios web. Concretamente he dockerizado:</p>
<ul>
  <li><a href="#cont-spring-boot">Spring Boot</a></li>
  <li><a href="#cont-laravel">Laravel</a></li>
  <li><a href="#cont-flask">Flask</a></li>
  <li><a href="#cont-nginx">Nginx</a></li>
  <li><a href="#cont-postgres">PostgreSQL</a></li>
  <li><a href="#cont-mysql">MySQL</a></li>
  <li><a href="#cont-mongo">MongoDB</a></li>
</ul>

<h1 id="instalación-de-docker-en-el-vps">Instalación de docker en el VPS</h1>

<p><strong>Docker</strong></p>

<p>En primer lugar he tenido que instalar docker y docker compose. Para la instalación de docker en ubuntu 22.04 server :</p>

<p>Actualizamos la lista de paquetes del S.O. y actualizamos el S.O.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">apt update <span class="o">&amp;&amp;</span> apt upgrade</code></pre></figure>

<p>Añadimos una serie de paquetes de requisitos previos.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">apt <span class="nb">install </span>apt-transport-https ca-certificates curl software-properties-common</code></pre></figure>

<p>Se agrega la clave GPG para el repositorio oficial de Docker a nuestro S.O.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">curl <span class="nt">-fsSL</span> https://download.docker.com/linux/ubuntu/gpg | apt-key add -</code></pre></figure>

<p>Y por último ya podremos añadir el repositorio a nuestro S.O. Podemos comprobar que se ha añadido una línea en /etc/apt/source.list.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">add-apt-repository <span class="s2">"deb [arch=amd64] https://download.docker.com/linux/ubuntu jammy stable"</span></code></pre></figure>

<p>Actualizamos la base de datos ya que hay una línea nueva (compruebe en el listado que sale) y comprobaremos antes de instalar que vamos a instalar desde el repositorio (y no desde Ubuntu Server).</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">apt update &amp; apt-cache policy docker-ce</code></pre></figure>

<p>Por último, podremos instalar el paquete (paquete pesado de aproximadamente 400 MBytes). Como no puede ser de otra manera hay que asegurar que Docker engine está arrancado y si reinicia el servicio en el arranque del S.O. anfitrión.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">apt-get <span class="nb">install </span>docker-ce</code></pre></figure>

<p><em>Manualillo de systemctl</em></p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">systemctl disable Docker <span class="c"># deshabilitamos en el arranque el demonio docker </span>
systemctl list-unit-files | <span class="nb">grep </span>docker 
systemctl <span class="nb">enable </span>docker 
systemctl list-unit-files | <span class="nb">grep </span>docker 
systemctl stop docker <span class="o">&amp;&amp;</span> systemctl status Docker 
systemctl start docker <span class="o">&amp;&amp;</span> systemctl status Docker 
docker versión</code></pre></figure>

<p><em>Resolución del problema de permisos de docker para un usuario no root</em></p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>groupadd docker
<span class="nb">sudo </span>usermod <span class="nt">-aG</span> docker mi_usuario
newgrp docker
docker ps</code></pre></figure>

<p><strong>Docker-Compose</strong></p>

<p>Actualización de la lista de repositorios</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>apt update</code></pre></figure>

<p>Instalación de docker-compose</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">sudo </span>apt <span class="nb">install </span>docker-compose</code></pre></figure>

<p>Comprobamos el estado del servidor docker y las versiones respectivamente</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">systemctl status docker
docker <span class="nt">-v</span>
docker-compose <span class="nt">-version</span></code></pre></figure>

<h1 id="creación-de-los-contenedores-y-docker-compose">Creación de los contenedores y docker-compose</h1>

<p>En primer lugar me he creado una carpeta <em>docker</em> en el home, que irá alojando los scripts y ficheros necesarios. Tiene la siguiente estructura:</p>

<p><img src="/images/pages/docker-jerarquia.jpg" alt="docker-jerarquia.jpg" /></p>

<p>Vamos a utilizar para el certificado de autenticación del servidor https <a href="https://letsencrypt.org/">Let’s encrypt</a>.</p>

<p><strong>Instalación y generación del certificado Let’s encrypt</strong></p>

<p>Para la instalación de la aplicación <em>certbot</em> de Let’s encrypt para generar los certificados, recomiendo seguir las instrucciones de la siguiente página <a href="https://certbot.eff.org/instructions?ws=other&amp;os=ubuntufocal">https://certbot.eff.org/instructions?ws=other&amp;os=ubuntufocal</a> está preseleccionado para Ubuntu server.</p>

<p>La página indicada anteriormente, es la única que funciona actualmente con Ubuntu Server 22.04, el resto de tutoriales que he visitado se encuentran obsoletos al haber cambiado a snap la aplicación de certbot de Let’s encrypt y el repositorio de github ya no funciona tampoco como se esperaba en instrucciones antiguas.</p>

<p>Una vez terminado nos generará la siguiente salida:
<img src="/images/pages/certificado_letsencrypt.jpg" alt="salida_certificado_letsencrypt" /></p>

<p>Generamos el certificado que es válido para tomcat .p12.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">openssl pkcs12 <span class="nt">-export</span> <span class="nt">-in</span> /etc/letsencrypt/live/mi_dominio_web/fullchain.pem <span class="nt">-inkey</span> /etc/letsencrypt/live/mi_dominio_web/privkey.pem <span class="nt">-out</span> springboot_letsencrypt.p12 <span class="nt">-name</span> bootalias <span class="nt">-CAfile</span> chain.pem <span class="nt">-caname</span> root</code></pre></figure>

<p><em>Recuerda cambiar las rutas por las tuyas</em></p>

<p><a name="cont-spring-boot"></a></p>

<p><strong>Contenedor para Spring Boot</strong></p>

<p>Copiamos los ficheros necesarios en nuestra carpeta de nuestro nuestra carpeta en el home de <em>/docker/docker-java/</em>: estando en la raíz de esta el fichero .jar y .p12.</p>

<p><em>Generación de los scripts de docker</em></p>

<p>En primer lugar, vamos a crear un <em>Dockerfile</em> para que contenga la imagen (para Ubuntu server) y realice la copia de los ficheros necesarios (el .jar y el certificado) hacia nuestro contenedor.</p>

<p>Dockerfile</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">FROM eclipse-temurin:17-jdk-alpine

ARG <span class="nv">JAR_FILE</span><span class="o">=</span><span class="k">*</span>.jar

COPY <span class="k">${</span><span class="nv">JAR_FILE</span><span class="k">}</span> my_proyect_compiled.jar
COPY my_cert_letsencrypt.p12 <span class="nb">.</span>

ENTRYPOINT <span class="o">[</span><span class="s2">"java"</span>,<span class="s2">"-jar"</span>,<span class="s2">"/my_proyect_compiled.jar"</span><span class="o">]</span></code></pre></figure>

<p><em>Tendremos que cambiar el nombre del certificado y del fichero del proyecto compilado .jar</em></p>

<p>En segundo lugar, vamos a crear el script de <em>docker-compose.yml</em> que creará nuestro servicio web y expondrá el puerto 8443 por defecto.</p>

<p>docker-compose.yml</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">version: <span class="s1">'3.8'</span>
services:
  proyect_name:
    build: <span class="nb">.</span>
    container_name: <span class="s1">'proyect_name-spring-app'</span>
    restart: always
    ports:
      - <span class="s1">'8080:8080'</span>
      - <span class="s1">'8443:8443'</span></code></pre></figure>

<p><em>Tendremos que cambiar el nombre del servicio y del contenedor</em></p>

<p><em>Proyecto Spring Boot</em></p>

<p>Vamos a añadir al fichero <em>aplication.properties</em> la configuración para que el servidor tomcat que crea Spring, escuche por el puerto https, que por defecto es el 8443 en lugar del 443. Y el certificado que hemos creado previamente para que nuestro servidor funcione con Let’s encrypt.</p>

<p>aplication.properties</p>

<figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">server</span><span class="o">.</span><span class="na">port</span><span class="o">=</span><span class="mi">9443</span>
<span class="n">server</span><span class="o">.</span><span class="na">ssl</span><span class="o">.</span><span class="na">enabled</span><span class="o">=</span><span class="kc">true</span>
<span class="n">server</span><span class="o">.</span><span class="na">ssl</span><span class="o">.</span><span class="na">key</span><span class="o">-</span><span class="n">store</span><span class="o">=</span><span class="n">my_cert_letsencrypt</span><span class="o">.</span><span class="na">p12</span>
<span class="n">server</span><span class="o">.</span><span class="na">ssl</span><span class="o">.</span><span class="na">key</span><span class="o">-</span><span class="n">store</span><span class="o">-</span><span class="n">password</span><span class="o">=</span><span class="n">your_password</span>
<span class="n">server</span><span class="o">.</span><span class="na">ssl</span><span class="o">.</span><span class="na">keyStoreType</span><span class="o">=</span><span class="no">PKCS12</span>
<span class="n">server</span><span class="o">.</span><span class="na">ssl</span><span class="o">.</span><span class="na">keyAlias</span><span class="o">=</span><span class="n">your_alias</span></code></pre></figure>

<p><em>Tendremos que cambiar: el certificado, la contraseña y el alias con el que creamos anteriormente.</em></p>

<p>Generamos el fichero <em>.jar</em> mediante el comando de mvn para compilar</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">mvn package</code></pre></figure>

<p><em>Para ver la diferencia entre mvn package y mvn install, consulta este <a href="https://www.appsdeveloperblog.com/difference-between-mvn-package-and-mvn-install/">enlace</a></em></p>

<p>Ahora en la carpeta <em>/target</em> del proyecto tendremos el fichero <em>.jar</em> que pasaremos por ftp a nuestra carpeta en el home de <em>/docker/docker-java/nombre_aplicacion</em> que contendrá a su vez los ficheros de <em>Dockerfile</em> y <em>docker-compose.yml</em>, junto a nuestro certificado <em>.p12</em>. Para que todo se pueda copiar en el contenedor de docker, según las instrucciones de nuesto <em>Dockerfile</em>.</p>

<p>Finalmente, debemos tener la siguiente estructura de ficheros en la carpeta de docker:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">/docker-my_app
|-Dockerfile
|-docker-compose.yml
|-my_app.jar
|-my_cert.p12</code></pre></figure>

<p>En la página oficial del Spring Boot hay también un tutorial que indica con mayor detalle lo realizado anteriormente <a href="https://spring.io/guides/topicals/spring-boot-docker/">https://spring.io/guides/topicals/spring-boot-docker/</a> incluyendo aspectos de seguridad como la creación de un usuario diferente a root dentro del contenedor de docker.</p>

<p><a name="cont-laravel"></a></p>

<p><strong>Contenedor para Laravel</strong></p>

<p>Para Laravel vamos a utilizar un servidor ngnix con la última versión por seguridad.
para ello crearemos varios ficheros que describiré a continuación:</p>

<p><em>Generación de los scripts de docker</em></p>

<p>Dockerfile</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># imagen de dockerhub que descargara</span>
FROM php:8.2-fpm-alpine

<span class="c"># algunas configuraciones para que funcione el contenedor para mysql</span>
<span class="c">#RUN docker-php-ext-install pdo pdo_mysql</span>

<span class="c"># Install Postgre PDO</span>
RUN <span class="nb">set</span> <span class="nt">-ex</span> <span class="se">\</span>
  <span class="o">&amp;&amp;</span> apk <span class="nt">--no-cache</span> add <span class="se">\</span>
    postgresql-dev

RUN docker-php-ext-install pdo pdo_pgsql

<span class="c"># instala composer en el contenedor</span>
RUN curl <span class="nt">-sS</span> https://getcomposer.org/installer | php <span class="nt">--</span> <span class="nt">--install-dir</span><span class="o">=</span>/usr/local/bin <span class="nt">--filename</span><span class="o">=</span>composer

<span class="c"># da permisos para editar los archivos en esta ruta del container</span>
RUN <span class="nb">chown</span> <span class="nt">-R</span> www-data:www-data /var/www
RUN <span class="nb">chmod </span>755 /var/www</code></pre></figure>

<p>docker-compose.yml</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">version: <span class="s2">"3.3"</span>

<span class="c"># Servidor nginx</span>
services:
  nginx-laravel:
    image: nginx:latest
    restart: always
    ports:
      - <span class="s2">"10440:443"</span>
    volumes:
      - ./src:/var/www/html
      - ./src/storage:/var/www/html/storage
      - ./nginx.conf:/etc/nginx/conf.d/default.conf
      - /etc/letsencrypt/live/mi_dominio_web/fullchain.pem:/etc/nginx/ssl/fullchain.pem:ro
      - /etc/letsencrypt/live/mi_dominio_web/privkey.pem:/etc/nginx/ssl/privkey.pem:ro

    links:
      - php-laravel

  <span class="c"># Configuración de php-fpm</span>
  php-laravel:
<span class="c">#    image: php:8-fpm</span>
    build: <span class="nb">.</span>
    restart: always
    volumes:
      - ./src:/var/www/html
<span class="c">#    command: sh -c "cd /var/www/html &amp;&amp; composer update nesbot/carbon"</span></code></pre></figure>

<p>nginx.conf</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">server <span class="o">{</span>
    listen 80<span class="p">;</span>
    listen <span class="o">[</span>::]:80<span class="p">;</span>
    listen 443 ssl<span class="p">;</span>
    server_name mi_ip www.mi_dominio mi_dominio localhost<span class="p">;</span>
    ssl_certificate /etc/nginx/ssl/fullchain.pem<span class="p">;</span>
    ssl_certificate_key /etc/nginx/ssl/privkey.pem<span class="p">;</span>

    <span class="c"># Redirect non-https traffic to https</span>
    <span class="k">if</span> <span class="o">(</span><span class="nv">$scheme</span> <span class="o">!=</span> <span class="s2">"https"</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return </span>301 https://<span class="nv">$host$request_uri</span><span class="p">;</span>
    <span class="o">}</span>

    <span class="c"># Log files for Debug</span>
    error_log  /var/log/nginx/error.log<span class="p">;</span>
    access_log /var/log/nginx/access.log<span class="p">;</span>

    <span class="c"># Laravel web root directory</span>
    root /var/www/html/public<span class="p">;</span>
    index index.php index.html<span class="p">;</span>

    location / <span class="o">{</span>
        try_files <span class="nv">$uri</span> <span class="nv">$uri</span>/ /index.php?<span class="nv">$query_string</span><span class="p">;</span>
        gzip_static on<span class="p">;</span>
    <span class="o">}</span>

    <span class="c"># Nginx Pass requests to PHP-FPM</span>
    location ~ <span class="se">\.</span>php<span class="nv">$ </span><span class="o">{</span>
        try_files <span class="nv">$uri</span> <span class="o">=</span>404<span class="p">;</span>
        fastcgi_split_path_info ^<span class="o">(</span>.+<span class="se">\.</span>php<span class="o">)(</span>/.+<span class="o">)</span><span class="nv">$;</span>
        fastcgi_pass php-laravel:9000<span class="p">;</span>
        fastcgi_index index.php<span class="p">;</span>
        include fastcgi_params<span class="p">;</span>
        fastcgi_param SCRIPT_FILENAME <span class="nv">$document_root$fastcgi_script_name</span><span class="p">;</span>
        fastcgi_param PATH_INFO <span class="nv">$fastcgi_path_info</span><span class="p">;</span>
    <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

<p><em>Sustituye mi dominio mi_dominio por el tuyo</em></p>

<p>Finalmente, debemos tener la siguiente estructura de ficheros en la carpeta de docker:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">/docker-my_app
|-Dockerfile
|-docker-compose.yml
|-default.conf
|-nginx.conf
|-src</code></pre></figure>

<p>Y en la carpeta <em>src</em> vamos a copiar todo el contenido de Laravel.</p>

<p>Levantamos el contenedor de docker como demonio y con la compilación activada</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">docker-compose up <span class="nt">--build</span> <span class="nt">-d</span></code></pre></figure>

<p>Con esto ya tenemos una versión de Laravel Dockerizada y funcionando.</p>

<p><a name="cont-flask"></a></p>

<p><strong>Contenedor para Flask</strong></p>

<p>Tenemos nuestra aplicación python con flask en la carpeta <em>app</em> y los certificados en la carpeta <em>certs</em> y el fichero de <em>requirements</em> al mismo nivel que los de docker.</p>

<p><em>Generación de los scripts de docker</em></p>

<p>Dockerfile</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">version: <span class="s1">'3.8'</span>

services:
  flask:
    restart: always
    build: <span class="nb">.</span>
    <span class="nb">command</span>: python app.py run <span class="nt">-h</span> 0.0.0.0
    volumes:
      - ./app:/usr/src/app/
    ports:
      - 10443:5000
    environment:
      - <span class="nv">FLASK_APP</span><span class="o">=</span>app.py
      - <span class="nv">FLASK_DEBUG</span><span class="o">=</span>1</code></pre></figure>

<p>nginx.conf</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">server <span class="o">{</span>
    listen 80<span class="p">;</span>
    listen <span class="o">[</span>::]:80<span class="p">;</span>
    listen 443 ssl<span class="p">;</span>
    server_name  www.mi_dominio_web mi_dominio_web<span class="p">;</span>
    ssl_certificate /etc/nginx/certs/fullchain.pem<span class="p">;</span>
    ssl_certificate_key /etc/nginx/certs/privkey.pem<span class="p">;</span>

    <span class="c"># Redirect non-https traffic to https</span>
    <span class="k">if</span> <span class="o">(</span><span class="nv">$scheme</span> <span class="o">!=</span> <span class="s2">"https"</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return </span>301 https://<span class="nv">$host$request_uri</span><span class="p">;</span>
    <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

<p>app.py</p>

<p><em>Sustituye mi dominio mi_dominio_web por el tuyo</em></p>

<p><a name="cont-nginx"></a></p>

<p><strong>Contenedor para Nginx</strong></p>

<p>Copiamos los ficheros necesarios en nuestra carpeta de nuestro nuestra carpeta en el home de <em>/docker/docker-ngnix/</em>: estando en la raíz de esta el fichero <em>docker-compose.yml y nginx.conf</em>, las carpetas: <em>cers, site-content y templates</em>.</p>

<p><em>Generación de los scripts de docker</em></p>

<p>docker-compose.yml</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">version: <span class="s2">"3.7"</span>
services:
  web:
    image: nginx
    volumes:
     - ./templates:/etc/nginx/templates
     - ./site-content:/etc/nginx/html
     - ./certs:/etc/nginx/certs:ro
     - ./nginx.conf:/etc/nginx/conf.d/nginx.conf

    ports:
     - <span class="s2">"80:80"</span>
     - <span class="s2">"443:443"</span></code></pre></figure>

<p><em>Generación del script de configuración de ngnix</em></p>

<p>nginx.conf</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">server <span class="o">{</span>
    listen 80<span class="p">;</span>
    listen <span class="o">[</span>::]:80<span class="p">;</span>
    listen 443 ssl<span class="p">;</span>
    server_name  www.mi_dominio_web mi_dominio_web<span class="p">;</span>
    ssl_certificate /etc/nginx/certs/fullchain.pem<span class="p">;</span>
    ssl_certificate_key /etc/nginx/certs/privkey.pem<span class="p">;</span>

    <span class="c"># Redirect non-https traffic to https</span>
    <span class="k">if</span> <span class="o">(</span><span class="nv">$scheme</span> <span class="o">!=</span> <span class="s2">"https"</span><span class="o">)</span> <span class="o">{</span>
        <span class="k">return </span>301 https://<span class="nv">$host$request_uri</span><span class="p">;</span>
    <span class="o">}</span>
<span class="o">}</span></code></pre></figure>

<p><em>Sustituye mi dominio mi_dominio_web por el tuyo</em></p>

<p><em>Generación del resto de ficheros y carpetas</em></p>

<p>En la carpeta <em>certs</em> tienes que tener una copia de los ficheros generados por <em>certbot</em>, son los ficheros: <em>fullchain.pem y privkey.pem</em>.</p>

<p>En la carpeta <em>site-content</em> el <em>index.html</em> de tu web con todo su contenido. Este es un ejemplo de redirección de mi página, por si te sirve de ejemplo.</p>

<p>site-content/index.html</p>

<figure class="highlight"><pre><code class="language-html" data-lang="html"><span class="cp">&lt;!DOCTYPE html&gt;</span>
<span class="nt">&lt;html</span> <span class="na">lang=</span><span class="s">"es"</span><span class="nt">&gt;</span>

<span class="nt">&lt;head&gt;</span>
    <span class="nt">&lt;meta</span> <span class="na">charset=</span><span class="s">"UTF-8"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;meta</span> <span class="na">name=</span><span class="s">"viewport"</span> <span class="na">content=</span><span class="s">"width=device-width, initial-scale=1.0"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;meta</span> <span class="na">http-equiv=</span><span class="s">"X-UA-Compatible"</span> <span class="na">content=</span><span class="s">"ie=edge"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;meta</span> <span class="na">http-equiv=</span><span class="s">"refresh"</span> <span class="na">content=</span><span class="s">"5;url=https://mi_dominio_web"</span><span class="nt">&gt;</span>
<span class="nt">&lt;/head&gt;</span>

<span class="nt">&lt;body&gt;</span>
<span class="nt">&lt;h1&gt;</span>Acceso no permitido<span class="nt">&lt;/h1&gt;</span>
<span class="nt">&lt;p&gt;</span>Va a ser redireccionado a la página <span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">"https://mi_dominio_web"</span><span class="nt">&gt;</span>https://mi_dominio_web<span class="nt">&lt;/a&gt;&lt;/p&gt;</span>
<span class="nt">&lt;/body&gt;</span>
<span class="nt">&lt;/html&gt;</span></code></pre></figure>

<p><a name="cont-postgres"></a></p>

<p><strong>Contenedor para PostgreSQL</strong></p>

<p>La dockerización de PostgreSQL es una de las más sencillas que hay, solamente tenemos que crear un docker-compose y levantar el contenedor.</p>

<p><em>Generación del scripts de docker</em></p>

<p>docker-compose.yml</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">version: <span class="s1">'3.3'</span>
services:
  db:
    image: postgres
    restart: always
    container_name: postgresql
    environment:
      - <span class="nv">POSTGRES_USER</span><span class="o">=</span>mi_usuario
      - <span class="nv">POSTGRES_PASSWORD</span><span class="o">=</span>mi_contraseña
    ports:
      - <span class="s1">'mi_puerto_ext:5432'</span>
    volumes:
      - db:/var/lib/postgresql/data
volumes:
  db:
    driver: <span class="nb">local</span></code></pre></figure>

<p>En la carpeta <em>./db</em> que se creará automáticamente tendremos todos los ficheros de la base de datos para poder consultar y/o modificar lo que necesitemos desde fuera del contenedor.</p>

<p><a name="cont-mysql"></a></p>

<p><strong>Contenedor para mySQL</strong></p>

<p>La dockerización de MySQL es una de las más sencillas que hay, solamente tenemos que crear un docker-compose y levantar el contenedor.</p>

<p><em>Generación del scripts de docker</em></p>

<p>docker-compose.yml</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">version: <span class="s1">'2.4'</span>
services:
  mariadb:
    image: mariadb
    container_name: mysql
    restart: always
    volumes:
      - ./db:/var/lib/mysql
    environment:
      TZ: Europe/Madrid
      <span class="c">#MYSQL_RANDOM_ROOT_PASSWORD: "yes"</span>
      MYSQL_ROOT_PASSWORD: mi_contraseña_root
      MYSQL_DATABASE: mi_nombre_bbdd
      MYSQL_USER: mi_usuario
      MYSQL_PASSWORD: mi_contraseña
    ports:
      - 23452:3306
    <span class="c">#healthcheck:</span>
      <span class="c">#test:  mysqladmin ping -h 127.0.0.1 -u root --password=$$MYSQL_ROOT_PASSWORD || exit 1</span>
      <span class="c">#test:  mysqladmin ping -h 127.0.0.1 -u $$MYSQL_USER --password=$$MYSQL_PASSWORD || exit 1</span>
      <span class="c">#interval: 60s</span>
      <span class="c">#timeout: 5s</span>
      <span class="c">#retries: 5</span>
      <span class="c">#start_period: 30s</span></code></pre></figure>

<p>En la carpeta <em>./db</em> que se creará automáticamente tendremos todos los ficheros de la base de datos para poder consultar y/o modificar lo que necesitemos desde fuera del contenedor.</p>

<p><a name="cont-mongo"></a></p>

<p><strong>Contenedor para MongoDB</strong></p>

<p>La dockerización de MongoDB es una de las más sencillas que hay, solamente tenemos que crear un docker-compose y levantar el contenedor.</p>

<p><em>Generación del scripts de docker</em></p>

<p>docker-compose.yml</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">version: <span class="s1">'3.7'</span>
services:
  mongodb_container:
    image: mongo:latest
    ports:
      - mi_puerto_ext:27017
    volumes:
      - db:/data/db
volumes:
  db:</code></pre></figure>

<p>En la carpeta <em>./db</em> que se creará automáticamente tendremos todos los ficheros de la base de datos para poder consultar y/o modificar lo que necesitemos desde fuera del contenedor.</p>

<hr />

<p><strong>Fuentes:</strong></p>

<p><a href="https://certbot.eff.org/instructions">https://certbot.eff.org/instructions</a></p>

<p><a href="https://wstutorial.com/rest/spring-boot-with-lets-encrypt.html">https://wstutorial.com/rest/spring-boot-with-lets-encrypt.html</a></p>

<p><a href="https://spring.io/guides/topicals/spring-boot-docker/">https://spring.io/guides/topicals/spring-boot-docker/</a></p>

<p><a href="https://awstip.com/run-nginx-in-a-docker-container-using-pre-generated-ssl-certificates-from-letsencrypt-b005ebce74ca">https://awstip.com/run-nginx-in-a-docker-container-using-pre-generated-ssl-certificates-from-letsencrypt-b005ebce74ca</a></p>]]></content><author><name></name></author><category term="docker" /><category term="docker-compose" /><category term="vps" /><category term="spring" /><category term="java" /><category term="php" /><category term="laravel" /><category term="flask" /><category term="python" /><summary type="html"><![CDATA[Cómo he dockerizado mi vps para alojar aplicaciones: spring, laravel, flask...y más]]></summary></entry><entry><title type="html">Python - IA juego Hotel</title><link href="https://rarcos.com/es/2022/08/11/IA-Juego-Hotel/" rel="alternate" type="text/html" title="Python - IA juego Hotel" /><published>2022-08-11T16:33:28+02:00</published><updated>2022-08-11T16:33:28+02:00</updated><id>https://rarcos.com/2022/08/11/IA%20-%20Juego%20Hotel</id><content type="html" xml:base="https://rarcos.com/2022/08/11/IA-Juego-Hotel/"><![CDATA[<p>He realizado la creación de un sistema de IA para aprendizaje de la decisión de compra para el juego del Hotel. Se trata de decidir si se compra o no en la casilla de <em>compra</em>, y predecir cual de las propiedades es mejor comprar.</p>

<h1 id="programa-generador-de-partidas">Programa generador de partidas</h1>

<p><strong>Generador de partidas</strong></p>

<p>En primer lugar he tenido que realizar una generador de partidas del juego del Hotel, para alimentar a la IA. Posteriormente he creado también un jugador IA para comparar los resultados obtenidos tras el aprendizaje de la IA.</p>

<p><em>Generador de partidas aleatorio (juego Hotel, 4 jugadores):</em></p>

<p><a href="https://colab.research.google.com/drive/1KEqghfPGeuk9u5u8_s531CCb7869Hn3u"><img src="/images/pages/repository_small_colab.png" alt="Generador de partidas" /></a></p>

<p><strong>Dataset</strong></p>

<p>El conjunto de datos utilizado es el dataset de 500 partidas, pero se ha probado progresivamente de 10, 100, 500, 1000. No teniendo apenas diferencia en el aprendizaje entre el de 500 a 1000 partidas.</p>

<p><em>10 partidas - 100 partidas - 500 partidas - 1000 partidas</em></p>

<p><a href="https://github.com/rubenarcos2/ia-juego_hotel/raw/main/datasets/Diez_Partidas_Hotel.csv"><img src="/images/pages/repository_small_file.png" alt="Dataset 10 partidas" /></a>
<a href="https://github.com/rubenarcos2/ia-juego_hotel/raw/main/datasets/Cien_Partidas_Hotel.csv"><img src="/images/pages/repository_small_file.png" alt="Dataset 100 partidas" /></a>
<a href="https://github.com/rubenarcos2/ia-juego_hotel/raw/main/datasets/Quinientas_Partidas_Hotel_A.csv"><img src="/images/pages/repository_small_file.png" alt="Dataset 500 partidas" /></a>
<a href="https://github.com/rubenarcos2/ia-juego_hotel/raw/main/datasets/Mil_Partidas_Hotel.csv"><img src="/images/pages/repository_small_file.png" alt="Dataset 1000 partidas" /></a></p>

<h1 id="programa-de-ia">Programa de IA</h1>

<p>Tras alimentar con el dataset y realizar el EDA correspondiente, he procedido a probar los modelos predictivos de IA que podrían ser más recomendables debido a la casuística en la que nos encontramos. Tras descartar, los que dabamos valores totalmente fuera de lugar, han sido: Adaboost, Naives Bayes, Decision Tree, Random Forest, XGBoost y 3 modelos diferente de deep learning (LSTM, Neuronal básica, Neuronal profunda).</p>

<p><strong>Evaluación y resultados</strong></p>

<table>
  <tbody>
    <tr>
      <td><strong>Modelo predictivo</strong></td>
      <td><strong>Tasa acierto</strong></td>
      <td><strong>Tase error</strong> *</td>
      <td><strong>Accuracy</strong></td>
    </tr>
    <tr>
      <td>Naives Bayes (Smooth 1e-10)</td>
      <td>66%</td>
      <td>40%</td>
      <td>0.66662</td>
    </tr>
    <tr>
      <td>Naives Bayes (Smooth 1e-7)</td>
      <td>91%</td>
      <td>75%</td>
      <td>0.90729</td>
    </tr>
    <tr>
      <td>Naives Bayes (Smooth 1e-11)</td>
      <td>65%</td>
      <td>40%</td>
      <td>0.65114</td>
    </tr>
    <tr>
      <td>Adaboost</td>
      <td>2%</td>
      <td>100%</td>
      <td>0.96112</td>
    </tr>
    <tr>
      <td>Decision Tree</td>
      <td>2%</td>
      <td>63%</td>
      <td>0.96113</td>
    </tr>
    <tr>
      <td>Adaboost</td>
      <td>2%</td>
      <td>100%</td>
      <td>0.96011</td>
    </tr>
    <tr>
      <td>Adaboost</td>
      <td>2%</td>
      <td>78%</td>
      <td>0.95977</td>
    </tr>
  </tbody>
</table>

<p><em>*en los diferenetes a ‘no compra’, es decir en la elección de la propiedad</em></p>

<p>Para ver los detalles de la evaluación y el programa de IA que contiene los resultados en :</p>

<p><a href="https://colab.research.google.com/drive/10rXkRiRnq59435RtOSICPrA1T2dXyxG6"><img src="/images/pages/repository_small_colab.png" alt="Programa IA" /></a></p>

<p><strong>Jugadores vs IA</strong></p>

<p>El resultado es que gana la IA entre un 40%-47% de las veces.</p>

<p>Para ver el programa que evalua la partida de jugadores aleatorios vs IA:</p>

<p><a href="https://colab.research.google.com/drive/1c-ozdgzMSYzZD2el46knjWx0SRIi-hMC"><img src="/images/pages/repository_small_colab.png" alt="Programa Jugadores vs IA" /></a></p>

<p>Los resultado de las partidas se encuentran aquí:</p>

<p><em>10 partidas - 100 partidas</em></p>

<p><a href="https://raw.githubusercontent.com/rubenarcos2/ia-juego_hotel/main/jugador_partidas_vs_ia/Diez_Partidas_Hotel-Jugadores_vs_IA.csv"><img src="/images/pages/repository_small_file.png" alt="Dataset 10 partidas" /></a>
<a href="https://github.com/rubenarcos2/ia-juego_hotel/raw/main/jugador_partidas_vs_ia/Cien_Partidas_Hotel-Jugadores_vs_IA.csv"><img src="/images/pages/repository_small_file.png" alt="Dataset 100 partidas" /></a></p>

<h1 id="programa-de-predicción">Programa de predicción</h1>

<p>He realizado en flask el programa de predicción, importando el modelo ya entrenado con <em>pickle</em> y creado un formulario web para la introducción de los datos necesarios para la predicción.</p>

<p><a href="https://hotel.rarcos.com">Aplicación web - https://hotel.rarcos.com</a></p>

<hr />

<p>Si quieres ver el resultado de todo, te recomiendo visites:</p>

<p><em>Repositorio con el contenido</em></p>

<p><em>Repositorio - Generador - Prog. IA - Jugadores vs IA</em></p>

<p><a href="https://github.com/rubenarcos2/ia-juego_hotel"><img src="/images/pages/repository_small.png" alt="Repositorio" /></a>
<a href="https://colab.research.google.com/drive/1KEqghfPGeuk9u5u8_s531CCb7869Hn3u"><img src="/images/pages/repository_small_colab.png" alt="Generador de partidas" /></a>
<a href="https://colab.research.google.com/drive/10rXkRiRnq59435RtOSICPrA1T2dXyxG6"><img src="/images/pages/repository_small_colab.png" alt="Programa IA" /></a>
<a href="https://colab.research.google.com/drive/1c-ozdgzMSYzZD2el46knjWx0SRIi-hMC"><img src="/images/pages/repository_small_colab.png" alt="Programa Jugadores vs IA" /></a></p>]]></content><author><name></name></author><category term="python" /><category term="naives bayes" /><category term="ia" /><category term="colab" /><summary type="html"><![CDATA[Creación de un sistema de IA para aprendizaje de la decisión de compra para el juego del Hotel]]></summary></entry></feed>