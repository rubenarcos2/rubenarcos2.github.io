<!DOCTYPE html>
<style>
  .alert {
    padding: 20px;
    background-color: #ff9203;
    text-align: center;
  }

  .alert a{
    color: white;
    text-decoration: none;
  }

  .closebtn {
    margin-left: 15px;
    color: white;
    font-weight: bold;
    float: right;
    font-size: 22px;
    line-height: 20px;
    cursor: pointer;
    transition: 0.3s;
  }

  .closebtn:hover {
    color: black;
  }
</style>




<html lang="es">







<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Chatbot opensource</title>
  <meta name='description'
    content='Creaci贸n de un chatbot con modelo opensource. Aplicando la t茅cnica RAG y utilizando Ollama, LangChain, ChromaDb y una salida final como API a un chatbot web'>

  <!-- Google Fonts -->
  <link
    href="https://fonts.googleapis.com/css?family=Dancing+Script%7CPT+Serif:400,400i,700%7CLato:400,700%7CRoboto:300,400"
    rel="stylesheet">

  <!-- Font Awesome v6.4.2 -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">

  <!-- Normalize v7.0.0 -->
  <link rel="stylesheet" href="/es/css/normalize.css">

  <!-- Main Stylesheet -->
  <link rel="stylesheet" href="/es/css/main.css">
  <link rel="canonical" href="https://rarcos.com/es/2024/05/25/Ollama_api_chatbot/">
  <link rel="alternate" type="application/rss+xml" title="Rub茅n Arcos" href="/es/feed.xml">

  <!-- Chrome, Firefox OS and Opera -->
  <meta name="theme-color" content="#faf5ee">
  <!-- Windows Phone -->
  <meta name="msapplication-navbutton-color" content="#faf5ee">
  <!-- iOS Safari -->
  <meta name="apple-mobile-web-app-status-bar-style" content="#faf5ee">
  <!-- Start cookieyes banner --> 
  <script id="cookieyes" type="text/javascript" src="https://cdn-cookieyes.com/client_data/6ae1ee7e40cef2c175ff9462/script.js"></script> 
  <!-- End cookieyes banner -->
</head>



  
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VL018H86JE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-VL018H86JE');
</script> <!-- /Google Analytics -->
  

  <div class="full-page-container">
    <div class="overlay"></div>
    <header class="site-header clearfix">
  <div class="wrapper-content">

    <div class="switch-lang">
      
      
      
      <a id="switch-lang" href=" /2024/05/25/Ollama_api_chatbot/" title="Change language to en">
        <img src=" https://cdn.wpml.org/wp-content/plugins/sitepress-multilingual-cms/res/flags/en.png">
      </a>
      
      
      
      
      <!--es-->
      
      
    </div>

    <div class="navigation-wrap">
      <div class="nav-toggle-close"><i class="fa fa-times" aria-hidden="true"></i></div>

      <nav class="site-nav">
        
        
        
        
        
        
        
      
      
      <a href='/es/about/'>Sobre m铆</a>
      
      
      
      
      
      
        
        
        
        
        
        
        
      
      
      <a href='/es/contacto/'>Contacto</a>
      
      
      
      
      
      
        
        
        
        
        
        
        
      
      
      <a href='/es/cookies/'>Cookies</a>
      
      
      
      
      
      
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        <a href="https://linkedin.com/in/rubenarcos2"><i class="fa-brands fa-linkedin fa-2x" aria-hidden="true"></i></a>
        <a href="https://github.com/rubenarcos2"><i class="fa-brands fa-github fa-2x" aria-hidden="true"></i></a>
      </nav>

    </div>

    <span class="search-toggle">
      <i class="fa fa-search" aria-hidden="true"></i>
    </span>

    <div class="nav-toggle"><i class="fa fa-bars" aria-hidden="true"></i></div>

    <div class="site-logo">
      <a href="/es/">Rub茅n Arcos</a>
    </div>

  </div>
</header> <!-- /.site-header -->
    <div class="search-box">
  <div class="wrapper-content">
    <form class="search-form">
      
      
      
      <label class="screen-reader-text" for="search-input">Buscar...</label>
      <input type="text" id="search-input" class="search-field" name="s" placeholder="Buscar...">
      
      
      
      
      
      

    </form>
    <div class="btn-close">
      <span class="bt-search-close">
        <i class="fa fa-times" aria-hidden="true"></i>
      </span>
    </div>
  </div>
  <ul id="results-container" class="search-results-list"></ul>
</div> <!-- /.search-box -->
    
    
    
    
    <div class="alert">
      <span class="closebtn" onclick="this.parentElement.style.display='none';">&times;</span> 
      <a href="https://www.linkedin.com/in/rubenarcos2/">Ofertas laborales, propuestas u otras iniciativas env铆amelas a trav茅s de LinkedIn</a>
    </div>    
    
    
    
    
    
    

    <div class="post-header" style="background: url(/images/pages/ollama_api.jpg)">
  <div class="post-header-info">
    <h1 class="post-title">Chatbot opensource</h1>
    <div class="post-meta">
      
      
      
      <time datetime="2024-05-25T09:10:28+02:00">
         25/05/2024
      </time>
      
      
      
      
      
      
      
    </div>
  </div>
</div>
<div id="readPostContent" style="text-align:center"><a class="btn btn-middle" onclick="readPostContent(this)">
    
    
    
    Leer art铆culo en voz alta
    
    
    
    
    
    
  </a></div>
<div class="content-box">
  <article class="post">

    <div class="post-content">
      <p>La creaci贸n de un chatbot para una p谩gina web, es una tarea que se suele contratar a un proveedor de servicios, pero en este caso voy a contar como se puede realizar de principio a fin y adem谩s con un conjunto de herramientas que son libres y gratuitas.</p>

<h1 id="creaci贸n-de-un-chatbot-con-modelo-opensource">Creaci贸n de un chatbot con modelo opensource</h1>

<p>Los bot de charla o bot conversacional (en ingl茅s: chatbot), son aplicaciones software que surgen en los a帽os 60, y que simulan mantener una conversaci贸n con una persona al proveer respuestas autom谩ticas, las cuales son previamente establecidas por un conjunto de expertos a entradas realizadas por el usuario. Estos bot, tambi茅n conocidos como sistemas expertos, utilizan el razonamiento basado en casos (CBR: case base reasoning).</p>

<p>Habitualmente, la conversaci贸n se establece mediante texto, aunque tambi茅n hay modelos que disponen de una interfaz de usuario multimedia que permiten la entrada auditiva. M谩s recientemente, algunos comienzan a utilizar programas conversores de texto a sonido (CTV), dotando de mayor realismo a la interacci贸n con el usuario y ayudando a reducir el tiempo de respuesta.</p>

<p>Para establecer una conversaci贸n, han de utilizarse frases f谩cilmente comprensibles y que sean coherentes, aunque la mayor铆a de los bot conversacionales no consiguen comprender del todo. En su lugar, tienen en cuenta las palabras o frases del interlocutor, que les permitir谩n usar una serie de respuestas preparadas de antemano. Estos son capaces de reconocer la manera en la que una frase est谩 formulada gracias a una serie de patrones comparativos preestablecidos, y de este modo, bas谩ndose en las diferentes variables de dicha frase, presentan una respuesta correspondiente. De esta manera, el bot es capaz de seguir una conversaci贸n con m谩s o menos l贸gica, pero sin saber realmente de qu茅 est谩 hablando.</p>

<blockquote>
  <p>Para tener m谩s informaci贸n te recomiendo visites el siguiente <a href="https://es.wikipedia.org/wiki/Bot_conversacional">art铆culo</a> de wikipedia de donde se ha obtenido este fragmento.</p>
</blockquote>

<h1 id="qu茅-es-retrieval-augmented-generation-rag">驴Qu茅 es Retrieval-Augmented Generation (RAG)?</h1>

<p>Es el aumento de conocimiento que se aplica a un LLM con datos que no ha sido entrenado. Esto permite al sistema de IA generativa proporcionar respuestas contextualmente adecuadas a las consultas, as铆 como basar dichas respuestas en datos extremadamente recientes.</p>

<p>En pocas palabras, la RAG ayuda a los LLM a proporcionar respuestas m谩s id贸neas.</p>

<p><strong>Conclusiones clave</strong></p>

<ul>
  <li>La RAG es una t茅cnica de inteligencia artificial relativamente nueva que mejora la calidad de la IA generativa al permitir a grandes modelos de lenguaje (LLM) aprovechar recursos de datos adicionales sin necesidad de volver a entrenarlos.</li>
  <li>Los modelos RAG crean repositorios de conocimientos basados en los datos de la propia organizaci贸n. Estos repositorios se pueden actualizar continuamente para ayudar a la IA generativa a brindar respuestas adaptadas al contexto y oportunas.</li>
  <li>Los chatbots y otros sistemas conversacionales que utilizan el procesamiento del lenguaje natural pueden beneficiarse enormemente de la RAG y la IA generativa.</li>
  <li>La implementaci贸n de RAG requiere tecnolog铆as como bases de datos vectoriales, que permiten la codificaci贸n r谩pida de nuevos datos y la b煤squeda en esos datos para alimentar el LLM.</li>
</ul>

<h2 id="c贸mo-funciona">驴C贸mo funciona?</h2>

<p>Los datos de esa biblioteca de conocimientos se procesan en representaciones num茅ricas utilizando un tipo especial de algoritmo llamado modelo de lenguaje embebido y se almacenan en una base de datos vectorial, en la que se puede buscar r谩pidamente para recuperar la informaci贸n contextual correcta.</p>

<blockquote>
  <p>Para tener m谩s informaci贸n te recomiendo visites el siguiente <a href="https://www.oracle.com/es/artificial-intelligence/generative-ai/retrieval-augmented-generation-rag/">art铆culo</a> de Oracle de donde se ha obtenido este fragmento.</p>
</blockquote>

<h1 id="arquitectura">Arquitectura</h1>

<p><img src="/images/pages/ollama_api_arquitectura.jpg" alt="Architecture" title="Ollama API Architecture" /></p>

<p>Nosotros vamos a ejecutar nuestro modelo LLM en un servidor local. Adem谩s vamos a tener la posibilidad de cambiar de modelo desde una interfaz amigable de administraci贸n, que nos permite descargarnos el modelo que deseemos utilizar e incluso poder probarlo con antelaci贸n. Por ello, he elegido <a href="https://ollama.com/">Ollama</a> que tiene un <a href="https://ollama.com/library">conjunto de modelos</a> opensource bastante interesante. Vamos a ir viendo paso a paso c贸mo ir instalando y configurando nuestro software.</p>

<p>Pero antes de nada, vamos a ver una breve descripci贸n de cada uno de los elementos que vamos a instalar:</p>

<h2 id="ollama">Ollama</h2>

<p>Ollama hace que sea muy f谩cil ejecutar LLM de c贸digo abierto localmente. Puede esperar un rendimiento decente incluso en port谩tiles peque帽os. Ollama es una alternativa a Hugging Face para ejecutar modelos localmente. Las bibliotecas de Hugging Face se ejecutan sobre Tensorflow o Torch. Ollama usa llama.cpp como tiempo de ejecuci贸n subyacente. Esto hace que sea muy f谩cil comenzar con Ollama. Ni siquiera necesitas tener Python instalado.</p>

<h2 id="langchain">LangChain</h2>

<p>LangChain es un marco de trabajo de c贸digo abierto para crear aplicaciones basadas en modelos de lenguaje de gran tama帽o (LLM). Los LLM son grandes modelos de aprendizaje profundo entrenados previamente con grandes cantidades de datos que pueden generar respuestas a las consultas de los usuarios, por ejemplo, responder preguntas o crear im谩genes a partir de peticiones basadas en texto. LangChain proporciona herramientas y abstracciones para mejorar la personalizaci贸n, precisi贸n y relevancia de la informaci贸n que generan los modelos. Por ejemplo, los desarrolladores pueden usar los componentes de LangChain para crear nuevas cadenas de peticiones o personalizar las plantillas existentes. LangChain tambi茅n incluye componentes que permiten a los LLM acceder a nuevos conjuntos de datos sin necesidad de repetir el entrenamiento.</p>

<blockquote>
  <p>Para tener m谩s informaci贸n te recomiendo visites el siguiente <a href="https://aws.amazon.com/es/what-is/langchain/">art铆culo</a> de AWS de donde se ha obtenido este fragmento.</p>
</blockquote>

<h2 id="chromadb">ChromaDb</h2>

<p>ChromaDB es una base de datos especializada en el almacenamiento y recuperaci贸n eficiente de informaci贸n ling眉铆stica, incluyendo datos de texto, anotaciones sem谩nticas y sint谩cticas. ChromaDB es particularmente 煤til para el almacenamiento y la gesti贸n de grandes cantidades de datos de lenguaje natural, lo que permite a los desarrolladores aprovechar al m谩ximo los avances en algoritmos de aprendizaje autom谩tico y an谩lisis de texto.</p>

<blockquote>
  <p>Para tener m谩s informaci贸n te recomiendo visites el siguiente <a href="https://brainq.ai/chromadb/">art铆culo</a> de donde se ha obtenido este fragmento.</p>
</blockquote>

<h2 id="api-con-flask">API con Flask</h2>

<p>Flask es un micro marco de trabajo web de Python que proporciona las herramientas necesarias para crear aplicaciones web de manera r谩pida y sencilla. Aunque es un micro marco, Flask es altamente modular y permite agregar f谩cilmente extensiones para agregar funcionalidades adicionales.</p>

<blockquote>
  <p>Para tener m谩s informaci贸n te recomiendo visites el siguiente <a href="https://datascientest.com/es/programacion-de-api-web-en-python-con-flask">art铆culo</a> de donde se ha obtenido este fragmento y donde puedes seguir el tutorial detallado de como crear una API con Flask.</p>
</blockquote>

<h2 id="el-chatbot-web">El Chatbot web</h2>

<p>Me he basado en esta integraci贸n de un chatbot web, para utilizar los recursos y adaptarlo a nuestro modelo opensource alojado en Ollama.</p>

<p>El c贸digo fuente se encuentra <a href="https://github.com/galaxyofai/chatgpt_flask_webapp">aqu铆</a>.</p>

<p>Y un explicaci贸n detallada de como integrarlo con otras API, se encuentra <a href="https://galaxyofai.com/building-a-flask-chat-web-app-with-openais-chatgpt-api/">aqu铆</a>.</p>

<h1 id="la-demostraci贸n">La demostraci贸n</h1>

<p>A continuaci贸n se ha embebido la aplicaci贸n realizada. Esta est谩 alojada en un servidor de unas caracter铆sticas muy limitadas para la ejecuci贸n de desarrollos de inteligencia artificial. Pero como demostraci贸n de que es posible, aqu铆 se encuentra en funcionamiento:</p>

<blockquote>
  <p><img src="/images/pages/aviso_icon.png" alt="Aviso" /> <strong>El chatbot est谩 alojado en un servidor con pocos recursos.</strong><br /><br />Por ello tarda bastante en contestar. Es precisamente lo que se busca, demostrar la viabilidad en este tipo de entornos.</p>
</blockquote>

<p>Preguntas de ejemplo que puede realizar:</p>
<ul>
  <li>驴Qu茅 experiencia tiene Rub茅n Arcos?</li>
  <li>驴Cu谩ntos a帽os de experiencia tiene Rub茅n Arcos?</li>
  <li>驴Qu茅 lenguajes de programaci贸n sabe Rub茅n Arcos?</li>
</ul>

<p><em>Haga clic sobre la burbuja morada, para abrir el Chatbot</em></p>

<p style="text-align: center">
  <iframe style="border: 0" id="chatbot" title="Chatbot" width="390" height="600" src="https://chat.rarcos.com/">
  </iframe>
</p>

<h1 id="el-tutorial">El tutorial</h1>

<p>Como viene siendo habitual en esta p谩gina web, vamos a utilizar un entorno dockerizado que ser谩 el encargado de levantar Ollama, el administrador web de Ollama y nuestra aplicaci贸n de ChatBot web.</p>

<p>Para ello tenemos los siguiente scripts de <em>docker compose</em>:</p>

<h3 id="script-de-ejecuci贸n-m谩s-completo-sin-gpu">Script de ejecuci贸n m谩s completo (sin GPU)</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>version: '3.8'
services:
  app:
    build: .
    container_name: ollama-app
    ports:
      - 8002:8002
      - 5678:5678
    volumes:
      - ./app:/usr/src/app/
    command: python app.py
    restart: always
    depends_on:
      - ollama
      - ollama-webui
    networks:
      - ollama-docker

  ollama:
    image: ollama/ollama:latest
    ports:
      - 11434:11434
    volumes:
      - .:/code
      - ./ollama/ollama:/root/.ollama
    container_name: ollama
    pull_policy: always
    tty: true
    restart: always
    networks:
      - ollama-docker

  ollama-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: ollama-webui
    volumes:
      - ./ollama/ollama-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
      - 8080:8080
    environment:
      - '/ollama/api=http://ollama:11434/api'
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped
    networks:
      - ollama-docker

networks:
  ollama-docker:
    external: false

</code></pre></div></div>

<h3 id="el-script-m铆nimo-sin-gpu">El script m铆nimo (sin GPU)</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>services:

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    tty: true
    restart: unless-stopped
    # Expose Ollama API outside the container stack
    ports:
      - 11434:11434
      - 53:53
    volumes:
      - ollama:/root/.ollama
    command: pip install -r requirements.txt

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    volumes:
      - open-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
      - 8080:8080
    environment:
      - "OLLAMA_API_BASE_URL=http://ollama:11434/api"
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped

volumes:
  ollama: {}
  open-webui: {}
</code></pre></div></div>
<h3 id="el-script-para-utilizaci贸n-de-gpu">El script para utilizaci贸n de GPU</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>version: '3.8'

services:
  app:
    build: .
    ports:
      - 8000:8000
      - 5678:5678
    volumes:
      - .:/code
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
    restart: always
    depends_on:
      - ollama
      - ollama-webui
    networks:
      - ollama-docker
      
  ollama:
    volumes:
      - ./ollama/ollama:/root/.ollama
    container_name: ollama
    pull_policy: always
    tty: true
    restart: unless-stopped
    image: ollama/ollama:latest
    ports:
      - 11434:11434
    networks:
      - ollama-docker
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  ollama-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: ollama-webui
    volumes:
      - ./ollama/ollama-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
      - 8080:8080
    environment:
      - '/ollama/api=http://ollama:11434/api'
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped
    networks:
      - ollama-docker

networks:
  ollama-docker:
    external: false

</code></pre></div></div>

<p>Las rutas de acceso que se establecen son:</p>
<ul>
  <li>P谩gina web de administraci贸n de Ollama: <a href="http://localhost:8080">http://localhost:8080</a></li>
  <li>Motor de Ollana: <a href="http://localhost:11434">http://localhost:11434</a></li>
  <li>Aplicaci贸n web: <a href="http://localhost:8002">http://localhost:8002</a></li>
</ul>

<blockquote>
  <p>Para tener m谩s informaci贸n te recomiendo visites el siguiente <a href="https://github.com/valiantlynx/ollama-docker/">repositorio</a> de donde se ha obtenido este script y donde hay m谩s ejemplos e informaci贸n.</p>
</blockquote>

<h3 id="la-instalaci贸n-del-modelo-desde-el-administrador-web-de-ollama">La instalaci贸n del modelo desde el administrador web de Ollama</h3>

<p>Una vez tenemos el docker levantado, tan solo tenemos que entrar a la url <a href="http://localhost:8080">http://localhost:8080</a>, descargar e instalar el modelo.</p>

<p>A continuaci贸n se muestra un video de c贸mo se realiza:</p>

<p><img src="/images/pages/ollama_install.gif" alt="video" /></p>

<p>En nuestro caso introduciremos el modelo: <em>mistral:instruct</em></p>

<h3 id="la-aplicaci贸n-en-consola-el-chatbot">La aplicaci贸n en consola (el chatbot)</h3>

<p>Luego tenemos la aplicaci贸n en consola que consume el modelo LLM, en nuestro ejemplo se ha utilizado <em>Mistral</em> por sus gran rendimiento similar a Llama y por ser opensource. Tambi茅n tenemos la especificaci贸n del promt de consulta, con unas instrucciones previas a las consultas. Y el m茅todo de entrenamiento RAG.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langchain_community.vectorstores import Chroma
from langchain_community.chat_models import ChatOllama
from langchain_community.embeddings.fastembed import FastEmbedEmbeddings
from langchain_community.document_loaders import WebBaseLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
import sys
 
class ChatWebDoc:
    vector_store = None
    retriever = None
    chain = None
 
    def __init__(self):
        self.model = ChatOllama(model="mistral:instruct")
        #Loading embedding
        self.embedding = FastEmbedEmbeddings()
 
        self.text_splitter = CharacterTextSplitter(chunk_size=1024, chunk_overlap=100)
        self.prompt = ChatPromptTemplate.from_messages(
        [
            ("system", 
"""You are an assistant for question-answering tasks. Use only the following 
context to answer the question. If you don't know the answer, just say that you don't know.
 
CONTEXT:
 
{context}
"""),
            ("human", "{input}"),
        ]
    )
 
    def ingest(self, url_list):
        #Load web pages
        docs = WebBaseLoader(url_list).load()
        chunks = self.text_splitter.split_documents(docs)
 
        #Create vector store
        vector_store = Chroma.from_documents(documents=chunks, 
            embedding=self.embedding, persist_directory="./chroma_db")
 
    def load(self):
        #Load vector store
        vector_store = Chroma(persist_directory="./chroma_db", 
            embedding_function=self.embedding)
 
        #Create chain
        self.retriever = vector_store.as_retriever(
            search_type="similarity_score_threshold",
            search_kwargs={
                "k": 3,
                "score_threshold": 0.5,
            },
        )
 
        document_chain = create_stuff_documents_chain(self.model, self.prompt)
        self.chain = create_retrieval_chain(self.retriever, document_chain)
 
    def ask(self, query: str):
        if not self.chain:
            self.load()
 
        result = self.chain.invoke({"input": query})
 
        print(result["answer"])
        for doc in result["context"]:
            print("Source: ", doc.metadata["source"])
 
 
def build():
    w = ChatWebDoc()
    w.ingest([
        "https://www.webagesolutions.com/courses/WA3446-comprehensive-angular-programming",
        "https://www.webagesolutions.com/courses/AZ-1005-configuring-azure-virtual-desktop-for-the-enterprise",
        "https://www.webagesolutions.com/courses/AZ-305T00-designing-microsoft-azure-infrastructure-solutions",
        ])
 
def chat():
    w = ChatWebDoc()
 
    w.load()
 
    while True:
        query = input("&gt;&gt;&gt; ")
 
        if len(query) == 0:
            continue
 
        if query == "/exit":
            break
         
        w.ask(query)
 
if len(sys.argv) &lt; 2:
    chat()
elif sys.argv[1] == "--ingest":
    build()
</code></pre></div></div>

<p>La ejecuci贸n del entrenamiento RAG de las web provistas anteriorement en el programa anterior se realiza con el comando:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python rag-test.py --ingest
</code></pre></div></div>

<p>La interactuaci贸n con el model una vez entrenado:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python rag-test.py
</code></pre></div></div>

<blockquote>
  <p>Recomiendo ver con mayor detalle esta <a href="https://mobiarch.wordpress.com/2024/02/19/run-rag-locally-using-mistral-ollama-and-langchain/">p谩gina web</a> donde se trata esta misma aplicaci贸n.</p>
</blockquote>

<h2 id="la-aplicaci贸n-web-el-chatbot">La aplicaci贸n web (el Chatbot)</h2>

<p>Queda pendiente para una futura actualizaci贸n del art铆culo que os muestre como integrar en la aplicaci贸n web el motor LLM, interactuar con el, entrenarlo con el m茅todo RAG y levantarlo en el servidor web. 隆Hasta pronto! </p>

<hr />

<p><strong>Fuentes:</strong></p>

<ul>
  <li><a href="https://github.com/valiantlynx/ollama-docker/">https://github.com/valiantlynx/ollama-docker</a></li>
  <li><a href="https://mobiarch.wordpress.com/2024/02/19/run-rag-locally-using-mistral-ollama-and-langchain/">https://mobiarch.wordpress.com/2024/02/19/run-rag-locally-using-mistral-ollama-and-langchain/</a></li>
  <li><a href="https://realpython.com/build-llm-rag-chatbot-with-langchain/">https://realpython.com/build-llm-rag-chatbot-with-langchain/</a></li>
</ul>

    </div>

    <footer class="post-footer">
      
      
      
      <p>
      <h3>Licencia de contenido</h3>

      <p><img src="/images/pages/88x311.png" /></p>

      <p>Esta p谩gina web y todo su contenido, incluido proyectos y c贸digo fuente, est谩 licenciado bajo una licencia de
        Creative Commons: Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) <a
          href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.es">M谩s info</a></p>

      </p>
      
      
      
      
      
      

      <ul class="post-footer-list">
        <li class="post-footer-item">
          <a class="post-facebook"
            href="https://www.facebook.com/sharer/sharer.php?u=https://rarcos.com/2024/05/25/Ollama_api_chatbot/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Facebook" rel="nofollow"><i class="fa-brands fa-facebook"
              aria-hidden="true"></i><span>Facebook</span></a>
        </li>

        <li class="post-footer-item">
          <a class="post-twitter"
            href="https://twitter.com/intent/tweet?text=Chatbot%20opensource&url=https://rarcos.com/2024/05/25/Ollama_api_chatbot/"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;"
            title="Share on Twitter" rel="nofollow"><i class="fa-brands fa-x-twitter"
              aria-hidden="true"></i><span>Twitter</span></a>
        </li>

        <li class="post-footer-item">
          <a href="http://pinterest.com/pin/create/button/?url=https://rarcos.com/2024/05/25/Ollama_api_chatbot/&amp;media=https://rarcos.com/images/pages/ollama_api.jpg&amp;description=Chatbot%20opensource"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;"
            class="post-pinterest" title="Share on Pinterest" rel="nofollow"><i class="fa-brands fa-pinterest"
              aria-hidden="true"></i><span>Pinterest</span></a>
        </li>

        <li class="post-footer-item">
          <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://rarcos.com/2024/05/25/Ollama_api_chatbot/&title=Chatbot%20opensource"
            onclick="window.open(this.href, 'pop-up', 'left=20,top=20,width=900,height=500,toolbar=1,resizable=0'); return false;"
            class="post-linkedin" title="Share on Linkedin" rel="nofollow"><i class="fa-brands fa-linkedin"
              aria-hidden="true"></i><span>Linkedin</span></a>
        </li>
      </ul>
      
      <div class="post-tag">
        <span>Tags:</span>
        
        <a href="/es/tags#ia" class="tag">ia</a>
        
        <a href="/es/tags#rag" class="tag">rag</a>
        
        <a href="/tags#open source" class="tag">open source</a>
        
        <a href="/es/tags#modelos" class="tag">modelos</a>
        
      </div>
      
    </footer>

    
    <div class="post-author">
      
      <div class="post-author-image">
        <a style="background-image: url(/images/ruben.jpg)">
          <span class="screen-reader-text">Rub茅n Arcos Picture</span>
        </a>
      </div>
      <div class="post-author-info">
        <h4>Rub茅n Arcos</h4>
        <p class="post-author-bio">
          
          
          
          Desarrollador TI. <br>M谩ster FP en IA y Big data, <br>T茅cnico superior en desarrollo de aplicaciones web y <br>T茅cnico superior en desarrollo de aplicaciones multiplataformas.
          
          
          
          
          
          
        </p>
        <div class="post-author-meta">
          
          <a href="https://twitter.com/rarcosdev" target="_blank"><i class="fa-brands fa-x-twitter" aria-hidden="true"></i></a>
          
          
          <a href="https://linkedin.com/in/rubenarcos2" target="_blank"><i class="fa-brands fa-linkedin" aria-hidden="true"></i></a>
          
          
          <a href="https://github.com/rubenarcos2" target="_blank"><i class="fa-brands fa-github" aria-hidden="true"></i></a>
          
          
          
          
          
          
          
          
          
        </div>
      </div>
      
    </div>

    <div class="page-navigation clearfix">
      
      <a class="prev-page" href="/es/2024/05/25/RAG_modelos_open_source/"><i class="fa fa-angle-left"
          aria-hidden="true"></i><span>RAG con modelos de IA open source</span></a>
      
      
      <a class="next-page" href="/es/2025/01/21/ALIA_a_spanish_model/"><span>ALIA el modelo espa帽ol de IA</span><i class="fa fa-angle-right"
          aria-hidden="true"></i></a>
      
    </div>

    
  </article> <!-- /.post -->

</div> <!-- /.content-box -->

    <div class="top" title="Scroll To Top">
  <i class="fa fa-chevron-up" aria-hidden="true"></i>
</div> <!-- /.top -->
    <footer class="site-footer">

  <div class="footer-wrapper">

    <h2 class="footer-heading">Rub茅n Arcos</h2>

    <ul class="social-footer">
    
      <li><a href="https://twitter.com/rarcosdev" target="_blank"><i class="fa-brands fa-x-twitter" aria-hidden="true"></i></a></li>
    
    
    
    
    <li><a href="https://linkedin.com/in/rubenarcos2" target="_blank"><i class="fa-brands fa-linkedin" aria-hidden="true"></i></a></li>
    
    
    <li><a href="https://github.com/rubenarcos2" target="_blank"><i class="fa-brands fa-github" aria-hidden="true"></i></a></li>
    
    
    
    
    
    
    
    
    
    </ul>

    <div class="copyright">
      <p><a href="https://jekyllrb.com/">Proudly powered by Jekyll</a> | Theme: Lokmont by <a href="https://artemsheludko.github.io/">Artem Sheludko</a> | Modifications: <a href="https://github.com/rubenarcos2">Rub茅n Arcos</a></p>
    </div>
  </div>

</footer> <!-- /.site-footer -->

  </div> <!-- /.full-page-container -->

  <script src="/js/jquery-3.7.1.min.js"></script>
<script src="/js/jquery.viewportchecker.min.js"></script>
<script src="/js/jquery.fitvids.js"></script>
<script src="/js/simple-jekyll-search.min.js"></script>
<script src="/js/transition.js"></script>
<script src="/js/zoom.min.js"></script>
<script src="/js/main.js"></script>
</body>

</html>